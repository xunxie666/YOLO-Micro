2023-04-04 16:45:14.254 | ERROR    | __main__:<module>:98 - An error has been caught in function '<module>', process 'MainProcess' (9264), thread 'MainThread' (716):
Traceback (most recent call last):

> File "E:\PyCharm2022.1.3\PycharmProjects\yolov7-main\tools\pruneModel.py", line 98, in <module>
    layer_pruning('../cfg/deploy/yolov7.pt')
    └ <function layer_pruning at 0x000001A1F0E1D040>

  File "E:\PyCharm2022.1.3\PycharmProjects\yolov7-main\tools\pruneModel.py", line 50, in layer_pruning
    strategy = tp.strategy.L1Strategy()  # L1策略
               └ <module 'torch_pruning' from 'D:\\XUNXIE\\anaconda3\\envs\\gluon\\lib\\site-packages\\torch_pruning\\__init__.py'>

AttributeError: module 'torch_pruning' has no attribute 'strategy'
2023-04-04 16:48:50.076 | INFO     | __main__:layer_pruning:63 - [Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)]
2023-04-04 16:48:50.084 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.0.conv (Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 24, 25, 26, 27, 29, 30, 31], NumPruned=594]
[ <DEP: prune_conv => prune_batchnorm on model.0.bn (BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 24, 25, 26, 27, 29, 30, 31], NumPruned=44]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 24, 25, 26, 27, 29, 30, 31], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.1.conv (Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 24, 25, 26, 27, 29, 30, 31], NumPruned=12672]
13310 parameters will be pruned
-------------

2023-04-04 16:48:50.085 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.0.bn (BatchNorm2d(10, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 7, 9], NumPruned=14]
[ <DEP: prune_batchnorm => prune_conv on model.0.conv (Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 9], NumPruned=189]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 9], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.1.conv (Conv2d(10, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 9], NumPruned=4032]
4235 parameters will be pruned
-------------

2023-04-04 16:48:50.086 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.1.conv (Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 18, 22, 23, 25, 26, 27, 28, 30, 32, 33, 34, 35, 37, 38, 39, 40, 44, 45, 46, 48, 49, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63], NumPruned=1188]
[ <DEP: prune_conv => prune_batchnorm on model.1.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 18, 22, 23, 25, 26, 27, 28, 30, 32, 33, 34, 35, 37, 38, 39, 40, 44, 45, 46, 48, 49, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 18, 22, 23, 25, 26, 27, 28, 30, 32, 33, 34, 35, 37, 38, 39, 40, 44, 45, 46, 48, 49, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.2.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 18, 22, 23, 25, 26, 27, 28, 30, 32, 33, 34, 35, 37, 38, 39, 40, 44, 45, 46, 48, 49, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63], NumPruned=25344]
26620 parameters will be pruned
-------------

2023-04-04 16:48:50.087 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.1.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.1.conv (Conv2d(3, 20, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18], NumPruned=378]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.2.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18], NumPruned=8064]
8470 parameters will be pruned
-------------

2023-04-04 16:48:50.098 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.2.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 6, 8, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 56, 58, 59, 62, 63], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.2.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 6, 8, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 56, 58, 59, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 6, 8, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 56, 58, 59, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.3.conv (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 3, 6, 8, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 56, 58, 59, 62, 63], NumPruned=50688]
53152 parameters will be pruned
-------------

2023-04-04 16:48:50.098 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.2.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 5, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.2.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 5, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.3.conv (Conv2d(20, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19], NumPruned=16128]
16912 parameters will be pruned
-------------

2023-04-04 16:48:50.099 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.3.conv (Conv2d(6, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 50, 52, 57, 60, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 78, 79, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127], NumPruned=4806]
[ <DEP: prune_conv => prune_batchnorm on model.3.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 50, 52, 57, 60, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 78, 79, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 50, 52, 57, 60, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 78, 79, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.5.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 50, 52, 57, 60, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 78, 79, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127], NumPruned=5696]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.4.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 50, 52, 57, 60, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 78, 79, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127], NumPruned=5696]
16376 parameters will be pruned
-------------

2023-04-04 16:48:50.114 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.3.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 36, 37], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.3.conv (Conv2d(6, 39, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 36, 37], NumPruned=1458]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 36, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.5.conv (Conv2d(39, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 36, 37], NumPruned=1728]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.4.conv (Conv2d(39, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 36, 37], NumPruned=1728]
4968 parameters will be pruned
-------------

2023-04-04 16:48:50.115 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.4.conv (Conv2d(12, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 3, 4, 6, 8, 11, 12, 14, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 50, 51, 53, 54, 56, 58, 61, 63], NumPruned=528]
[ <DEP: prune_conv => prune_batchnorm on model.4.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 6, 8, 11, 12, 14, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 50, 51, 53, 54, 56, 58, 61, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 6, 8, 11, 12, 14, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 50, 51, 53, 54, 56, 58, 61, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256])>, Index=[194, 195, 196, 198, 200, 203, 204, 206, 208, 209, 210, 211, 212, 214, 215, 216, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 237, 238, 239, 240, 242, 243, 245, 246, 248, 250, 253, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[194, 195, 196, 198, 200, 203, 204, 206, 208, 209, 210, 211, 212, 214, 215, 216, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 237, 238, 239, 240, 242, 243, 245, 246, 248, 250, 253, 255], NumPruned=11264]
11880 parameters will be pruned
-------------

2023-04-04 16:48:50.116 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.4.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 7, 10, 11, 14, 15, 17, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.4.conv (Conv2d(12, 20, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 10, 11, 14, 15, 17, 18, 19], NumPruned=168]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 7, 10, 11, 14, 15, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 212])>, Index=[192, 193, 194, 195, 196, 198, 199, 202, 203, 206, 207, 209, 210, 211], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(212, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[192, 193, 194, 195, 196, 198, 199, 202, 203, 206, 207, 209, 210, 211], NumPruned=3584]
3780 parameters will be pruned
-------------

2023-04-04 16:48:50.129 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.5.conv (Conv2d(12, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 8, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 48, 50, 51, 53, 54, 55, 56, 58, 59, 62, 63], NumPruned=528]
[ <DEP: prune_conv => prune_batchnorm on model.5.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 6, 8, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 48, 50, 51, 53, 54, 55, 56, 58, 59, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 6, 8, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 48, 50, 51, 53, 54, 55, 56, 58, 59, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.6.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 8, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 48, 50, 51, 53, 54, 55, 56, 58, 59, 62, 63], NumPruned=25344]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 198])>, Index=[128, 131, 132, 134, 136, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 173, 174, 176, 178, 179, 181, 182, 183, 184, 186, 187, 190, 191], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(198, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 131, 132, 134, 136, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 173, 174, 176, 178, 179, 181, 182, 183, 184, 186, 187, 190, 191], NumPruned=11264]
37224 parameters will be pruned
-------------

2023-04-04 16:48:50.131 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.5.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.5.conv (Conv2d(12, 20, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17], NumPruned=168]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.6.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17], NumPruned=8064]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 148, 154])>, Index=[130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(154, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145], NumPruned=3584]
11844 parameters will be pruned
-------------

2023-04-04 16:48:50.132 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.6.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 21, 25, 27, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.6.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 21, 25, 27, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 21, 25, 27, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.7.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 21, 25, 27, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63], NumPruned=25344]
27808 parameters will be pruned
-------------

2023-04-04 16:48:50.146 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.6.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.6.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 18, 19], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.7.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 18, 19], NumPruned=8064]
8848 parameters will be pruned
-------------

2023-04-04 16:48:50.146 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.7.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 12, 14, 15, 18, 20, 21, 22, 25, 27, 28, 29, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 62], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.7.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 12, 14, 15, 18, 20, 21, 22, 25, 27, 28, 29, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 62], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 12, 14, 15, 18, 20, 21, 22, 25, 27, 28, 29, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 62], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.8.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 12, 14, 15, 18, 20, 21, 22, 25, 27, 28, 29, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 62], NumPruned=25344]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 134, 140])>, Index=[64, 65, 66, 67, 68, 69, 70, 74, 76, 78, 79, 82, 84, 85, 86, 89, 91, 92, 93, 95, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 119, 120, 121, 122, 123, 124, 126], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(140, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 65, 66, 67, 68, 69, 70, 74, 76, 78, 79, 82, 84, 85, 86, 89, 91, 92, 93, 95, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 119, 120, 121, 122, 123, 124, 126], NumPruned=11264]
39072 parameters will be pruned
-------------

2023-04-04 16:48:50.147 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.7.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.7.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.8.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18], NumPruned=8064]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 84, 90, 96])>, Index=[64, 65, 67, 69, 71, 72, 73, 75, 76, 77, 79, 80, 81, 82], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 65, 67, 69, 71, 72, 73, 75, 76, 77, 79, 80, 81, 82], NumPruned=3584]
12432 parameters will be pruned
-------------

2023-04-04 16:48:50.162 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.8.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 7, 10, 14, 15, 18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.8.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 7, 10, 14, 15, 18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 7, 10, 14, 15, 18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.9.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 7, 10, 14, 15, 18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], NumPruned=25344]
27808 parameters will be pruned
-------------

2023-04-04 16:48:50.162 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.8.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], NumPruned=30]
[ <DEP: prune_batchnorm => prune_conv on model.8.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], NumPruned=810]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.9.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], NumPruned=8640]
9480 parameters will be pruned
-------------

2023-04-04 16:48:50.163 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.9.conv (Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 33, 37, 39, 40, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63], NumPruned=1980]
[ <DEP: prune_conv => prune_batchnorm on model.9.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 33, 37, 39, 40, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 33, 37, 39, 40, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 70, 76, 82])>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 33, 37, 39, 40, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(82, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 33, 37, 39, 40, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63], NumPruned=11264]
13332 parameters will be pruned
-------------

2023-04-04 16:48:50.178 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.9.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.9.conv (Conv2d(5, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 18, 19], NumPruned=630]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 20, 26, 32, 38])>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(38, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 18, 19], NumPruned=3584]
4242 parameters will be pruned
-------------

2023-04-04 16:48:50.179 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.11.conv (Conv2d(24, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=4296]
[ <DEP: prune_conv => prune_batchnorm on model.11.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.14.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=22912]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.13.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=22912]
50478 parameters will be pruned
-------------

2023-04-04 16:48:50.194 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.11.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=108]
[ <DEP: prune_batchnorm => prune_conv on model.11.conv (Conv2d(24, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=1296]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.14.conv (Conv2d(77, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=6912]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.13.conv (Conv2d(77, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=6912]
15228 parameters will be pruned
-------------

2023-04-04 16:48:50.195 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.13.conv (Conv2d(23, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 19, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 44, 45, 46, 47, 48, 52, 53, 54, 57, 59, 60, 61, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 98, 99, 103, 106, 107, 108, 109, 110, 113, 115, 117, 119, 122, 123, 124, 125, 126, 127], NumPruned=2047]
[ <DEP: prune_conv => prune_batchnorm on model.13.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 19, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 44, 45, 46, 47, 48, 52, 53, 54, 57, 59, 60, 61, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 98, 99, 103, 106, 107, 108, 109, 110, 113, 115, 117, 119, 122, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 19, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 44, 45, 46, 47, 48, 52, 53, 54, 57, 59, 60, 61, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 98, 99, 103, 106, 107, 108, 109, 110, 113, 115, 117, 119, 122, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256])>, Index=[128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 147, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 164, 165, 166, 167, 172, 173, 174, 175, 176, 180, 181, 182, 185, 187, 188, 189, 190, 192, 193, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 214, 215, 216, 218, 220, 221, 222, 223, 224, 226, 227, 231, 234, 235, 236, 237, 238, 241, 243, 245, 247, 250, 251, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.18.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 147, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 164, 165, 166, 167, 172, 173, 174, 175, 176, 180, 181, 182, 185, 187, 188, 189, 190, 192, 193, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 214, 215, 216, 218, 220, 221, 222, 223, 224, 226, 227, 231, 234, 235, 236, 237, 238, 241, 243, 245, 247, 250, 251, 252, 253, 254, 255], NumPruned=11392]
[ <DEP: _prune_concat => prune_related_conv on model.17.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 147, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 164, 165, 166, 167, 172, 173, 174, 175, 176, 180, 181, 182, 185, 187, 188, 189, 190, 192, 193, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 214, 215, 216, 218, 220, 221, 222, 223, 224, 226, 227, 231, 234, 235, 236, 237, 238, 241, 243, 245, 247, 250, 251, 252, 253, 254, 255], NumPruned=11392]
25009 parameters will be pruned
-------------

2023-04-04 16:48:50.210 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.13.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.13.conv (Conv2d(23, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38], NumPruned=621]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 167])>, Index=[128, 130, 132, 133, 134, 135, 138, 139, 141, 142, 143, 146, 147, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 162, 164, 165, 166], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.18.conv (Conv2d(167, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 130, 132, 133, 134, 135, 138, 139, 141, 142, 143, 146, 147, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 162, 164, 165, 166], NumPruned=3456]
[ <DEP: _prune_concat => prune_related_conv on model.17.conv (Conv2d(167, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 130, 132, 133, 134, 135, 138, 139, 141, 142, 143, 146, 147, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 162, 164, 165, 166], NumPruned=3456]
7587 parameters will be pruned
-------------

2023-04-04 16:48:50.212 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.14.conv (Conv2d(23, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 34, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 71, 72, 73, 75, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 127], NumPruned=2047]
[ <DEP: prune_conv => prune_batchnorm on model.14.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 34, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 71, 72, 73, 75, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 34, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 71, 72, 73, 75, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.15.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 34, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 71, 72, 73, 75, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 127], NumPruned=102528]
104753 parameters will be pruned
-------------

2023-04-04 16:48:50.213 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.14.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 14, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 31, 33, 34, 35, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.14.conv (Conv2d(23, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 14, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 31, 33, 34, 35, 38], NumPruned=621]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 14, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 31, 33, 34, 35, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.15.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 14, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 31, 33, 34, 35, 38], NumPruned=31104]
31779 parameters will be pruned
-------------

2023-04-04 16:48:50.226 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.15.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.15.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 140])>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.18.conv (Conv2d(140, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=11392]
[ <DEP: _prune_concat => prune_related_conv on model.17.conv (Conv2d(140, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=11392]
32574 parameters will be pruned
-------------

2023-04-04 16:48:50.228 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.15.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.15.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 39, 51])>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.18.conv (Conv2d(51, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=3456]
[ <DEP: _prune_concat => prune_related_conv on model.17.conv (Conv2d(51, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=3456]
9882 parameters will be pruned
-------------

2023-04-04 16:48:50.242 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.17.conv (Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 102, 104, 105, 106, 108, 110, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125], NumPruned=2136]
[ <DEP: prune_conv => prune_batchnorm on model.17.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 102, 104, 105, 106, 108, 110, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 102, 104, 105, 106, 108, 110, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512])>, Index=[385, 386, 387, 393, 394, 395, 396, 398, 399, 402, 403, 404, 405, 407, 408, 409, 410, 412, 414, 415, 416, 417, 418, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 436, 439, 440, 441, 442, 443, 444, 447, 448, 449, 450, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 468, 471, 472, 473, 474, 475, 476, 479, 480, 481, 482, 483, 486, 488, 489, 490, 492, 494, 497, 498, 500, 501, 502, 503, 505, 507, 508, 509], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[385, 386, 387, 393, 394, 395, 396, 398, 399, 402, 403, 404, 405, 407, 408, 409, 410, 412, 414, 415, 416, 417, 418, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 436, 439, 440, 441, 442, 443, 444, 447, 448, 449, 450, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 468, 471, 472, 473, 474, 475, 476, 479, 480, 481, 482, 483, 486, 488, 489, 490, 492, 494, 497, 498, 500, 501, 502, 503, 505, 507, 508, 509], NumPruned=45568]
47882 parameters will be pruned
-------------

2023-04-04 16:48:50.244 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.17.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 23, 24, 26, 29, 31, 32, 34, 35, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.17.conv (Conv2d(24, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 23, 24, 26, 29, 31, 32, 34, 35, 37, 38], NumPruned=648]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 23, 24, 26, 29, 31, 32, 34, 35, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 423])>, Index=[385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 399, 400, 401, 402, 404, 407, 408, 410, 413, 415, 416, 418, 419, 421, 422], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(423, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 399, 400, 401, 402, 404, 407, 408, 410, 413, 415, 416, 418, 419, 421, 422], NumPruned=13824]
14526 parameters will be pruned
-------------

2023-04-04 16:48:50.258 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.18.conv (Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 55, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 73, 76, 77, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 94, 95, 100, 102, 104, 106, 108, 109, 110, 113, 114, 116, 117, 118, 121, 122, 123, 124, 125, 126], NumPruned=2136]
[ <DEP: prune_conv => prune_batchnorm on model.18.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 55, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 73, 76, 77, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 94, 95, 100, 102, 104, 106, 108, 109, 110, 113, 114, 116, 117, 118, 121, 122, 123, 124, 125, 126], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 55, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 73, 76, 77, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 94, 95, 100, 102, 104, 106, 108, 109, 110, 113, 114, 116, 117, 118, 121, 122, 123, 124, 125, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.19.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 55, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 73, 76, 77, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 94, 95, 100, 102, 104, 106, 108, 109, 110, 113, 114, 116, 117, 118, 121, 122, 123, 124, 125, 126], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 396])>, Index=[256, 257, 258, 259, 260, 261, 264, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 285, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 306, 307, 308, 311, 314, 315, 316, 317, 318, 320, 321, 323, 324, 325, 326, 328, 329, 332, 333, 335, 336, 337, 338, 339, 340, 343, 344, 345, 346, 348, 350, 351, 356, 358, 360, 362, 364, 365, 366, 369, 370, 372, 373, 374, 377, 378, 379, 380, 381, 382], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(396, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 260, 261, 264, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 285, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 306, 307, 308, 311, 314, 315, 316, 317, 318, 320, 321, 323, 324, 325, 326, 328, 329, 332, 333, 335, 336, 337, 338, 339, 340, 343, 344, 345, 346, 348, 350, 351, 356, 358, 360, 362, 364, 365, 366, 369, 370, 372, 373, 374, 377, 378, 379, 380, 381, 382], NumPruned=45568]
150410 parameters will be pruned
-------------

2023-04-04 16:48:50.259 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.18.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.18.conv (Conv2d(24, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36], NumPruned=648]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.19.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 295, 307])>, Index=[257, 258, 259, 260, 261, 262, 263, 267, 268, 269, 271, 272, 273, 276, 277, 278, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(307, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 259, 260, 261, 262, 263, 267, 268, 269, 271, 272, 273, 276, 277, 278, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292], NumPruned=13824]
45630 parameters will be pruned
-------------

2023-04-04 16:48:50.274 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.19.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 49, 50, 52, 53, 54, 55, 57, 58, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 109, 110, 112, 114, 118, 121, 122, 123, 124, 125, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.19.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 49, 50, 52, 53, 54, 55, 57, 58, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 109, 110, 112, 114, 118, 121, 122, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 49, 50, 52, 53, 54, 55, 57, 58, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 109, 110, 112, 114, 118, 121, 122, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.20.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 49, 50, 52, 53, 54, 55, 57, 58, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 109, 110, 112, 114, 118, 121, 122, 123, 124, 125, 126, 127], NumPruned=102528]
112318 parameters will be pruned
-------------

2023-04-04 16:48:50.275 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.19.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 19, 20, 21, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.19.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 19, 20, 21, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 19, 20, 21, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.20.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 19, 20, 21, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38], NumPruned=31104]
34074 parameters will be pruned
-------------

2023-04-04 16:48:50.276 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.20.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 55, 56, 58, 59, 63, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 96, 97, 99, 101, 103, 104, 105, 107, 108, 111, 112, 114, 116, 117, 118, 119, 121, 122, 123, 125, 126], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.20.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 4, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 55, 56, 58, 59, 63, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 96, 97, 99, 101, 103, 104, 105, 107, 108, 111, 112, 114, 116, 117, 118, 119, 121, 122, 123, 125, 126], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 4, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 55, 56, 58, 59, 63, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 96, 97, 99, 101, 103, 104, 105, 107, 108, 111, 112, 114, 116, 117, 118, 119, 121, 122, 123, 125, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.21.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 55, 56, 58, 59, 63, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 96, 97, 99, 101, 103, 104, 105, 107, 108, 111, 112, 114, 116, 117, 118, 119, 121, 122, 123, 125, 126], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 268, 280])>, Index=[128, 129, 132, 133, 134, 135, 137, 139, 141, 142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 164, 165, 166, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 181, 183, 184, 186, 187, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 208, 209, 210, 211, 213, 214, 216, 217, 218, 220, 221, 224, 225, 227, 229, 231, 232, 233, 235, 236, 239, 240, 242, 244, 245, 246, 247, 249, 250, 251, 253, 254], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(280, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 132, 133, 134, 135, 137, 139, 141, 142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 164, 165, 166, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 181, 183, 184, 186, 187, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 208, 209, 210, 211, 213, 214, 216, 217, 218, 220, 221, 224, 225, 227, 229, 231, 232, 233, 235, 236, 239, 240, 242, 244, 245, 246, 247, 249, 250, 251, 253, 254], NumPruned=45568]
157886 parameters will be pruned
-------------

2023-04-04 16:48:50.291 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.20.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 21, 23, 24, 25, 26, 30, 31, 33, 36, 37], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.20.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 21, 23, 24, 25, 26, 30, 31, 33, 36, 37], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 21, 23, 24, 25, 26, 30, 31, 33, 36, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.21.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 21, 23, 24, 25, 26, 30, 31, 33, 36, 37], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 167, 179, 191])>, Index=[128, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 146, 148, 149, 151, 152, 153, 154, 158, 159, 161, 164, 165], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(191, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 146, 148, 149, 151, 152, 153, 154, 158, 159, 161, 164, 165], NumPruned=13824]
47898 parameters will be pruned
-------------

2023-04-04 16:48:50.293 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.21.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 63, 65, 66, 68, 69, 70, 71, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 105, 108, 109, 110, 111, 112, 114, 115, 117, 120, 121, 123, 124, 126], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.21.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 63, 65, 66, 68, 69, 70, 71, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 105, 108, 109, 110, 111, 112, 114, 115, 117, 120, 121, 123, 124, 126], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 63, 65, 66, 68, 69, 70, 71, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 105, 108, 109, 110, 111, 112, 114, 115, 117, 120, 121, 123, 124, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.22.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 63, 65, 66, 68, 69, 70, 71, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 105, 108, 109, 110, 111, 112, 114, 115, 117, 120, 121, 123, 124, 126], NumPruned=102528]
112318 parameters will be pruned
-------------

2023-04-04 16:48:50.295 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.21.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 32, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.21.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 32, 36, 37, 38], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 32, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.22.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 32, 36, 37, 38], NumPruned=31104]
34074 parameters will be pruned
-------------

2023-04-04 16:48:50.306 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.22.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 65, 69, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 94, 96, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 112, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.22.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 65, 69, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 94, 96, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 112, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 65, 69, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 94, 96, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 112, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 140, 152, 164])>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 65, 69, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 94, 96, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 112, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(164, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 65, 69, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 94, 96, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 112, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127], NumPruned=45568]
55358 parameters will be pruned
-------------

2023-04-04 16:48:50.308 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.22.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.22.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 39, 51, 63, 75])>, Index=[2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(75, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33], NumPruned=13824]
16794 parameters will be pruned
-------------

2023-04-04 16:48:50.310 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.24.conv (Conv2d(48, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=17184]
[ <DEP: prune_conv => prune_batchnorm on model.24.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=716]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.66.conv (Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=45824]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.27.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=91648]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.26.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=91648]
247020 parameters will be pruned
-------------

2023-04-04 16:48:50.323 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.24.bn (BatchNorm2d(154, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=214]
[ <DEP: prune_batchnorm => prune_conv on model.24.conv (Conv2d(48, 154, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=5136]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.66.conv (Conv2d(154, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=13696]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.27.conv (Conv2d(154, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=27392]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.26.conv (Conv2d(154, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=27392]
73830 parameters will be pruned
-------------

2023-04-04 16:48:50.338 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.26.conv (Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 15, 18, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 74, 75, 76, 79, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 109, 110, 112, 113, 115, 118, 119, 121, 122, 123, 125, 126, 127, 129, 132, 134, 135, 136, 137, 139, 140, 141, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 162, 163, 165, 166, 168, 169, 173, 174, 175, 178, 180, 181, 182, 183, 184, 185, 186, 190, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 211, 215, 217, 218, 219, 220, 221, 222, 223, 225, 228, 229, 230, 231, 232, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 254, 255], NumPruned=8413]
[ <DEP: prune_conv => prune_batchnorm on model.26.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 15, 18, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 74, 75, 76, 79, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 109, 110, 112, 113, 115, 118, 119, 121, 122, 123, 125, 126, 127, 129, 132, 134, 135, 136, 137, 139, 140, 141, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 162, 163, 165, 166, 168, 169, 173, 174, 175, 178, 180, 181, 182, 183, 184, 185, 186, 190, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 211, 215, 217, 218, 219, 220, 221, 222, 223, 225, 228, 229, 230, 231, 232, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 15, 18, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 74, 75, 76, 79, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 109, 110, 112, 113, 115, 118, 119, 121, 122, 123, 125, 126, 127, 129, 132, 134, 135, 136, 137, 139, 140, 141, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 162, 163, 165, 166, 168, 169, 173, 174, 175, 178, 180, 181, 182, 183, 184, 185, 186, 190, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 211, 215, 217, 218, 219, 220, 221, 222, 223, 225, 228, 229, 230, 231, 232, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512])>, Index=[256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 268, 270, 271, 274, 276, 277, 278, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 294, 295, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 316, 317, 318, 319, 320, 321, 322, 323, 326, 327, 328, 330, 331, 332, 335, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 359, 360, 361, 362, 365, 366, 368, 369, 371, 374, 375, 377, 378, 379, 381, 382, 383, 385, 388, 390, 391, 392, 393, 395, 396, 397, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 418, 419, 421, 422, 424, 425, 429, 430, 431, 434, 436, 437, 438, 439, 440, 441, 442, 446, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467, 471, 473, 474, 475, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.31.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 268, 270, 271, 274, 276, 277, 278, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 294, 295, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 316, 317, 318, 319, 320, 321, 322, 323, 326, 327, 328, 330, 331, 332, 335, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 359, 360, 361, 362, 365, 366, 368, 369, 371, 374, 375, 377, 378, 379, 381, 382, 383, 385, 388, 390, 391, 392, 393, 395, 396, 397, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 418, 419, 421, 422, 424, 425, 429, 430, 431, 434, 436, 437, 438, 439, 440, 441, 442, 446, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467, 471, 473, 474, 475, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 510, 511], NumPruned=45824]
[ <DEP: _prune_concat => prune_related_conv on model.30.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 268, 270, 271, 274, 276, 277, 278, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 294, 295, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 316, 317, 318, 319, 320, 321, 322, 323, 326, 327, 328, 330, 331, 332, 335, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 359, 360, 361, 362, 365, 366, 368, 369, 371, 374, 375, 377, 378, 379, 381, 382, 383, 385, 388, 390, 391, 392, 393, 395, 396, 397, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 418, 419, 421, 422, 424, 425, 429, 430, 431, 434, 436, 437, 438, 439, 440, 441, 442, 446, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467, 471, 473, 474, 475, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 510, 511], NumPruned=45824]
100419 parameters will be pruned
-------------

2023-04-04 16:48:50.355 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.26.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 17, 20, 21, 22, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 55, 56, 58, 59, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.26.conv (Conv2d(47, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 17, 20, 21, 22, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 55, 56, 58, 59, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76], NumPruned=2491]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 17, 20, 21, 22, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 55, 56, 58, 59, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 333])>, Index=[257, 259, 260, 261, 262, 263, 264, 268, 269, 270, 271, 273, 276, 277, 278, 281, 282, 283, 284, 285, 288, 289, 290, 291, 293, 294, 297, 298, 300, 301, 302, 303, 304, 307, 308, 309, 311, 312, 314, 315, 317, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 332], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.31.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 259, 260, 261, 262, 263, 264, 268, 269, 270, 271, 273, 276, 277, 278, 281, 282, 283, 284, 285, 288, 289, 290, 291, 293, 294, 297, 298, 300, 301, 302, 303, 304, 307, 308, 309, 311, 312, 314, 315, 317, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 332], NumPruned=13568]
[ <DEP: _prune_concat => prune_related_conv on model.30.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 259, 260, 261, 262, 263, 264, 268, 269, 270, 271, 273, 276, 277, 278, 281, 282, 283, 284, 285, 288, 289, 290, 291, 293, 294, 297, 298, 300, 301, 302, 303, 304, 307, 308, 309, 311, 312, 314, 315, 317, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 332], NumPruned=13568]
29733 parameters will be pruned
-------------

2023-04-04 16:48:50.357 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.27.conv (Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 98, 103, 104, 105, 106, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 138, 139, 140, 142, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 155, 157, 158, 161, 164, 166, 167, 168, 169, 170, 172, 173, 175, 176, 177, 178, 179, 180, 182, 183, 185, 186, 187, 189, 190, 192, 193, 194, 196, 198, 199, 200, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 224, 228, 231, 232, 233, 234, 235, 237, 238, 240, 241, 242, 243, 244, 246, 247, 248, 250, 252, 254, 255], NumPruned=8413]
[ <DEP: prune_conv => prune_batchnorm on model.27.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 98, 103, 104, 105, 106, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 138, 139, 140, 142, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 155, 157, 158, 161, 164, 166, 167, 168, 169, 170, 172, 173, 175, 176, 177, 178, 179, 180, 182, 183, 185, 186, 187, 189, 190, 192, 193, 194, 196, 198, 199, 200, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 224, 228, 231, 232, 233, 234, 235, 237, 238, 240, 241, 242, 243, 244, 246, 247, 248, 250, 252, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 98, 103, 104, 105, 106, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 138, 139, 140, 142, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 155, 157, 158, 161, 164, 166, 167, 168, 169, 170, 172, 173, 175, 176, 177, 178, 179, 180, 182, 183, 185, 186, 187, 189, 190, 192, 193, 194, 196, 198, 199, 200, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 224, 228, 231, 232, 233, 234, 235, 237, 238, 240, 241, 242, 243, 244, 246, 247, 248, 250, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.28.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 98, 103, 104, 105, 106, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 138, 139, 140, 142, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 155, 157, 158, 161, 164, 166, 167, 168, 169, 170, 172, 173, 175, 176, 177, 178, 179, 180, 182, 183, 185, 186, 187, 189, 190, 192, 193, 194, 196, 198, 199, 200, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 224, 228, 231, 232, 233, 234, 235, 237, 238, 240, 241, 242, 243, 244, 246, 247, 248, 250, 252, 254, 255], NumPruned=412416]
421187 parameters will be pruned
-------------

2023-04-04 16:48:50.371 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.27.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 53, 54, 55, 62, 63, 64, 67, 69, 72, 73, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.27.conv (Conv2d(47, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 53, 54, 55, 62, 63, 64, 67, 69, 72, 73, 74, 75, 76], NumPruned=2491]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 53, 54, 55, 62, 63, 64, 67, 69, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.28.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 53, 54, 55, 62, 63, 64, 67, 69, 72, 73, 74, 75, 76], NumPruned=122112]
124709 parameters will be pruned
-------------

2023-04-04 16:48:50.372 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.28.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.28.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 280])>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.31.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=45824]
[ <DEP: _prune_concat => prune_related_conv on model.30.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=45824]
130670 parameters will be pruned
-------------

2023-04-04 16:48:50.387 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.28.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.28.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 77, 101])>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.31.conv (Conv2d(101, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=13568]
[ <DEP: _prune_concat => prune_related_conv on model.30.conv (Conv2d(101, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=13568]
38690 parameters will be pruned
-------------

2023-04-04 16:48:50.388 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.30.conv (Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 6, 7, 8, 12, 13, 14, 15, 16, 17, 22, 25, 26, 27, 31, 32, 33, 34, 36, 37, 41, 42, 44, 45, 46, 47, 51, 53, 54, 56, 57, 58, 59, 60, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 82, 83, 84, 85, 86, 88, 90, 92, 93, 94, 95, 98, 100, 102, 103, 104, 106, 107, 108, 111, 112, 113, 114, 115, 116, 122, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 136, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 175, 176, 177, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 202, 203, 204, 205, 207, 208, 209, 210, 211, 214, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 229, 231, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254], NumPruned=8592]
[ <DEP: prune_conv => prune_batchnorm on model.30.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 5, 6, 7, 8, 12, 13, 14, 15, 16, 17, 22, 25, 26, 27, 31, 32, 33, 34, 36, 37, 41, 42, 44, 45, 46, 47, 51, 53, 54, 56, 57, 58, 59, 60, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 82, 83, 84, 85, 86, 88, 90, 92, 93, 94, 95, 98, 100, 102, 103, 104, 106, 107, 108, 111, 112, 113, 114, 115, 116, 122, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 136, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 175, 176, 177, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 202, 203, 204, 205, 207, 208, 209, 210, 211, 214, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 229, 231, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 5, 6, 7, 8, 12, 13, 14, 15, 16, 17, 22, 25, 26, 27, 31, 32, 33, 34, 36, 37, 41, 42, 44, 45, 46, 47, 51, 53, 54, 56, 57, 58, 59, 60, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 82, 83, 84, 85, 86, 88, 90, 92, 93, 94, 95, 98, 100, 102, 103, 104, 106, 107, 108, 111, 112, 113, 114, 115, 116, 122, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 136, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 175, 176, 177, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 202, 203, 204, 205, 207, 208, 209, 210, 211, 214, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 229, 231, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 1024])>, Index=[768, 770, 771, 773, 774, 775, 776, 780, 781, 782, 783, 784, 785, 790, 793, 794, 795, 799, 800, 801, 802, 804, 805, 809, 810, 812, 813, 814, 815, 819, 821, 822, 824, 825, 826, 827, 828, 834, 835, 836, 837, 838, 839, 840, 841, 844, 845, 846, 847, 850, 851, 852, 853, 854, 856, 858, 860, 861, 862, 863, 866, 868, 870, 871, 872, 874, 875, 876, 879, 880, 881, 882, 883, 884, 890, 891, 893, 895, 896, 897, 898, 899, 900, 902, 903, 904, 906, 907, 908, 909, 910, 911, 913, 914, 916, 917, 918, 920, 921, 922, 923, 924, 925, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 943, 944, 945, 947, 948, 951, 952, 953, 954, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 968, 970, 971, 972, 973, 975, 976, 977, 978, 979, 982, 984, 985, 986, 987, 988, 989, 991, 992, 993, 994, 995, 997, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1011, 1012, 1013, 1014, 1016, 1017, 1018, 1019, 1020, 1021, 1022], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 770, 771, 773, 774, 775, 776, 780, 781, 782, 783, 784, 785, 790, 793, 794, 795, 799, 800, 801, 802, 804, 805, 809, 810, 812, 813, 814, 815, 819, 821, 822, 824, 825, 826, 827, 828, 834, 835, 836, 837, 838, 839, 840, 841, 844, 845, 846, 847, 850, 851, 852, 853, 854, 856, 858, 860, 861, 862, 863, 866, 868, 870, 871, 872, 874, 875, 876, 879, 880, 881, 882, 883, 884, 890, 891, 893, 895, 896, 897, 898, 899, 900, 902, 903, 904, 906, 907, 908, 909, 910, 911, 913, 914, 916, 917, 918, 920, 921, 922, 923, 924, 925, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 943, 944, 945, 947, 948, 951, 952, 953, 954, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 968, 970, 971, 972, 973, 975, 976, 977, 978, 979, 982, 984, 985, 986, 987, 988, 989, 991, 992, 993, 994, 995, 997, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1011, 1012, 1013, 1014, 1016, 1017, 1018, 1019, 1020, 1021, 1022], NumPruned=183296]
192246 parameters will be pruned
-------------

2023-04-04 16:48:50.404 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.30.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 6, 7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 72, 73, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.30.conv (Conv2d(48, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 6, 7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 72, 73, 76], NumPruned=2544]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 6, 7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 72, 73, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 845])>, Index=[768, 769, 770, 772, 774, 775, 778, 780, 781, 782, 783, 785, 788, 789, 790, 791, 793, 795, 796, 797, 798, 800, 801, 802, 803, 805, 806, 807, 808, 809, 812, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 831, 832, 833, 834, 836, 837, 840, 841, 844], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(845, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 769, 770, 772, 774, 775, 778, 780, 781, 782, 783, 785, 788, 789, 790, 791, 793, 795, 796, 797, 798, 800, 801, 802, 803, 805, 806, 807, 808, 809, 812, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 831, 832, 833, 834, 836, 837, 840, 841, 844], NumPruned=54272]
56922 parameters will be pruned
-------------

2023-04-04 16:48:50.407 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.31.conv (Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 69, 70, 73, 74, 75, 77, 79, 80, 83, 85, 86, 88, 92, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 114, 115, 116, 118, 119, 121, 123, 124, 126, 127, 128, 129, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 205, 206, 207, 208, 209, 212, 213, 214, 216, 217, 219, 221, 222, 223, 225, 228, 229, 233, 234, 235, 236, 237, 240, 241, 243, 246, 247, 248, 249, 250, 252, 253, 255], NumPruned=8592]
[ <DEP: prune_conv => prune_batchnorm on model.31.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 69, 70, 73, 74, 75, 77, 79, 80, 83, 85, 86, 88, 92, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 114, 115, 116, 118, 119, 121, 123, 124, 126, 127, 128, 129, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 205, 206, 207, 208, 209, 212, 213, 214, 216, 217, 219, 221, 222, 223, 225, 228, 229, 233, 234, 235, 236, 237, 240, 241, 243, 246, 247, 248, 249, 250, 252, 253, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 69, 70, 73, 74, 75, 77, 79, 80, 83, 85, 86, 88, 92, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 114, 115, 116, 118, 119, 121, 123, 124, 126, 127, 128, 129, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 205, 206, 207, 208, 209, 212, 213, 214, 216, 217, 219, 221, 222, 223, 225, 228, 229, 233, 234, 235, 236, 237, 240, 241, 243, 246, 247, 248, 249, 250, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.32.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 69, 70, 73, 74, 75, 77, 79, 80, 83, 85, 86, 88, 92, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 114, 115, 116, 118, 119, 121, 123, 124, 126, 127, 128, 129, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 205, 206, 207, 208, 209, 212, 213, 214, 216, 217, 219, 221, 222, 223, 225, 228, 229, 233, 234, 235, 236, 237, 240, 241, 243, 246, 247, 248, 249, 250, 252, 253, 255], NumPruned=412416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 792])>, Index=[514, 516, 518, 520, 521, 522, 523, 524, 525, 526, 528, 529, 532, 533, 534, 535, 536, 537, 538, 540, 541, 542, 543, 546, 547, 549, 550, 552, 553, 554, 555, 556, 557, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 575, 576, 577, 580, 581, 582, 585, 586, 587, 589, 591, 592, 595, 597, 598, 600, 604, 605, 608, 610, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 626, 627, 628, 630, 631, 633, 635, 636, 638, 639, 640, 641, 647, 648, 649, 650, 651, 652, 653, 654, 656, 657, 658, 659, 660, 661, 663, 664, 666, 667, 669, 670, 671, 672, 673, 675, 676, 677, 678, 679, 680, 681, 688, 689, 690, 691, 692, 693, 694, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 713, 714, 715, 716, 717, 718, 719, 720, 721, 724, 725, 726, 728, 729, 731, 733, 734, 735, 737, 740, 741, 745, 746, 747, 748, 749, 752, 753, 755, 758, 759, 760, 761, 762, 764, 765, 767], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(792, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[514, 516, 518, 520, 521, 522, 523, 524, 525, 526, 528, 529, 532, 533, 534, 535, 536, 537, 538, 540, 541, 542, 543, 546, 547, 549, 550, 552, 553, 554, 555, 556, 557, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 575, 576, 577, 580, 581, 582, 585, 586, 587, 589, 591, 592, 595, 597, 598, 600, 604, 605, 608, 610, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 626, 627, 628, 630, 631, 633, 635, 636, 638, 639, 640, 641, 647, 648, 649, 650, 651, 652, 653, 654, 656, 657, 658, 659, 660, 661, 663, 664, 666, 667, 669, 670, 671, 672, 673, 675, 676, 677, 678, 679, 680, 681, 688, 689, 690, 691, 692, 693, 694, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 713, 714, 715, 716, 717, 718, 719, 720, 721, 724, 725, 726, 728, 729, 731, 733, 734, 735, 737, 740, 741, 745, 746, 747, 748, 749, 752, 753, 755, 758, 759, 760, 761, 762, 764, 765, 767], NumPruned=183296]
604662 parameters will be pruned
-------------

2023-04-04 16:48:50.420 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.31.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 27, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76], NumPruned=108]
[ <DEP: prune_batchnorm => prune_conv on model.31.conv (Conv2d(48, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 27, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76], NumPruned=2592]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 27, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.32.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 27, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76], NumPruned=124416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 589, 613])>, Index=[512, 513, 514, 515, 517, 518, 520, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 536, 539, 542, 543, 544, 545, 547, 548, 550, 551, 552, 553, 554, 556, 557, 559, 560, 562, 563, 565, 566, 567, 568, 571, 572, 573, 575, 576, 577, 579, 580, 583, 584, 585, 586, 587, 588], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(613, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 513, 514, 515, 517, 518, 520, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 536, 539, 542, 543, 544, 545, 547, 548, 550, 551, 552, 553, 554, 556, 557, 559, 560, 562, 563, 565, 566, 567, 568, 571, 572, 573, 575, 576, 577, 579, 580, 583, 584, 585, 586, 587, 588], NumPruned=55296]
182412 parameters will be pruned
-------------

2023-04-04 16:48:50.423 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.32.conv (Conv2d(23, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 29, 30, 31, 32, 34, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 63, 64, 65, 67, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 88, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 142, 143, 144, 145, 147, 149, 150, 153, 155, 156, 157, 158, 159, 163, 164, 166, 167, 168, 170, 173, 174, 175, 176, 177, 179, 180, 182, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 198, 200, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 214, 215, 216, 218, 220, 222, 227, 230, 231, 232, 233, 236, 237, 238, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=37053]
[ <DEP: prune_conv => prune_batchnorm on model.32.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 29, 30, 31, 32, 34, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 63, 64, 65, 67, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 88, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 142, 143, 144, 145, 147, 149, 150, 153, 155, 156, 157, 158, 159, 163, 164, 166, 167, 168, 170, 173, 174, 175, 176, 177, 179, 180, 182, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 198, 200, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 214, 215, 216, 218, 220, 222, 227, 230, 231, 232, 233, 236, 237, 238, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 29, 30, 31, 32, 34, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 63, 64, 65, 67, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 88, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 142, 143, 144, 145, 147, 149, 150, 153, 155, 156, 157, 158, 159, 163, 164, 166, 167, 168, 170, 173, 174, 175, 176, 177, 179, 180, 182, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 198, 200, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 214, 215, 216, 218, 220, 222, 227, 230, 231, 232, 233, 236, 237, 238, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.33.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 29, 30, 31, 32, 34, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 63, 64, 65, 67, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 88, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 142, 143, 144, 145, 147, 149, 150, 153, 155, 156, 157, 158, 159, 163, 164, 166, 167, 168, 170, 173, 174, 175, 176, 177, 179, 180, 182, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 198, 200, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 214, 215, 216, 218, 220, 222, 227, 230, 231, 232, 233, 236, 237, 238, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=412416]
449827 parameters will be pruned
-------------

2023-04-04 16:48:50.433 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.32.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 31, 32, 33, 34, 35, 37, 38, 39, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 74], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.32.conv (Conv2d(23, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 31, 32, 33, 34, 35, 37, 38, 39, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 74], NumPruned=10971]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 31, 32, 33, 34, 35, 37, 38, 39, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 74], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.33.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 31, 32, 33, 34, 35, 37, 38, 39, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 74], NumPruned=122112]
133189 parameters will be pruned
-------------

2023-04-04 16:48:50.435 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.33.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 5, 6, 7, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 84, 86, 88, 89, 92, 93, 94, 97, 99, 102, 103, 104, 106, 107, 108, 110, 113, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 141, 143, 145, 146, 147, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 162, 163, 166, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 187, 188, 189, 191, 192, 193, 195, 197, 199, 200, 202, 204, 205, 206, 207, 208, 209, 210, 212, 215, 216, 218, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 237, 239, 242, 243, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.33.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 5, 6, 7, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 84, 86, 88, 89, 92, 93, 94, 97, 99, 102, 103, 104, 106, 107, 108, 110, 113, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 141, 143, 145, 146, 147, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 162, 163, 166, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 187, 188, 189, 191, 192, 193, 195, 197, 199, 200, 202, 204, 205, 206, 207, 208, 209, 210, 212, 215, 216, 218, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 237, 239, 242, 243, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 5, 6, 7, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 84, 86, 88, 89, 92, 93, 94, 97, 99, 102, 103, 104, 106, 107, 108, 110, 113, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 141, 143, 145, 146, 147, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 162, 163, 166, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 187, 188, 189, 191, 192, 193, 195, 197, 199, 200, 202, 204, 205, 206, 207, 208, 209, 210, 212, 215, 216, 218, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 237, 239, 242, 243, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.34.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 5, 6, 7, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 84, 86, 88, 89, 92, 93, 94, 97, 99, 102, 103, 104, 106, 107, 108, 110, 113, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 141, 143, 145, 146, 147, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 162, 163, 166, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 187, 188, 189, 191, 192, 193, 195, 197, 199, 200, 202, 204, 205, 206, 207, 208, 209, 210, 212, 215, 216, 218, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 237, 239, 242, 243, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=412416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 535, 559])>, Index=[257, 261, 262, 263, 265, 266, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 284, 285, 287, 290, 291, 292, 293, 295, 296, 298, 299, 300, 301, 303, 304, 305, 306, 307, 308, 310, 312, 313, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 342, 344, 345, 348, 349, 350, 353, 355, 358, 359, 360, 362, 363, 364, 366, 369, 372, 373, 374, 375, 378, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 394, 395, 397, 399, 401, 402, 403, 405, 406, 407, 409, 411, 412, 413, 414, 416, 417, 418, 419, 422, 424, 425, 426, 427, 428, 429, 430, 432, 433, 434, 435, 437, 438, 439, 443, 444, 445, 447, 448, 449, 451, 453, 455, 456, 458, 460, 461, 462, 463, 464, 465, 466, 468, 471, 472, 474, 476, 478, 479, 480, 481, 483, 484, 485, 486, 487, 489, 490, 492, 493, 495, 498, 499, 502, 503, 504, 505, 506, 508, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(559, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 261, 262, 263, 265, 266, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 284, 285, 287, 290, 291, 292, 293, 295, 296, 298, 299, 300, 301, 303, 304, 305, 306, 307, 308, 310, 312, 313, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 342, 344, 345, 348, 349, 350, 353, 355, 358, 359, 360, 362, 363, 364, 366, 369, 372, 373, 374, 375, 378, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 394, 395, 397, 399, 401, 402, 403, 405, 406, 407, 409, 411, 412, 413, 414, 416, 417, 418, 419, 422, 424, 425, 426, 427, 428, 429, 430, 432, 433, 434, 435, 437, 438, 439, 443, 444, 445, 447, 448, 449, 451, 453, 455, 456, 458, 460, 461, 462, 463, 464, 465, 466, 468, 471, 472, 474, 476, 478, 479, 480, 481, 483, 484, 485, 486, 487, 489, 490, 492, 493, 495, 498, 499, 502, 503, 504, 505, 506, 508, 509, 510, 511], NumPruned=183296]
634734 parameters will be pruned
-------------

2023-04-04 16:48:50.451 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.33.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 17, 19, 20, 21, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 57, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.33.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 17, 19, 20, 21, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 57, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 17, 19, 20, 21, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 57, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.34.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 17, 19, 20, 21, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 57, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76], NumPruned=122112]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 333, 356, 380])>, Index=[256, 258, 259, 260, 261, 262, 264, 265, 266, 268, 269, 270, 273, 275, 276, 277, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 306, 307, 313, 316, 318, 319, 320, 321, 322, 324, 325, 326, 327, 329, 330, 331, 332], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(380, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 258, 259, 260, 261, 262, 264, 265, 266, 268, 269, 270, 273, 275, 276, 277, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 306, 307, 313, 316, 318, 319, 320, 321, 322, 324, 325, 326, 327, 329, 330, 331, 332], NumPruned=54272]
187938 parameters will be pruned
-------------

2023-04-04 16:48:50.453 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.34.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 8, 10, 11, 12, 14, 15, 17, 18, 19, 20, 23, 25, 26, 27, 28, 30, 32, 33, 38, 39, 41, 42, 43, 44, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 118, 120, 123, 124, 126, 127, 128, 129, 130, 131, 134, 135, 137, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 181, 184, 185, 186, 188, 189, 190, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 220, 221, 225, 227, 229, 230, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.34.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 8, 10, 11, 12, 14, 15, 17, 18, 19, 20, 23, 25, 26, 27, 28, 30, 32, 33, 38, 39, 41, 42, 43, 44, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 118, 120, 123, 124, 126, 127, 128, 129, 130, 131, 134, 135, 137, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 181, 184, 185, 186, 188, 189, 190, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 220, 221, 225, 227, 229, 230, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 8, 10, 11, 12, 14, 15, 17, 18, 19, 20, 23, 25, 26, 27, 28, 30, 32, 33, 38, 39, 41, 42, 43, 44, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 118, 120, 123, 124, 126, 127, 128, 129, 130, 131, 134, 135, 137, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 181, 184, 185, 186, 188, 189, 190, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 220, 221, 225, 227, 229, 230, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.35.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 8, 10, 11, 12, 14, 15, 17, 18, 19, 20, 23, 25, 26, 27, 28, 30, 32, 33, 38, 39, 41, 42, 43, 44, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 118, 120, 123, 124, 126, 127, 128, 129, 130, 131, 134, 135, 137, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 181, 184, 185, 186, 188, 189, 190, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 220, 221, 225, 227, 229, 230, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=412416]
451438 parameters will be pruned
-------------

2023-04-04 16:48:50.466 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.34.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 74, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.34.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 74, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 74, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.35.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 74, 76], NumPruned=122112]
133666 parameters will be pruned
-------------

2023-04-04 16:48:50.467 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.35.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 27, 28, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61, 63, 65, 67, 68, 69, 71, 75, 76, 77, 78, 81, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 182, 183, 184, 185, 186, 187, 191, 192, 193, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 209, 212, 213, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 235, 236, 238, 240, 242, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.35.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 27, 28, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61, 63, 65, 67, 68, 69, 71, 75, 76, 77, 78, 81, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 182, 183, 184, 185, 186, 187, 191, 192, 193, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 209, 212, 213, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 235, 236, 238, 240, 242, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 27, 28, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61, 63, 65, 67, 68, 69, 71, 75, 76, 77, 78, 81, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 182, 183, 184, 185, 186, 187, 191, 192, 193, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 209, 212, 213, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 235, 236, 238, 240, 242, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 280, 303, 327])>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 27, 28, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61, 63, 65, 67, 68, 69, 71, 75, 76, 77, 78, 81, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 182, 183, 184, 185, 186, 187, 191, 192, 193, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 209, 212, 213, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 235, 236, 238, 240, 242, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(327, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 27, 28, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61, 63, 65, 67, 68, 69, 71, 75, 76, 77, 78, 81, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 182, 183, 184, 185, 186, 187, 191, 192, 193, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 209, 212, 213, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 235, 236, 238, 240, 242, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=183296]
222318 parameters will be pruned
-------------

2023-04-04 16:48:50.482 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.35.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.35.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 77, 101, 124, 148])>, Index=[2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(148, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76], NumPruned=54272]
65826 parameters will be pruned
-------------

2023-04-04 16:48:50.484 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.37.conv (Conv2d(95, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=68020]
[ <DEP: prune_conv => prune_batchnorm on model.37.bn (BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=1432]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.54.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=183296]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.40.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=366592]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.39.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=366592]
985932 parameters will be pruned
-------------

2023-04-04 16:48:50.500 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.37.bn (BatchNorm2d(308, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=430]
[ <DEP: prune_batchnorm => prune_conv on model.37.conv (Conv2d(95, 308, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=20425]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.54.conv (Conv2d(308, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=55040]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.40.conv (Conv2d(308, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=110080]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.39.conv (Conv2d(308, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=110080]
296055 parameters will be pruned
-------------

2023-04-04 16:48:50.514 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.39.conv (Conv2d(93, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 30, 32, 34, 35, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 66, 67, 68, 69, 71, 76, 82, 83, 85, 88, 90, 91, 93, 94, 95, 97, 98, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 120, 122, 124, 126, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 147, 148, 149, 150, 152, 153, 155, 156, 157, 159, 160, 161, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 176, 177, 179, 180, 181, 182, 185, 186, 188, 192, 195, 196, 198, 200, 201, 203, 204, 206, 208, 209, 210, 211, 213, 214, 216, 217, 218, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 231, 233, 234, 237, 238, 239, 240, 241, 244, 245, 247, 249, 251, 252, 253, 254, 256, 257, 258, 259, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 291, 292, 293, 294, 295, 297, 298, 300, 301, 303, 305, 306, 307, 308, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 332, 333, 335, 336, 339, 340, 341, 342, 343, 345, 346, 349, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 364, 365, 366, 368, 370, 371, 372, 373, 376, 377, 378, 379, 381, 384, 385, 387, 389, 391, 392, 393, 394, 395, 396, 397, 399, 401, 402, 404, 405, 407, 409, 411, 412, 413, 414, 415, 417, 420, 421, 422, 423, 424, 426, 427, 429, 430, 431, 432, 433, 434, 435, 436, 438, 440, 441, 442, 445, 446, 447, 448, 450, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 482, 484, 487, 488, 491, 494, 495, 496, 497, 498, 499, 500, 501, 503, 504, 505, 506, 507, 508, 511], NumPruned=33294]
[ <DEP: prune_conv => prune_batchnorm on model.39.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 30, 32, 34, 35, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 66, 67, 68, 69, 71, 76, 82, 83, 85, 88, 90, 91, 93, 94, 95, 97, 98, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 120, 122, 124, 126, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 147, 148, 149, 150, 152, 153, 155, 156, 157, 159, 160, 161, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 176, 177, 179, 180, 181, 182, 185, 186, 188, 192, 195, 196, 198, 200, 201, 203, 204, 206, 208, 209, 210, 211, 213, 214, 216, 217, 218, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 231, 233, 234, 237, 238, 239, 240, 241, 244, 245, 247, 249, 251, 252, 253, 254, 256, 257, 258, 259, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 291, 292, 293, 294, 295, 297, 298, 300, 301, 303, 305, 306, 307, 308, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 332, 333, 335, 336, 339, 340, 341, 342, 343, 345, 346, 349, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 364, 365, 366, 368, 370, 371, 372, 373, 376, 377, 378, 379, 381, 384, 385, 387, 389, 391, 392, 393, 394, 395, 396, 397, 399, 401, 402, 404, 405, 407, 409, 411, 412, 413, 414, 415, 417, 420, 421, 422, 423, 424, 426, 427, 429, 430, 431, 432, 433, 434, 435, 436, 438, 440, 441, 442, 445, 446, 447, 448, 450, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 482, 484, 487, 488, 491, 494, 495, 496, 497, 498, 499, 500, 501, 503, 504, 505, 506, 507, 508, 511], NumPruned=716]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 30, 32, 34, 35, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 66, 67, 68, 69, 71, 76, 82, 83, 85, 88, 90, 91, 93, 94, 95, 97, 98, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 120, 122, 124, 126, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 147, 148, 149, 150, 152, 153, 155, 156, 157, 159, 160, 161, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 176, 177, 179, 180, 181, 182, 185, 186, 188, 192, 195, 196, 198, 200, 201, 203, 204, 206, 208, 209, 210, 211, 213, 214, 216, 217, 218, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 231, 233, 234, 237, 238, 239, 240, 241, 244, 245, 247, 249, 251, 252, 253, 254, 256, 257, 258, 259, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 291, 292, 293, 294, 295, 297, 298, 300, 301, 303, 305, 306, 307, 308, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 332, 333, 335, 336, 339, 340, 341, 342, 343, 345, 346, 349, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 364, 365, 366, 368, 370, 371, 372, 373, 376, 377, 378, 379, 381, 384, 385, 387, 389, 391, 392, 393, 394, 395, 396, 397, 399, 401, 402, 404, 405, 407, 409, 411, 412, 413, 414, 415, 417, 420, 421, 422, 423, 424, 426, 427, 429, 430, 431, 432, 433, 434, 435, 436, 438, 440, 441, 442, 445, 446, 447, 448, 450, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 482, 484, 487, 488, 491, 494, 495, 496, 497, 498, 499, 500, 501, 503, 504, 505, 506, 507, 508, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 512, 1024])>, Index=[512, 514, 515, 516, 517, 518, 519, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 534, 535, 537, 538, 540, 541, 542, 544, 546, 547, 553, 554, 555, 556, 557, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 575, 576, 578, 579, 580, 581, 583, 588, 594, 595, 597, 600, 602, 603, 605, 606, 607, 609, 610, 612, 613, 614, 615, 617, 618, 619, 620, 621, 622, 625, 626, 627, 628, 629, 630, 632, 634, 636, 638, 639, 643, 644, 645, 646, 647, 648, 649, 650, 651, 654, 655, 659, 660, 661, 662, 664, 665, 667, 668, 669, 671, 672, 673, 676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 688, 689, 691, 692, 693, 694, 697, 698, 700, 704, 707, 708, 710, 712, 713, 715, 716, 718, 720, 721, 722, 723, 725, 726, 728, 729, 730, 731, 732, 733, 734, 736, 738, 739, 740, 741, 742, 743, 745, 746, 749, 750, 751, 752, 753, 756, 757, 759, 761, 763, 764, 765, 766, 768, 769, 770, 771, 774, 775, 777, 778, 779, 780, 781, 782, 783, 784, 785, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 798, 799, 800, 801, 803, 804, 805, 806, 807, 809, 810, 812, 813, 815, 817, 818, 819, 820, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 844, 845, 847, 848, 851, 852, 853, 854, 855, 857, 858, 861, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 876, 877, 878, 880, 882, 883, 884, 885, 888, 889, 890, 891, 893, 896, 897, 899, 901, 903, 904, 905, 906, 907, 908, 909, 911, 913, 914, 916, 917, 919, 921, 923, 924, 925, 926, 927, 929, 932, 933, 934, 935, 936, 938, 939, 941, 942, 943, 944, 945, 946, 947, 948, 950, 952, 953, 954, 957, 958, 959, 960, 962, 964, 966, 967, 968, 969, 970, 972, 973, 974, 975, 976, 977, 978, 981, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 994, 996, 999, 1000, 1003, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1015, 1016, 1017, 1018, 1019, 1020, 1023], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.44.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 514, 515, 516, 517, 518, 519, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 534, 535, 537, 538, 540, 541, 542, 544, 546, 547, 553, 554, 555, 556, 557, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 575, 576, 578, 579, 580, 581, 583, 588, 594, 595, 597, 600, 602, 603, 605, 606, 607, 609, 610, 612, 613, 614, 615, 617, 618, 619, 620, 621, 622, 625, 626, 627, 628, 629, 630, 632, 634, 636, 638, 639, 643, 644, 645, 646, 647, 648, 649, 650, 651, 654, 655, 659, 660, 661, 662, 664, 665, 667, 668, 669, 671, 672, 673, 676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 688, 689, 691, 692, 693, 694, 697, 698, 700, 704, 707, 708, 710, 712, 713, 715, 716, 718, 720, 721, 722, 723, 725, 726, 728, 729, 730, 731, 732, 733, 734, 736, 738, 739, 740, 741, 742, 743, 745, 746, 749, 750, 751, 752, 753, 756, 757, 759, 761, 763, 764, 765, 766, 768, 769, 770, 771, 774, 775, 777, 778, 779, 780, 781, 782, 783, 784, 785, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 798, 799, 800, 801, 803, 804, 805, 806, 807, 809, 810, 812, 813, 815, 817, 818, 819, 820, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 844, 845, 847, 848, 851, 852, 853, 854, 855, 857, 858, 861, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 876, 877, 878, 880, 882, 883, 884, 885, 888, 889, 890, 891, 893, 896, 897, 899, 901, 903, 904, 905, 906, 907, 908, 909, 911, 913, 914, 916, 917, 919, 921, 923, 924, 925, 926, 927, 929, 932, 933, 934, 935, 936, 938, 939, 941, 942, 943, 944, 945, 946, 947, 948, 950, 952, 953, 954, 957, 958, 959, 960, 962, 964, 966, 967, 968, 969, 970, 972, 973, 974, 975, 976, 977, 978, 981, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 994, 996, 999, 1000, 1003, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1015, 1016, 1017, 1018, 1019, 1020, 1023], NumPruned=91648]
[ <DEP: _prune_concat => prune_related_conv on model.43.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 514, 515, 516, 517, 518, 519, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 534, 535, 537, 538, 540, 541, 542, 544, 546, 547, 553, 554, 555, 556, 557, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 575, 576, 578, 579, 580, 581, 583, 588, 594, 595, 597, 600, 602, 603, 605, 606, 607, 609, 610, 612, 613, 614, 615, 617, 618, 619, 620, 621, 622, 625, 626, 627, 628, 629, 630, 632, 634, 636, 638, 639, 643, 644, 645, 646, 647, 648, 649, 650, 651, 654, 655, 659, 660, 661, 662, 664, 665, 667, 668, 669, 671, 672, 673, 676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 688, 689, 691, 692, 693, 694, 697, 698, 700, 704, 707, 708, 710, 712, 713, 715, 716, 718, 720, 721, 722, 723, 725, 726, 728, 729, 730, 731, 732, 733, 734, 736, 738, 739, 740, 741, 742, 743, 745, 746, 749, 750, 751, 752, 753, 756, 757, 759, 761, 763, 764, 765, 766, 768, 769, 770, 771, 774, 775, 777, 778, 779, 780, 781, 782, 783, 784, 785, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 798, 799, 800, 801, 803, 804, 805, 806, 807, 809, 810, 812, 813, 815, 817, 818, 819, 820, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 844, 845, 847, 848, 851, 852, 853, 854, 855, 857, 858, 861, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 876, 877, 878, 880, 882, 883, 884, 885, 888, 889, 890, 891, 893, 896, 897, 899, 901, 903, 904, 905, 906, 907, 908, 909, 911, 913, 914, 916, 917, 919, 921, 923, 924, 925, 926, 927, 929, 932, 933, 934, 935, 936, 938, 939, 941, 942, 943, 944, 945, 946, 947, 948, 950, 952, 953, 954, 957, 958, 959, 960, 962, 964, 966, 967, 968, 969, 970, 972, 973, 974, 975, 976, 977, 978, 981, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 994, 996, 999, 1000, 1003, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1015, 1016, 1017, 1018, 1019, 1020, 1023], NumPruned=91648]
217306 parameters will be pruned
-------------

2023-04-04 16:48:50.531 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.39.bn (BatchNorm2d(154, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 17, 18, 20, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 44, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 74, 75, 79, 80, 82, 84, 85, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 111, 112, 113, 115, 117, 119, 120, 121, 122, 125, 127, 129, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 152], NumPruned=214]
[ <DEP: prune_batchnorm => prune_conv on model.39.conv (Conv2d(93, 154, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 17, 18, 20, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 44, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 74, 75, 79, 80, 82, 84, 85, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 111, 112, 113, 115, 117, 119, 120, 121, 122, 125, 127, 129, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 152], NumPruned=9951]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 17, 18, 20, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 44, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 74, 75, 79, 80, 82, 84, 85, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 111, 112, 113, 115, 117, 119, 120, 121, 122, 125, 127, 129, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 152], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 512, 666])>, Index=[512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 524, 526, 527, 529, 530, 532, 535, 536, 537, 538, 541, 542, 543, 544, 545, 546, 548, 549, 550, 552, 554, 556, 557, 558, 559, 563, 564, 565, 566, 568, 569, 570, 572, 573, 574, 576, 577, 578, 579, 582, 583, 584, 586, 587, 591, 592, 594, 596, 597, 600, 601, 602, 604, 605, 606, 607, 608, 609, 611, 612, 613, 614, 616, 617, 618, 619, 620, 622, 623, 624, 625, 627, 629, 631, 632, 633, 634, 637, 639, 641, 643, 644, 645, 646, 647, 648, 650, 651, 652, 654, 655, 657, 658, 659, 660, 661, 664], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.44.conv (Conv2d(666, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 524, 526, 527, 529, 530, 532, 535, 536, 537, 538, 541, 542, 543, 544, 545, 546, 548, 549, 550, 552, 554, 556, 557, 558, 559, 563, 564, 565, 566, 568, 569, 570, 572, 573, 574, 576, 577, 578, 579, 582, 583, 584, 586, 587, 591, 592, 594, 596, 597, 600, 601, 602, 604, 605, 606, 607, 608, 609, 611, 612, 613, 614, 616, 617, 618, 619, 620, 622, 623, 624, 625, 627, 629, 631, 632, 633, 634, 637, 639, 641, 643, 644, 645, 646, 647, 648, 650, 651, 652, 654, 655, 657, 658, 659, 660, 661, 664], NumPruned=27392]
[ <DEP: _prune_concat => prune_related_conv on model.43.conv (Conv2d(666, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 524, 526, 527, 529, 530, 532, 535, 536, 537, 538, 541, 542, 543, 544, 545, 546, 548, 549, 550, 552, 554, 556, 557, 558, 559, 563, 564, 565, 566, 568, 569, 570, 572, 573, 574, 576, 577, 578, 579, 582, 583, 584, 586, 587, 591, 592, 594, 596, 597, 600, 601, 602, 604, 605, 606, 607, 608, 609, 611, 612, 613, 614, 616, 617, 618, 619, 620, 622, 623, 624, 625, 627, 629, 631, 632, 633, 634, 637, 639, 641, 643, 644, 645, 646, 647, 648, 650, 651, 652, 654, 655, 657, 658, 659, 660, 661, 664], NumPruned=27392]
64949 parameters will be pruned
-------------

2023-04-04 16:48:50.533 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.40.conv (Conv2d(93, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 23, 25, 29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 44, 45, 47, 50, 51, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 105, 106, 110, 111, 113, 114, 115, 117, 118, 121, 123, 124, 127, 128, 129, 130, 132, 133, 134, 136, 137, 140, 141, 142, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 156, 159, 161, 162, 164, 165, 166, 169, 170, 171, 172, 173, 174, 177, 179, 182, 183, 185, 186, 190, 191, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 208, 210, 211, 212, 213, 215, 216, 218, 219, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 246, 247, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 263, 266, 267, 270, 274, 275, 276, 277, 278, 280, 284, 285, 286, 287, 289, 290, 291, 292, 295, 296, 297, 298, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 315, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 363, 364, 365, 366, 368, 369, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 382, 384, 385, 387, 389, 392, 393, 394, 397, 399, 401, 402, 403, 404, 405, 406, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 423, 425, 426, 427, 428, 430, 433, 434, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 472, 474, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 492, 494, 495, 497, 499, 500, 501, 503, 504, 505, 509, 510, 511], NumPruned=33294]
[ <DEP: prune_conv => prune_batchnorm on model.40.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 23, 25, 29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 44, 45, 47, 50, 51, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 105, 106, 110, 111, 113, 114, 115, 117, 118, 121, 123, 124, 127, 128, 129, 130, 132, 133, 134, 136, 137, 140, 141, 142, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 156, 159, 161, 162, 164, 165, 166, 169, 170, 171, 172, 173, 174, 177, 179, 182, 183, 185, 186, 190, 191, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 208, 210, 211, 212, 213, 215, 216, 218, 219, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 246, 247, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 263, 266, 267, 270, 274, 275, 276, 277, 278, 280, 284, 285, 286, 287, 289, 290, 291, 292, 295, 296, 297, 298, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 315, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 363, 364, 365, 366, 368, 369, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 382, 384, 385, 387, 389, 392, 393, 394, 397, 399, 401, 402, 403, 404, 405, 406, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 423, 425, 426, 427, 428, 430, 433, 434, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 472, 474, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 492, 494, 495, 497, 499, 500, 501, 503, 504, 505, 509, 510, 511], NumPruned=716]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 23, 25, 29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 44, 45, 47, 50, 51, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 105, 106, 110, 111, 113, 114, 115, 117, 118, 121, 123, 124, 127, 128, 129, 130, 132, 133, 134, 136, 137, 140, 141, 142, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 156, 159, 161, 162, 164, 165, 166, 169, 170, 171, 172, 173, 174, 177, 179, 182, 183, 185, 186, 190, 191, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 208, 210, 211, 212, 213, 215, 216, 218, 219, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 246, 247, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 263, 266, 267, 270, 274, 275, 276, 277, 278, 280, 284, 285, 286, 287, 289, 290, 291, 292, 295, 296, 297, 298, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 315, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 363, 364, 365, 366, 368, 369, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 382, 384, 385, 387, 389, 392, 393, 394, 397, 399, 401, 402, 403, 404, 405, 406, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 423, 425, 426, 427, 428, 430, 433, 434, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 472, 474, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 492, 494, 495, 497, 499, 500, 501, 503, 504, 505, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.41.conv (Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 23, 25, 29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 44, 45, 47, 50, 51, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 105, 106, 110, 111, 113, 114, 115, 117, 118, 121, 123, 124, 127, 128, 129, 130, 132, 133, 134, 136, 137, 140, 141, 142, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 156, 159, 161, 162, 164, 165, 166, 169, 170, 171, 172, 173, 174, 177, 179, 182, 183, 185, 186, 190, 191, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 208, 210, 211, 212, 213, 215, 216, 218, 219, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 246, 247, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 263, 266, 267, 270, 274, 275, 276, 277, 278, 280, 284, 285, 286, 287, 289, 290, 291, 292, 295, 296, 297, 298, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 315, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 363, 364, 365, 366, 368, 369, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 382, 384, 385, 387, 389, 392, 393, 394, 397, 399, 401, 402, 403, 404, 405, 406, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 423, 425, 426, 427, 428, 430, 433, 434, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 472, 474, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 492, 494, 495, 497, 499, 500, 501, 503, 504, 505, 509, 510, 511], NumPruned=1649664]
1683674 parameters will be pruned
-------------

2023-04-04 16:48:50.547 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.40.bn (BatchNorm2d(154, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 17, 19, 21, 24, 27, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 97, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 123, 125, 128, 131, 132, 135, 137, 139, 140, 142, 144, 145, 146, 147, 149, 151, 152, 153], NumPruned=216]
[ <DEP: prune_batchnorm => prune_conv on model.40.conv (Conv2d(93, 154, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 17, 19, 21, 24, 27, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 97, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 123, 125, 128, 131, 132, 135, 137, 139, 140, 142, 144, 145, 146, 147, 149, 151, 152, 153], NumPruned=10044]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 17, 19, 21, 24, 27, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 97, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 123, 125, 128, 131, 132, 135, 137, 139, 140, 142, 144, 145, 146, 147, 149, 151, 152, 153], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.41.conv (Conv2d(154, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 17, 19, 21, 24, 27, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 97, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 123, 125, 128, 131, 132, 135, 137, 139, 140, 142, 144, 145, 146, 147, 149, 151, 152, 153], NumPruned=497664]
507924 parameters will be pruned
-------------

2023-04-04 16:48:50.549 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.41.conv (Conv2d(46, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=148212]
[ <DEP: prune_conv => prune_batchnorm on model.41.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=716]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 512, 559])>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.44.conv (Conv2d(559, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=91648]
[ <DEP: _prune_concat => prune_related_conv on model.43.conv (Conv2d(559, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=91648]
332224 parameters will be pruned
-------------

2023-04-04 16:48:50.560 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.41.bn (BatchNorm2d(154, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=214]
[ <DEP: prune_batchnorm => prune_conv on model.41.conv (Conv2d(46, 154, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=44298]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 154, 201])>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.44.conv (Conv2d(201, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=27392]
[ <DEP: _prune_concat => prune_related_conv on model.43.conv (Conv2d(201, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=27392]
99296 parameters will be pruned
-------------

2023-04-04 16:48:50.562 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.43.conv (Conv2d(94, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 34, 35, 36, 37, 38, 40, 43, 44, 45, 46, 47, 48, 50, 51, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 81, 82, 83, 84, 89, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 106, 107, 110, 111, 116, 121, 122, 123, 124, 126, 127, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 152, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 183, 184, 185, 186, 187, 189, 191, 193, 194, 195, 197, 198, 200, 201, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 219, 220, 221, 222, 223, 224, 227, 228, 229, 231, 232, 235, 236, 238, 239, 243, 245, 246, 247, 248, 249, 250, 251, 252, 254], NumPruned=16826]
[ <DEP: prune_conv => prune_batchnorm on model.43.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 34, 35, 36, 37, 38, 40, 43, 44, 45, 46, 47, 48, 50, 51, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 81, 82, 83, 84, 89, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 106, 107, 110, 111, 116, 121, 122, 123, 124, 126, 127, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 152, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 183, 184, 185, 186, 187, 189, 191, 193, 194, 195, 197, 198, 200, 201, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 219, 220, 221, 222, 223, 224, 227, 228, 229, 231, 232, 235, 236, 238, 239, 243, 245, 246, 247, 248, 249, 250, 251, 252, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 34, 35, 36, 37, 38, 40, 43, 44, 45, 46, 47, 48, 50, 51, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 81, 82, 83, 84, 89, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 106, 107, 110, 111, 116, 121, 122, 123, 124, 126, 127, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 152, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 183, 184, 185, 186, 187, 189, 191, 193, 194, 195, 197, 198, 200, 201, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 219, 220, 221, 222, 223, 224, 227, 228, 229, 231, 232, 235, 236, 238, 239, 243, 245, 246, 247, 248, 249, 250, 251, 252, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 1024])>, Index=[768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 797, 798, 799, 802, 803, 804, 805, 806, 808, 811, 812, 813, 814, 815, 816, 818, 819, 822, 823, 825, 826, 828, 830, 831, 832, 833, 834, 835, 836, 837, 840, 841, 842, 843, 844, 845, 846, 849, 850, 851, 852, 857, 862, 863, 864, 866, 867, 869, 870, 871, 872, 873, 874, 875, 878, 879, 884, 889, 890, 891, 892, 894, 895, 899, 900, 901, 903, 904, 905, 906, 907, 908, 909, 911, 913, 914, 915, 916, 917, 918, 920, 926, 927, 928, 929, 930, 931, 932, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 949, 951, 952, 953, 954, 955, 957, 959, 961, 962, 963, 965, 966, 968, 969, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 984, 985, 987, 988, 989, 990, 991, 992, 995, 996, 997, 999, 1000, 1003, 1004, 1006, 1007, 1011, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1022], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 797, 798, 799, 802, 803, 804, 805, 806, 808, 811, 812, 813, 814, 815, 816, 818, 819, 822, 823, 825, 826, 828, 830, 831, 832, 833, 834, 835, 836, 837, 840, 841, 842, 843, 844, 845, 846, 849, 850, 851, 852, 857, 862, 863, 864, 866, 867, 869, 870, 871, 872, 873, 874, 875, 878, 879, 884, 889, 890, 891, 892, 894, 895, 899, 900, 901, 903, 904, 905, 906, 907, 908, 909, 911, 913, 914, 915, 916, 917, 918, 920, 926, 927, 928, 929, 930, 931, 932, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 949, 951, 952, 953, 954, 955, 957, 959, 961, 962, 963, 965, 966, 968, 969, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 984, 985, 987, 988, 989, 990, 991, 992, 995, 996, 997, 999, 1000, 1003, 1004, 1006, 1007, 1011, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1022], NumPruned=183296]
200480 parameters will be pruned
-------------

2023-04-04 16:48:50.577 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.43.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 25, 26, 30, 31, 32, 34, 36, 38, 39, 40, 41, 43, 44, 45, 47, 48, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.43.conv (Conv2d(94, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 25, 26, 30, 31, 32, 34, 36, 38, 39, 40, 41, 43, 44, 45, 47, 48, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76], NumPruned=4982]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 25, 26, 30, 31, 32, 34, 36, 38, 39, 40, 41, 43, 44, 45, 47, 48, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 845])>, Index=[770, 771, 772, 773, 774, 776, 777, 779, 780, 781, 782, 783, 784, 786, 787, 788, 790, 793, 794, 798, 799, 800, 802, 804, 806, 807, 808, 809, 811, 812, 813, 815, 816, 821, 822, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 843, 844], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(845, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[770, 771, 772, 773, 774, 776, 777, 779, 780, 781, 782, 783, 784, 786, 787, 788, 790, 793, 794, 798, 799, 800, 802, 804, 806, 807, 808, 809, 811, 812, 813, 815, 816, 821, 822, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 843, 844], NumPruned=54272]
59360 parameters will be pruned
-------------

2023-04-04 16:48:50.580 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.44.conv (Conv2d(94, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 7, 11, 13, 14, 15, 17, 20, 21, 23, 25, 26, 28, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 55, 56, 57, 60, 61, 62, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 97, 98, 101, 102, 104, 105, 107, 108, 110, 111, 112, 115, 116, 118, 120, 121, 122, 123, 125, 126, 128, 129, 130, 131, 133, 134, 136, 137, 139, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 194, 195, 197, 198, 199, 203, 205, 206, 207, 208, 209, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 246, 247, 248, 249, 250, 251, 252, 254, 255], NumPruned=16826]
[ <DEP: prune_conv => prune_batchnorm on model.44.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 5, 7, 11, 13, 14, 15, 17, 20, 21, 23, 25, 26, 28, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 55, 56, 57, 60, 61, 62, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 97, 98, 101, 102, 104, 105, 107, 108, 110, 111, 112, 115, 116, 118, 120, 121, 122, 123, 125, 126, 128, 129, 130, 131, 133, 134, 136, 137, 139, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 194, 195, 197, 198, 199, 203, 205, 206, 207, 208, 209, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 246, 247, 248, 249, 250, 251, 252, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 5, 7, 11, 13, 14, 15, 17, 20, 21, 23, 25, 26, 28, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 55, 56, 57, 60, 61, 62, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 97, 98, 101, 102, 104, 105, 107, 108, 110, 111, 112, 115, 116, 118, 120, 121, 122, 123, 125, 126, 128, 129, 130, 131, 133, 134, 136, 137, 139, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 194, 195, 197, 198, 199, 203, 205, 206, 207, 208, 209, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 246, 247, 248, 249, 250, 251, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.45.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 7, 11, 13, 14, 15, 17, 20, 21, 23, 25, 26, 28, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 55, 56, 57, 60, 61, 62, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 97, 98, 101, 102, 104, 105, 107, 108, 110, 111, 112, 115, 116, 118, 120, 121, 122, 123, 125, 126, 128, 129, 130, 131, 133, 134, 136, 137, 139, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 194, 195, 197, 198, 199, 203, 205, 206, 207, 208, 209, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 246, 247, 248, 249, 250, 251, 252, 254, 255], NumPruned=412416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 792])>, Index=[512, 514, 515, 517, 519, 523, 525, 526, 527, 529, 532, 533, 535, 537, 538, 540, 541, 542, 546, 547, 548, 550, 551, 552, 553, 554, 555, 556, 557, 560, 561, 563, 564, 565, 567, 568, 569, 572, 573, 574, 579, 580, 581, 583, 584, 585, 586, 587, 588, 589, 590, 592, 593, 594, 595, 596, 597, 598, 599, 600, 602, 604, 605, 607, 609, 610, 613, 614, 616, 617, 619, 620, 622, 623, 624, 627, 628, 630, 632, 633, 634, 635, 637, 638, 640, 641, 642, 643, 645, 646, 648, 649, 651, 653, 654, 655, 656, 657, 659, 660, 661, 662, 663, 665, 668, 669, 670, 671, 672, 673, 675, 676, 677, 678, 680, 683, 684, 685, 686, 687, 690, 691, 692, 693, 694, 695, 696, 697, 698, 701, 702, 703, 704, 706, 707, 709, 710, 711, 715, 717, 718, 719, 720, 721, 723, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 738, 739, 740, 741, 744, 745, 746, 747, 748, 750, 751, 752, 755, 756, 758, 759, 760, 761, 762, 763, 764, 766, 767], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(792, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 514, 515, 517, 519, 523, 525, 526, 527, 529, 532, 533, 535, 537, 538, 540, 541, 542, 546, 547, 548, 550, 551, 552, 553, 554, 555, 556, 557, 560, 561, 563, 564, 565, 567, 568, 569, 572, 573, 574, 579, 580, 581, 583, 584, 585, 586, 587, 588, 589, 590, 592, 593, 594, 595, 596, 597, 598, 599, 600, 602, 604, 605, 607, 609, 610, 613, 614, 616, 617, 619, 620, 622, 623, 624, 627, 628, 630, 632, 633, 634, 635, 637, 638, 640, 641, 642, 643, 645, 646, 648, 649, 651, 653, 654, 655, 656, 657, 659, 660, 661, 662, 663, 665, 668, 669, 670, 671, 672, 673, 675, 676, 677, 678, 680, 683, 684, 685, 686, 687, 690, 691, 692, 693, 694, 695, 696, 697, 698, 701, 702, 703, 704, 706, 707, 709, 710, 711, 715, 717, 718, 719, 720, 721, 723, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 738, 739, 740, 741, 744, 745, 746, 747, 748, 750, 751, 752, 755, 756, 758, 759, 760, 761, 762, 763, 764, 766, 767], NumPruned=183296]
612896 parameters will be pruned
-------------

2023-04-04 16:48:50.594 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.44.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 6, 8, 9, 11, 16, 18, 19, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.44.conv (Conv2d(94, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 3, 6, 8, 9, 11, 16, 18, 19, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75], NumPruned=4982]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 6, 8, 9, 11, 16, 18, 19, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.45.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 6, 8, 9, 11, 16, 18, 19, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75], NumPruned=122112]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 589, 613])>, Index=[514, 515, 518, 520, 521, 523, 528, 530, 531, 534, 535, 536, 537, 539, 540, 542, 543, 544, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 559, 560, 561, 562, 563, 566, 567, 569, 570, 572, 573, 574, 576, 577, 578, 579, 580, 581, 583, 584, 585, 586, 587], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(613, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[514, 515, 518, 520, 521, 523, 528, 530, 531, 534, 535, 536, 537, 539, 540, 542, 543, 544, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 559, 560, 561, 562, 563, 566, 567, 569, 570, 572, 573, 574, 576, 577, 578, 579, 580, 581, 583, 584, 585, 586, 587], NumPruned=54272]
181472 parameters will be pruned
-------------

2023-04-04 16:48:50.596 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.45.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 4, 5, 6, 7, 9, 10, 11, 16, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 84, 85, 87, 89, 90, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 110, 111, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 188, 189, 192, 193, 194, 195, 197, 199, 200, 201, 203, 205, 206, 208, 210, 211, 214, 215, 216, 219, 220, 222, 223, 224, 225, 226, 227, 231, 232, 233, 236, 237, 239, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.45.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 5, 6, 7, 9, 10, 11, 16, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 84, 85, 87, 89, 90, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 110, 111, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 188, 189, 192, 193, 194, 195, 197, 199, 200, 201, 203, 205, 206, 208, 210, 211, 214, 215, 216, 219, 220, 222, 223, 224, 225, 226, 227, 231, 232, 233, 236, 237, 239, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 5, 6, 7, 9, 10, 11, 16, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 84, 85, 87, 89, 90, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 110, 111, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 188, 189, 192, 193, 194, 195, 197, 199, 200, 201, 203, 205, 206, 208, 210, 211, 214, 215, 216, 219, 220, 222, 223, 224, 225, 226, 227, 231, 232, 233, 236, 237, 239, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.46.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 4, 5, 6, 7, 9, 10, 11, 16, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 84, 85, 87, 89, 90, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 110, 111, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 188, 189, 192, 193, 194, 195, 197, 199, 200, 201, 203, 205, 206, 208, 210, 211, 214, 215, 216, 219, 220, 222, 223, 224, 225, 226, 227, 231, 232, 233, 236, 237, 239, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=412416]
451438 parameters will be pruned
-------------

2023-04-04 16:48:50.608 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.45.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 6, 8, 10, 16, 17, 18, 21, 22, 24, 25, 26, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.45.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 6, 8, 10, 16, 17, 18, 21, 22, 24, 25, 26, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 6, 8, 10, 16, 17, 18, 21, 22, 24, 25, 26, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.46.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 6, 8, 10, 16, 17, 18, 21, 22, 24, 25, 26, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], NumPruned=122112]
133666 parameters will be pruned
-------------

2023-04-04 16:48:50.609 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.46.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 9, 12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 103, 105, 107, 108, 112, 113, 115, 116, 117, 118, 121, 123, 125, 126, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 164, 165, 166, 167, 170, 172, 173, 174, 176, 177, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 210, 211, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 235, 236, 238, 239, 240, 241, 244, 247, 248, 250, 251, 252, 253, 254, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.46.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 5, 6, 7, 9, 12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 103, 105, 107, 108, 112, 113, 115, 116, 117, 118, 121, 123, 125, 126, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 164, 165, 166, 167, 170, 172, 173, 174, 176, 177, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 210, 211, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 235, 236, 238, 239, 240, 241, 244, 247, 248, 250, 251, 252, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 6, 7, 9, 12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 103, 105, 107, 108, 112, 113, 115, 116, 117, 118, 121, 123, 125, 126, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 164, 165, 166, 167, 170, 172, 173, 174, 176, 177, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 210, 211, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 235, 236, 238, 239, 240, 241, 244, 247, 248, 250, 251, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.47.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 9, 12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 103, 105, 107, 108, 112, 113, 115, 116, 117, 118, 121, 123, 125, 126, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 164, 165, 166, 167, 170, 172, 173, 174, 176, 177, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 210, 211, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 235, 236, 238, 239, 240, 241, 244, 247, 248, 250, 251, 252, 253, 254, 255], NumPruned=412416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 536, 560])>, Index=[256, 259, 260, 261, 262, 263, 265, 268, 270, 271, 272, 273, 275, 276, 277, 279, 280, 281, 284, 285, 286, 287, 291, 292, 293, 294, 295, 296, 297, 298, 299, 302, 303, 304, 306, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 333, 334, 335, 336, 337, 339, 340, 341, 342, 344, 345, 346, 348, 349, 350, 352, 354, 355, 356, 357, 359, 361, 363, 364, 368, 369, 371, 372, 373, 374, 377, 379, 381, 382, 384, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 399, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 416, 417, 418, 420, 421, 422, 423, 426, 428, 429, 430, 432, 433, 436, 438, 439, 440, 441, 442, 443, 444, 445, 446, 449, 450, 451, 452, 453, 454, 456, 457, 458, 459, 460, 461, 462, 463, 466, 467, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481, 482, 483, 485, 486, 487, 488, 491, 492, 494, 495, 496, 497, 500, 503, 504, 506, 507, 508, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(560, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 259, 260, 261, 262, 263, 265, 268, 270, 271, 272, 273, 275, 276, 277, 279, 280, 281, 284, 285, 286, 287, 291, 292, 293, 294, 295, 296, 297, 298, 299, 302, 303, 304, 306, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 333, 334, 335, 336, 337, 339, 340, 341, 342, 344, 345, 346, 348, 349, 350, 352, 354, 355, 356, 357, 359, 361, 363, 364, 368, 369, 371, 372, 373, 374, 377, 379, 381, 382, 384, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 399, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 416, 417, 418, 420, 421, 422, 423, 426, 428, 429, 430, 432, 433, 436, 438, 439, 440, 441, 442, 443, 444, 445, 446, 449, 450, 451, 452, 453, 454, 456, 457, 458, 459, 460, 461, 462, 463, 466, 467, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481, 482, 483, 485, 486, 487, 488, 491, 492, 494, 495, 496, 497, 500, 503, 504, 506, 507, 508, 509, 510, 511], NumPruned=183296]
634734 parameters will be pruned
-------------

2023-04-04 16:48:50.625 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.46.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.46.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.47.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76], NumPruned=122112]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 333, 357, 381])>, Index=[258, 260, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 282, 283, 284, 287, 288, 289, 290, 291, 292, 293, 296, 297, 298, 301, 302, 303, 305, 306, 307, 309, 312, 313, 314, 316, 317, 318, 320, 321, 322, 323, 324, 326, 327, 328, 330, 332], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(381, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[258, 260, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 282, 283, 284, 287, 288, 289, 290, 291, 292, 293, 296, 297, 298, 301, 302, 303, 305, 306, 307, 309, 312, 313, 314, 316, 317, 318, 320, 321, 322, 323, 324, 326, 327, 328, 330, 332], NumPruned=54272]
187938 parameters will be pruned
-------------

2023-04-04 16:48:50.627 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.47.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 32, 34, 36, 37, 38, 44, 46, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 150, 151, 152, 153, 154, 155, 156, 160, 161, 162, 163, 164, 166, 167, 170, 171, 172, 180, 181, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 207, 208, 210, 211, 213, 214, 217, 219, 220, 221, 222, 223, 224, 225, 226, 228, 231, 232, 233, 236, 237, 238, 240, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.47.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 32, 34, 36, 37, 38, 44, 46, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 150, 151, 152, 153, 154, 155, 156, 160, 161, 162, 163, 164, 166, 167, 170, 171, 172, 180, 181, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 207, 208, 210, 211, 213, 214, 217, 219, 220, 221, 222, 223, 224, 225, 226, 228, 231, 232, 233, 236, 237, 238, 240, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 32, 34, 36, 37, 38, 44, 46, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 150, 151, 152, 153, 154, 155, 156, 160, 161, 162, 163, 164, 166, 167, 170, 171, 172, 180, 181, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 207, 208, 210, 211, 213, 214, 217, 219, 220, 221, 222, 223, 224, 225, 226, 228, 231, 232, 233, 236, 237, 238, 240, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.48.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 32, 34, 36, 37, 38, 44, 46, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 150, 151, 152, 153, 154, 155, 156, 160, 161, 162, 163, 164, 166, 167, 170, 171, 172, 180, 181, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 207, 208, 210, 211, 213, 214, 217, 219, 220, 221, 222, 223, 224, 225, 226, 228, 231, 232, 233, 236, 237, 238, 240, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255], NumPruned=412416]
451438 parameters will be pruned
-------------

2023-04-04 16:48:50.641 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.47.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44, 45, 47, 51, 52, 53, 56, 58, 59, 60, 62, 65, 66, 67, 68, 69, 73, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.47.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44, 45, 47, 51, 52, 53, 56, 58, 59, 60, 62, 65, 66, 67, 68, 69, 73, 75, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44, 45, 47, 51, 52, 53, 56, 58, 59, 60, 62, 65, 66, 67, 68, 69, 73, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.48.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44, 45, 47, 51, 52, 53, 56, 58, 59, 60, 62, 65, 66, 67, 68, 69, 73, 75, 76], NumPruned=122112]
133666 parameters will be pruned
-------------

2023-04-04 16:48:50.642 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.48.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 75, 77, 82, 83, 84, 85, 86, 89, 91, 92, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 137, 138, 139, 140, 143, 145, 146, 148, 149, 150, 151, 152, 155, 157, 158, 160, 161, 163, 164, 165, 167, 170, 171, 172, 173, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.48.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 75, 77, 82, 83, 84, 85, 86, 89, 91, 92, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 137, 138, 139, 140, 143, 145, 146, 148, 149, 150, 151, 152, 155, 157, 158, 160, 161, 163, 164, 165, 167, 170, 171, 172, 173, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 75, 77, 82, 83, 84, 85, 86, 89, 91, 92, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 137, 138, 139, 140, 143, 145, 146, 148, 149, 150, 151, 152, 155, 157, 158, 160, 161, 163, 164, 165, 167, 170, 171, 172, 173, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 280, 304, 328])>, Index=[1, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 75, 77, 82, 83, 84, 85, 86, 89, 91, 92, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 137, 138, 139, 140, 143, 145, 146, 148, 149, 150, 151, 152, 155, 157, 158, 160, 161, 163, 164, 165, 167, 170, 171, 172, 173, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(328, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 75, 77, 82, 83, 84, 85, 86, 89, 91, 92, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 137, 138, 139, 140, 143, 145, 146, 148, 149, 150, 151, 152, 155, 157, 158, 160, 161, 163, 164, 165, 167, 170, 171, 172, 173, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255], NumPruned=183296]
222318 parameters will be pruned
-------------

2023-04-04 16:48:50.656 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.48.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 6, 7, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 69, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.48.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 6, 7, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 69, 74, 75, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 6, 7, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 69, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 77, 101, 125, 149])>, Index=[1, 4, 6, 7, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 69, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(149, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 4, 6, 7, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 69, 74, 75, 76], NumPruned=54272]
65826 parameters will be pruned
-------------

2023-04-04 16:48:50.657 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.50.conv (Conv2d(96, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 53, 56, 57, 59, 60, 62, 64, 65, 67, 69, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 94, 95, 96, 98, 99, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 132, 133, 134, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 178, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 203, 204, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 254, 255, 256, 257, 259, 260, 263, 264, 267, 268, 271, 272, 273, 274, 276, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 340, 342, 343, 344, 345, 346, 349, 350, 351, 353, 355, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 370, 372, 373, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 405, 408, 409, 411, 412, 413, 415, 417, 419, 420, 423, 424, 425, 426, 427, 428, 430, 431, 434, 435, 436, 440, 442, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 470, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 487, 488, 489, 492, 496, 497, 498, 499, 501, 503, 506, 507, 508, 511, 512, 513, 514, 515, 517, 519, 520, 521, 523, 524, 526, 528, 529, 531, 532, 533, 534, 535, 536, 537, 539, 540, 542, 545, 547, 550, 551, 553, 554, 555, 558, 559, 561, 563, 564, 565, 566, 567, 568, 570, 571, 573, 574, 575, 576, 577, 579, 580, 582, 583, 586, 587, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 609, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 639, 640, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 665, 666, 667, 668, 672, 673, 674, 675, 676, 677, 678, 679, 680, 684, 685, 689, 691, 692, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 707, 709, 711, 712, 713, 714, 715, 716, 717, 719, 720, 722, 726, 727, 728, 729, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 743, 744, 745, 747, 748, 751, 752, 753, 754, 756, 757, 759, 760, 764, 765, 766, 767, 768, 770, 771, 773, 774, 777, 778, 779, 781, 782, 783, 784, 786, 787, 789, 790, 791, 792, 793, 795, 797, 798, 799, 801, 803, 805, 806, 807, 809, 810, 811, 812, 813, 814, 816, 817, 819, 824, 825, 826, 827, 828, 829, 830, 832, 833, 834, 837, 838, 839, 840, 842, 843, 846, 849, 851, 853, 854, 855, 856, 857, 858, 859, 861, 862, 863, 864, 865, 867, 868, 870, 872, 875, 876, 877, 878, 879, 881, 882, 883, 885, 886, 887, 888, 890, 891, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 912, 913, 914, 916, 920, 922, 925, 926, 927, 929, 931, 933, 934, 935, 938, 939, 940, 942, 943, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 956, 957, 958, 959, 964, 966, 967, 970, 971, 972, 973, 975, 977, 979, 982, 984, 985, 989, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1020, 1021, 1022, 1023], NumPruned=68736]
[ <DEP: prune_conv => prune_batchnorm on model.50.bn (BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 53, 56, 57, 59, 60, 62, 64, 65, 67, 69, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 94, 95, 96, 98, 99, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 132, 133, 134, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 178, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 203, 204, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 254, 255, 256, 257, 259, 260, 263, 264, 267, 268, 271, 272, 273, 274, 276, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 340, 342, 343, 344, 345, 346, 349, 350, 351, 353, 355, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 370, 372, 373, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 405, 408, 409, 411, 412, 413, 415, 417, 419, 420, 423, 424, 425, 426, 427, 428, 430, 431, 434, 435, 436, 440, 442, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 470, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 487, 488, 489, 492, 496, 497, 498, 499, 501, 503, 506, 507, 508, 511, 512, 513, 514, 515, 517, 519, 520, 521, 523, 524, 526, 528, 529, 531, 532, 533, 534, 535, 536, 537, 539, 540, 542, 545, 547, 550, 551, 553, 554, 555, 558, 559, 561, 563, 564, 565, 566, 567, 568, 570, 571, 573, 574, 575, 576, 577, 579, 580, 582, 583, 586, 587, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 609, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 639, 640, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 665, 666, 667, 668, 672, 673, 674, 675, 676, 677, 678, 679, 680, 684, 685, 689, 691, 692, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 707, 709, 711, 712, 713, 714, 715, 716, 717, 719, 720, 722, 726, 727, 728, 729, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 743, 744, 745, 747, 748, 751, 752, 753, 754, 756, 757, 759, 760, 764, 765, 766, 767, 768, 770, 771, 773, 774, 777, 778, 779, 781, 782, 783, 784, 786, 787, 789, 790, 791, 792, 793, 795, 797, 798, 799, 801, 803, 805, 806, 807, 809, 810, 811, 812, 813, 814, 816, 817, 819, 824, 825, 826, 827, 828, 829, 830, 832, 833, 834, 837, 838, 839, 840, 842, 843, 846, 849, 851, 853, 854, 855, 856, 857, 858, 859, 861, 862, 863, 864, 865, 867, 868, 870, 872, 875, 876, 877, 878, 879, 881, 882, 883, 885, 886, 887, 888, 890, 891, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 912, 913, 914, 916, 920, 922, 925, 926, 927, 929, 931, 933, 934, 935, 938, 939, 940, 942, 943, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 956, 957, 958, 959, 964, 966, 967, 970, 971, 972, 973, 975, 977, 979, 982, 984, 985, 989, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1020, 1021, 1022, 1023], NumPruned=1432]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 53, 56, 57, 59, 60, 62, 64, 65, 67, 69, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 94, 95, 96, 98, 99, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 132, 133, 134, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 178, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 203, 204, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 254, 255, 256, 257, 259, 260, 263, 264, 267, 268, 271, 272, 273, 274, 276, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 340, 342, 343, 344, 345, 346, 349, 350, 351, 353, 355, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 370, 372, 373, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 405, 408, 409, 411, 412, 413, 415, 417, 419, 420, 423, 424, 425, 426, 427, 428, 430, 431, 434, 435, 436, 440, 442, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 470, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 487, 488, 489, 492, 496, 497, 498, 499, 501, 503, 506, 507, 508, 511, 512, 513, 514, 515, 517, 519, 520, 521, 523, 524, 526, 528, 529, 531, 532, 533, 534, 535, 536, 537, 539, 540, 542, 545, 547, 550, 551, 553, 554, 555, 558, 559, 561, 563, 564, 565, 566, 567, 568, 570, 571, 573, 574, 575, 576, 577, 579, 580, 582, 583, 586, 587, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 609, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 639, 640, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 665, 666, 667, 668, 672, 673, 674, 675, 676, 677, 678, 679, 680, 684, 685, 689, 691, 692, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 707, 709, 711, 712, 713, 714, 715, 716, 717, 719, 720, 722, 726, 727, 728, 729, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 743, 744, 745, 747, 748, 751, 752, 753, 754, 756, 757, 759, 760, 764, 765, 766, 767, 768, 770, 771, 773, 774, 777, 778, 779, 781, 782, 783, 784, 786, 787, 789, 790, 791, 792, 793, 795, 797, 798, 799, 801, 803, 805, 806, 807, 809, 810, 811, 812, 813, 814, 816, 817, 819, 824, 825, 826, 827, 828, 829, 830, 832, 833, 834, 837, 838, 839, 840, 842, 843, 846, 849, 851, 853, 854, 855, 856, 857, 858, 859, 861, 862, 863, 864, 865, 867, 868, 870, 872, 875, 876, 877, 878, 879, 881, 882, 883, 885, 886, 887, 888, 890, 891, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 912, 913, 914, 916, 920, 922, 925, 926, 927, 929, 931, 933, 934, 935, 938, 939, 940, 942, 943, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 956, 957, 958, 959, 964, 966, 967, 970, 971, 972, 973, 975, 977, 979, 982, 984, 985, 989, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1020, 1021, 1022, 1023], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.51.cv1.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 53, 56, 57, 59, 60, 62, 64, 65, 67, 69, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 94, 95, 96, 98, 99, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 132, 133, 134, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 178, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 203, 204, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 254, 255, 256, 257, 259, 260, 263, 264, 267, 268, 271, 272, 273, 274, 276, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 340, 342, 343, 344, 345, 346, 349, 350, 351, 353, 355, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 370, 372, 373, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 405, 408, 409, 411, 412, 413, 415, 417, 419, 420, 423, 424, 425, 426, 427, 428, 430, 431, 434, 435, 436, 440, 442, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 470, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 487, 488, 489, 492, 496, 497, 498, 499, 501, 503, 506, 507, 508, 511, 512, 513, 514, 515, 517, 519, 520, 521, 523, 524, 526, 528, 529, 531, 532, 533, 534, 535, 536, 537, 539, 540, 542, 545, 547, 550, 551, 553, 554, 555, 558, 559, 561, 563, 564, 565, 566, 567, 568, 570, 571, 573, 574, 575, 576, 577, 579, 580, 582, 583, 586, 587, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 609, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 639, 640, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 665, 666, 667, 668, 672, 673, 674, 675, 676, 677, 678, 679, 680, 684, 685, 689, 691, 692, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 707, 709, 711, 712, 713, 714, 715, 716, 717, 719, 720, 722, 726, 727, 728, 729, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 743, 744, 745, 747, 748, 751, 752, 753, 754, 756, 757, 759, 760, 764, 765, 766, 767, 768, 770, 771, 773, 774, 777, 778, 779, 781, 782, 783, 784, 786, 787, 789, 790, 791, 792, 793, 795, 797, 798, 799, 801, 803, 805, 806, 807, 809, 810, 811, 812, 813, 814, 816, 817, 819, 824, 825, 826, 827, 828, 829, 830, 832, 833, 834, 837, 838, 839, 840, 842, 843, 846, 849, 851, 853, 854, 855, 856, 857, 858, 859, 861, 862, 863, 864, 865, 867, 868, 870, 872, 875, 876, 877, 878, 879, 881, 882, 883, 885, 886, 887, 888, 890, 891, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 912, 913, 914, 916, 920, 922, 925, 926, 927, 929, 931, 933, 934, 935, 938, 939, 940, 942, 943, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 956, 957, 958, 959, 964, 966, 967, 970, 971, 972, 973, 975, 977, 979, 982, 984, 985, 989, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1020, 1021, 1022, 1023], NumPruned=366592]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.51.cv2.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 53, 56, 57, 59, 60, 62, 64, 65, 67, 69, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 94, 95, 96, 98, 99, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 132, 133, 134, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 178, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 203, 204, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 254, 255, 256, 257, 259, 260, 263, 264, 267, 268, 271, 272, 273, 274, 276, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 340, 342, 343, 344, 345, 346, 349, 350, 351, 353, 355, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 370, 372, 373, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 405, 408, 409, 411, 412, 413, 415, 417, 419, 420, 423, 424, 425, 426, 427, 428, 430, 431, 434, 435, 436, 440, 442, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 470, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 487, 488, 489, 492, 496, 497, 498, 499, 501, 503, 506, 507, 508, 511, 512, 513, 514, 515, 517, 519, 520, 521, 523, 524, 526, 528, 529, 531, 532, 533, 534, 535, 536, 537, 539, 540, 542, 545, 547, 550, 551, 553, 554, 555, 558, 559, 561, 563, 564, 565, 566, 567, 568, 570, 571, 573, 574, 575, 576, 577, 579, 580, 582, 583, 586, 587, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 609, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 639, 640, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 665, 666, 667, 668, 672, 673, 674, 675, 676, 677, 678, 679, 680, 684, 685, 689, 691, 692, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 707, 709, 711, 712, 713, 714, 715, 716, 717, 719, 720, 722, 726, 727, 728, 729, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 743, 744, 745, 747, 748, 751, 752, 753, 754, 756, 757, 759, 760, 764, 765, 766, 767, 768, 770, 771, 773, 774, 777, 778, 779, 781, 782, 783, 784, 786, 787, 789, 790, 791, 792, 793, 795, 797, 798, 799, 801, 803, 805, 806, 807, 809, 810, 811, 812, 813, 814, 816, 817, 819, 824, 825, 826, 827, 828, 829, 830, 832, 833, 834, 837, 838, 839, 840, 842, 843, 846, 849, 851, 853, 854, 855, 856, 857, 858, 859, 861, 862, 863, 864, 865, 867, 868, 870, 872, 875, 876, 877, 878, 879, 881, 882, 883, 885, 886, 887, 888, 890, 891, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 912, 913, 914, 916, 920, 922, 925, 926, 927, 929, 931, 933, 934, 935, 938, 939, 940, 942, 943, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 956, 957, 958, 959, 964, 966, 967, 970, 971, 972, 973, 975, 977, 979, 982, 984, 985, 989, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1020, 1021, 1022, 1023], NumPruned=366592]
803352 parameters will be pruned
-------------

2023-04-04 16:48:50.673 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.50.bn (BatchNorm2d(308, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 95, 97, 98, 99, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 130, 131, 134, 135, 136, 137, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 171, 172, 175, 177, 178, 179, 180, 183, 184, 185, 187, 188, 189, 191, 193, 196, 197, 198, 200, 203, 210, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 225, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 255, 256, 258, 260, 261, 262, 263, 265, 266, 267, 268, 270, 271, 273, 274, 278, 279, 280, 281, 283, 284, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 299, 300, 301, 302, 303, 304, 307], NumPruned=430]
[ <DEP: prune_batchnorm => prune_conv on model.50.conv (Conv2d(96, 308, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 95, 97, 98, 99, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 130, 131, 134, 135, 136, 137, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 171, 172, 175, 177, 178, 179, 180, 183, 184, 185, 187, 188, 189, 191, 193, 196, 197, 198, 200, 203, 210, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 225, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 255, 256, 258, 260, 261, 262, 263, 265, 266, 267, 268, 270, 271, 273, 274, 278, 279, 280, 281, 283, 284, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 299, 300, 301, 302, 303, 304, 307], NumPruned=20640]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 95, 97, 98, 99, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 130, 131, 134, 135, 136, 137, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 171, 172, 175, 177, 178, 179, 180, 183, 184, 185, 187, 188, 189, 191, 193, 196, 197, 198, 200, 203, 210, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 225, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 255, 256, 258, 260, 261, 262, 263, 265, 266, 267, 268, 270, 271, 273, 274, 278, 279, 280, 281, 283, 284, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 299, 300, 301, 302, 303, 304, 307], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.51.cv1.conv (Conv2d(308, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 95, 97, 98, 99, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 130, 131, 134, 135, 136, 137, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 171, 172, 175, 177, 178, 179, 180, 183, 184, 185, 187, 188, 189, 191, 193, 196, 197, 198, 200, 203, 210, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 225, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 255, 256, 258, 260, 261, 262, 263, 265, 266, 267, 268, 270, 271, 273, 274, 278, 279, 280, 281, 283, 284, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 299, 300, 301, 302, 303, 304, 307], NumPruned=110080]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.51.cv2.conv (Conv2d(308, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 95, 97, 98, 99, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 130, 131, 134, 135, 136, 137, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 171, 172, 175, 177, 178, 179, 180, 183, 184, 185, 187, 188, 189, 191, 193, 196, 197, 198, 200, 203, 210, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 225, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 255, 256, 258, 260, 261, 262, 263, 265, 266, 267, 268, 270, 271, 273, 274, 278, 279, 280, 281, 283, 284, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 299, 300, 301, 302, 303, 304, 307], NumPruned=110080]
241230 parameters will be pruned
-------------

2023-04-04 16:48:50.688 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.52.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 29, 32, 33, 34, 36, 39, 41, 42, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 84, 88, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 108, 109, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 136, 138, 139, 140, 141, 143, 145, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 175, 176, 177, 178, 179, 180, 181, 182, 183, 187, 188, 189, 190, 192, 194, 195, 197, 198, 199, 201, 202, 203, 205, 206, 207, 208, 209, 211, 212, 213, 218, 219, 220, 221, 222, 223, 224, 225, 227, 229, 232, 233, 234, 236, 237, 240, 242, 243, 244, 245, 246, 247, 249, 251, 253, 254, 255], NumPruned=91648]
[ <DEP: prune_conv => prune_batchnorm on model.52.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 29, 32, 33, 34, 36, 39, 41, 42, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 84, 88, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 108, 109, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 136, 138, 139, 140, 141, 143, 145, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 175, 176, 177, 178, 179, 180, 181, 182, 183, 187, 188, 189, 190, 192, 194, 195, 197, 198, 199, 201, 202, 203, 205, 206, 207, 208, 209, 211, 212, 213, 218, 219, 220, 221, 222, 223, 224, 225, 227, 229, 232, 233, 234, 236, 237, 240, 242, 243, 244, 245, 246, 247, 249, 251, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 29, 32, 33, 34, 36, 39, 41, 42, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 84, 88, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 108, 109, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 136, 138, 139, 140, 141, 143, 145, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 175, 176, 177, 178, 179, 180, 181, 182, 183, 187, 188, 189, 190, 192, 194, 195, 197, 198, 199, 201, 202, 203, 205, 206, 207, 208, 209, 211, 212, 213, 218, 219, 220, 221, 222, 223, 224, 225, 227, 229, 232, 233, 234, 236, 237, 240, 242, 243, 244, 245, 246, 247, 249, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 29, 32, 33, 34, 36, 39, 41, 42, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 84, 88, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 108, 109, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 136, 138, 139, 140, 141, 143, 145, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 175, 176, 177, 178, 179, 180, 181, 182, 183, 187, 188, 189, 190, 192, 194, 195, 197, 198, 199, 201, 202, 203, 205, 206, 207, 208, 209, 211, 212, 213, 218, 219, 220, 221, 222, 223, 224, 225, 227, 229, 232, 233, 234, 236, 237, 240, 242, 243, 244, 245, 246, 247, 249, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512])>, Index=[256, 257, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 278, 279, 280, 281, 283, 285, 288, 289, 290, 292, 295, 297, 298, 300, 301, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 337, 340, 344, 347, 348, 349, 350, 351, 352, 353, 354, 359, 360, 361, 364, 365, 367, 368, 369, 371, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388, 389, 390, 392, 394, 395, 396, 397, 399, 401, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 417, 418, 419, 421, 422, 423, 424, 425, 426, 431, 432, 433, 434, 435, 436, 437, 438, 439, 443, 444, 445, 446, 448, 450, 451, 453, 454, 455, 457, 458, 459, 461, 462, 463, 464, 465, 467, 468, 469, 474, 475, 476, 477, 478, 479, 480, 481, 483, 485, 488, 489, 490, 492, 493, 496, 498, 499, 500, 501, 502, 503, 505, 507, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.57.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 278, 279, 280, 281, 283, 285, 288, 289, 290, 292, 295, 297, 298, 300, 301, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 337, 340, 344, 347, 348, 349, 350, 351, 352, 353, 354, 359, 360, 361, 364, 365, 367, 368, 369, 371, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388, 389, 390, 392, 394, 395, 396, 397, 399, 401, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 417, 418, 419, 421, 422, 423, 424, 425, 426, 431, 432, 433, 434, 435, 436, 437, 438, 439, 443, 444, 445, 446, 448, 450, 451, 453, 454, 455, 457, 458, 459, 461, 462, 463, 464, 465, 467, 468, 469, 474, 475, 476, 477, 478, 479, 480, 481, 483, 485, 488, 489, 490, 492, 493, 496, 498, 499, 500, 501, 502, 503, 505, 507, 509, 510, 511], NumPruned=45824]
[ <DEP: _prune_concat => prune_related_conv on model.56.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 278, 279, 280, 281, 283, 285, 288, 289, 290, 292, 295, 297, 298, 300, 301, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 337, 340, 344, 347, 348, 349, 350, 351, 352, 353, 354, 359, 360, 361, 364, 365, 367, 368, 369, 371, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388, 389, 390, 392, 394, 395, 396, 397, 399, 401, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 417, 418, 419, 421, 422, 423, 424, 425, 426, 431, 432, 433, 434, 435, 436, 437, 438, 439, 443, 444, 445, 446, 448, 450, 451, 453, 454, 455, 457, 458, 459, 461, 462, 463, 464, 465, 467, 468, 469, 474, 475, 476, 477, 478, 479, 480, 481, 483, 485, 488, 489, 490, 492, 493, 496, 498, 499, 500, 501, 502, 503, 505, 507, 509, 510, 511], NumPruned=45824]
183654 parameters will be pruned
-------------

2023-04-04 16:48:50.704 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.52.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 21, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.52.conv (Conv2d(512, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 21, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 76], NumPruned=27136]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 21, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 21, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 333])>, Index=[256, 257, 258, 259, 261, 264, 265, 266, 267, 268, 269, 271, 272, 274, 275, 277, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 295, 296, 297, 298, 299, 300, 302, 304, 305, 306, 307, 308, 309, 312, 313, 314, 316, 317, 318, 321, 322, 323, 324, 326, 327, 328, 332], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.57.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 261, 264, 265, 266, 267, 268, 269, 271, 272, 274, 275, 277, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 295, 296, 297, 298, 299, 300, 302, 304, 305, 306, 307, 308, 309, 312, 313, 314, 316, 317, 318, 321, 322, 323, 324, 326, 327, 328, 332], NumPruned=13568]
[ <DEP: _prune_concat => prune_related_conv on model.56.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 261, 264, 265, 266, 267, 268, 269, 271, 272, 274, 275, 277, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 295, 296, 297, 298, 299, 300, 302, 304, 305, 306, 307, 308, 309, 312, 313, 314, 316, 317, 318, 321, 322, 323, 324, 326, 327, 328, 332], NumPruned=13568]
54378 parameters will be pruned
-------------

2023-04-04 16:48:50.707 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.54.conv (Conv2d(93, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=16647]
[ <DEP: prune_conv => prune_batchnorm on model.54.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 280])>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.57.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=45824]
[ <DEP: _prune_concat => prune_related_conv on model.56.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=45824]
108653 parameters will be pruned
-------------

2023-04-04 16:48:50.720 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.54.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.54.conv (Conv2d(93, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=4929]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 77, 101])>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.57.conv (Conv2d(101, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=13568]
[ <DEP: _prune_concat => prune_related_conv on model.56.conv (Conv2d(101, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=13568]
32171 parameters will be pruned
-------------

2023-04-04 16:48:50.721 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.56.conv (Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 34, 37, 38, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 67, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 92, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 128, 130, 131, 132, 133, 136, 138, 140, 141, 143, 145, 147, 148, 149, 151, 152, 154, 155, 156, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 176, 177, 178, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 208, 209, 210, 211, 213, 214, 215, 216, 217, 219, 220, 221, 223, 225, 226, 228, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 252, 253, 254], NumPruned=8592]
[ <DEP: prune_conv => prune_batchnorm on model.56.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 34, 37, 38, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 67, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 92, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 128, 130, 131, 132, 133, 136, 138, 140, 141, 143, 145, 147, 148, 149, 151, 152, 154, 155, 156, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 176, 177, 178, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 208, 209, 210, 211, 213, 214, 215, 216, 217, 219, 220, 221, 223, 225, 226, 228, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 252, 253, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 34, 37, 38, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 67, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 92, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 128, 130, 131, 132, 133, 136, 138, 140, 141, 143, 145, 147, 148, 149, 151, 152, 154, 155, 156, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 176, 177, 178, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 208, 209, 210, 211, 213, 214, 215, 216, 217, 219, 220, 221, 223, 225, 226, 228, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 252, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 1024])>, Index=[768, 769, 771, 773, 774, 775, 776, 777, 781, 782, 783, 785, 786, 788, 789, 791, 792, 793, 794, 795, 796, 797, 799, 802, 805, 806, 808, 809, 810, 812, 813, 815, 816, 818, 820, 821, 822, 823, 824, 825, 826, 829, 830, 831, 832, 835, 837, 838, 839, 843, 844, 845, 846, 847, 848, 849, 850, 852, 855, 856, 857, 860, 863, 864, 865, 866, 868, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 881, 882, 883, 884, 885, 889, 890, 891, 892, 893, 894, 896, 898, 899, 900, 901, 904, 906, 908, 909, 911, 913, 915, 916, 917, 919, 920, 922, 923, 924, 927, 928, 929, 930, 931, 932, 934, 935, 936, 938, 939, 940, 941, 942, 944, 945, 946, 949, 950, 951, 952, 953, 955, 956, 957, 959, 960, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 976, 977, 978, 979, 981, 982, 983, 984, 985, 987, 988, 989, 991, 993, 994, 996, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1017, 1020, 1021, 1022], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 769, 771, 773, 774, 775, 776, 777, 781, 782, 783, 785, 786, 788, 789, 791, 792, 793, 794, 795, 796, 797, 799, 802, 805, 806, 808, 809, 810, 812, 813, 815, 816, 818, 820, 821, 822, 823, 824, 825, 826, 829, 830, 831, 832, 835, 837, 838, 839, 843, 844, 845, 846, 847, 848, 849, 850, 852, 855, 856, 857, 860, 863, 864, 865, 866, 868, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 881, 882, 883, 884, 885, 889, 890, 891, 892, 893, 894, 896, 898, 899, 900, 901, 904, 906, 908, 909, 911, 913, 915, 916, 917, 919, 920, 922, 923, 924, 927, 928, 929, 930, 931, 932, 934, 935, 936, 938, 939, 940, 941, 942, 944, 945, 946, 949, 950, 951, 952, 953, 955, 956, 957, 959, 960, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 976, 977, 978, 979, 981, 982, 983, 984, 985, 987, 988, 989, 991, 993, 994, 996, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1017, 1020, 1021, 1022], NumPruned=45824]
54774 parameters will be pruned
-------------

2023-04-04 16:48:50.736 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.56.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 5, 7, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 47, 48, 49, 51, 53, 54, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.56.conv (Conv2d(48, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 5, 7, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 47, 48, 49, 51, 53, 54, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=2544]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 5, 7, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 47, 48, 49, 51, 53, 54, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 845])>, Index=[769, 771, 773, 775, 777, 778, 779, 780, 782, 783, 786, 787, 788, 789, 791, 792, 793, 794, 797, 798, 799, 800, 801, 802, 803, 804, 807, 808, 809, 811, 812, 815, 816, 817, 819, 821, 822, 824, 826, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(845, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[769, 771, 773, 775, 777, 778, 779, 780, 782, 783, 786, 787, 788, 789, 791, 792, 793, 794, 797, 798, 799, 800, 801, 802, 803, 804, 807, 808, 809, 811, 812, 815, 816, 817, 819, 821, 822, 824, 826, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844], NumPruned=13568]
16218 parameters will be pruned
-------------

2023-04-04 16:48:50.738 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.57.conv (Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 50, 51, 52, 54, 55, 58, 59, 62, 64, 66, 67, 68, 69, 71, 73, 77, 78, 80, 81, 82, 86, 87, 88, 89, 90, 92, 93, 94, 95, 98, 99, 102, 103, 105, 107, 108, 109, 111, 112, 113, 114, 117, 118, 119, 121, 122, 123, 124, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 143, 144, 145, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 171, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 216, 218, 219, 220, 221, 222, 226, 227, 228, 230, 231, 232, 234, 235, 236, 237, 239, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=8592]
[ <DEP: prune_conv => prune_batchnorm on model.57.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 50, 51, 52, 54, 55, 58, 59, 62, 64, 66, 67, 68, 69, 71, 73, 77, 78, 80, 81, 82, 86, 87, 88, 89, 90, 92, 93, 94, 95, 98, 99, 102, 103, 105, 107, 108, 109, 111, 112, 113, 114, 117, 118, 119, 121, 122, 123, 124, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 143, 144, 145, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 171, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 216, 218, 219, 220, 221, 222, 226, 227, 228, 230, 231, 232, 234, 235, 236, 237, 239, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 50, 51, 52, 54, 55, 58, 59, 62, 64, 66, 67, 68, 69, 71, 73, 77, 78, 80, 81, 82, 86, 87, 88, 89, 90, 92, 93, 94, 95, 98, 99, 102, 103, 105, 107, 108, 109, 111, 112, 113, 114, 117, 118, 119, 121, 122, 123, 124, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 143, 144, 145, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 171, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 216, 218, 219, 220, 221, 222, 226, 227, 228, 230, 231, 232, 234, 235, 236, 237, 239, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.58.conv (Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 50, 51, 52, 54, 55, 58, 59, 62, 64, 66, 67, 68, 69, 71, 73, 77, 78, 80, 81, 82, 86, 87, 88, 89, 90, 92, 93, 94, 95, 98, 99, 102, 103, 105, 107, 108, 109, 111, 112, 113, 114, 117, 118, 119, 121, 122, 123, 124, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 143, 144, 145, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 171, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 216, 218, 219, 220, 221, 222, 226, 227, 228, 230, 231, 232, 234, 235, 236, 237, 239, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=206208]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 792])>, Index=[512, 513, 514, 515, 516, 517, 519, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 539, 540, 541, 543, 545, 546, 548, 549, 550, 551, 552, 554, 556, 557, 559, 560, 562, 563, 564, 566, 567, 570, 571, 574, 576, 578, 579, 580, 581, 583, 585, 589, 590, 592, 593, 594, 598, 599, 600, 601, 602, 604, 605, 606, 607, 610, 611, 614, 615, 617, 619, 620, 621, 623, 624, 625, 626, 629, 630, 631, 633, 634, 635, 636, 638, 641, 642, 643, 644, 645, 647, 648, 649, 650, 651, 653, 655, 656, 657, 660, 661, 662, 665, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 678, 679, 680, 681, 683, 685, 686, 688, 689, 690, 692, 693, 694, 695, 696, 698, 699, 700, 701, 702, 703, 704, 705, 707, 708, 709, 713, 714, 715, 717, 718, 719, 721, 722, 723, 724, 725, 728, 730, 731, 732, 733, 734, 738, 739, 740, 742, 743, 744, 746, 747, 748, 749, 751, 753, 754, 755, 757, 758, 759, 760, 761, 762, 764, 765, 766, 767], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(792, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 513, 514, 515, 516, 517, 519, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 539, 540, 541, 543, 545, 546, 548, 549, 550, 551, 552, 554, 556, 557, 559, 560, 562, 563, 564, 566, 567, 570, 571, 574, 576, 578, 579, 580, 581, 583, 585, 589, 590, 592, 593, 594, 598, 599, 600, 601, 602, 604, 605, 606, 607, 610, 611, 614, 615, 617, 619, 620, 621, 623, 624, 625, 626, 629, 630, 631, 633, 634, 635, 636, 638, 641, 642, 643, 644, 645, 647, 648, 649, 650, 651, 653, 655, 656, 657, 660, 661, 662, 665, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 678, 679, 680, 681, 683, 685, 686, 688, 689, 690, 692, 693, 694, 695, 696, 698, 699, 700, 701, 702, 703, 704, 705, 707, 708, 709, 713, 714, 715, 717, 718, 719, 721, 722, 723, 724, 725, 728, 730, 731, 732, 733, 734, 738, 739, 740, 742, 743, 744, 746, 747, 748, 749, 751, 753, 754, 755, 757, 758, 759, 760, 761, 762, 764, 765, 766, 767], NumPruned=45824]
260982 parameters will be pruned
-------------

2023-04-04 16:48:50.752 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.57.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 31, 33, 34, 35, 36, 38, 39, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 64, 65, 67, 68, 69, 71, 72, 74, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.57.conv (Conv2d(48, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 31, 33, 34, 35, 36, 38, 39, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 64, 65, 67, 68, 69, 71, 72, 74, 76], NumPruned=2544]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 31, 33, 34, 35, 36, 38, 39, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 64, 65, 67, 68, 69, 71, 72, 74, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.58.conv (Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 31, 33, 34, 35, 36, 38, 39, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 64, 65, 67, 68, 69, 71, 72, 74, 76], NumPruned=61056]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 589, 613])>, Index=[512, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 528, 529, 530, 531, 533, 534, 535, 536, 538, 539, 543, 545, 546, 547, 548, 550, 551, 552, 558, 559, 560, 561, 562, 563, 564, 565, 566, 568, 570, 571, 572, 576, 577, 579, 580, 581, 583, 584, 586, 588], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(613, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 528, 529, 530, 531, 533, 534, 535, 536, 538, 539, 543, 545, 546, 547, 548, 550, 551, 552, 558, 559, 560, 561, 562, 563, 564, 565, 566, 568, 570, 571, 572, 576, 577, 579, 580, 581, 583, 584, 586, 588], NumPruned=13568]
77274 parameters will be pruned
-------------

2023-04-04 16:48:50.754 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.58.conv (Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 7, 8, 10, 13, 14, 16, 18, 19, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 67, 69, 70, 71, 72, 73, 74, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 112, 114, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127], NumPruned=19224]
[ <DEP: prune_conv => prune_batchnorm on model.58.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 7, 8, 10, 13, 14, 16, 18, 19, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 67, 69, 70, 71, 72, 73, 74, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 112, 114, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 7, 8, 10, 13, 14, 16, 18, 19, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 67, 69, 70, 71, 72, 73, 74, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 112, 114, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.59.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 7, 8, 10, 13, 14, 16, 18, 19, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 67, 69, 70, 71, 72, 73, 74, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 112, 114, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 536, 560])>, Index=[384, 385, 387, 388, 391, 392, 394, 397, 398, 400, 402, 403, 405, 407, 408, 410, 411, 413, 414, 415, 416, 417, 418, 419, 425, 426, 427, 428, 429, 431, 432, 433, 434, 436, 437, 438, 439, 440, 441, 442, 443, 447, 448, 451, 453, 454, 455, 456, 457, 458, 461, 462, 464, 466, 467, 468, 469, 471, 472, 473, 474, 476, 477, 478, 480, 481, 482, 484, 485, 487, 488, 489, 490, 491, 492, 493, 496, 498, 499, 500, 501, 502, 503, 505, 506, 508, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(560, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 385, 387, 388, 391, 392, 394, 397, 398, 400, 402, 403, 405, 407, 408, 410, 411, 413, 414, 415, 416, 417, 418, 419, 425, 426, 427, 428, 429, 431, 432, 433, 434, 436, 437, 438, 439, 440, 441, 442, 443, 447, 448, 451, 453, 454, 455, 456, 457, 458, 461, 462, 464, 466, 467, 468, 469, 471, 472, 473, 474, 476, 477, 478, 480, 481, 482, 484, 485, 487, 488, 489, 490, 491, 492, 493, 496, 498, 499, 500, 501, 502, 503, 505, 506, 508, 509, 510, 511], NumPruned=22784]
144714 parameters will be pruned
-------------

2023-04-04 16:48:50.768 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.58.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 14, 16, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 35, 36, 37], NumPruned=56]
[ <DEP: prune_batchnorm => prune_conv on model.58.conv (Conv2d(24, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 14, 16, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 35, 36, 37], NumPruned=6048]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 14, 16, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 35, 36, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.59.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 14, 16, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 35, 36, 37], NumPruned=32256]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 423, 447, 471])>, Index=[384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 398, 400, 402, 403, 405, 406, 407, 408, 409, 411, 412, 414, 415, 416, 419, 420, 421], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(471, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 398, 400, 402, 403, 405, 406, 407, 408, 409, 411, 412, 414, 415, 416, 419, 420, 421], NumPruned=7168]
45528 parameters will be pruned
-------------

2023-04-04 16:48:50.769 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.59.conv (Conv2d(11, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 6, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 60, 64, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 107, 108, 109, 110, 113, 115, 117, 118, 119, 122, 124, 125, 126], NumPruned=8811]
[ <DEP: prune_conv => prune_batchnorm on model.59.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 6, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 60, 64, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 107, 108, 109, 110, 113, 115, 117, 118, 119, 122, 124, 125, 126], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 6, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 60, 64, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 107, 108, 109, 110, 113, 115, 117, 118, 119, 122, 124, 125, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.60.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 6, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 60, 64, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 107, 108, 109, 110, 113, 115, 117, 118, 119, 122, 124, 125, 126], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 395, 419, 443])>, Index=[257, 259, 260, 262, 265, 266, 267, 268, 269, 272, 274, 275, 276, 277, 278, 280, 281, 282, 283, 285, 286, 287, 288, 289, 291, 292, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 309, 310, 311, 312, 313, 314, 316, 320, 321, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 337, 338, 339, 341, 342, 343, 344, 345, 348, 349, 350, 351, 352, 354, 355, 356, 358, 360, 361, 363, 364, 365, 366, 369, 371, 373, 374, 375, 378, 380, 381, 382], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(443, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 259, 260, 262, 265, 266, 267, 268, 269, 272, 274, 275, 276, 277, 278, 280, 281, 282, 283, 285, 286, 287, 288, 289, 291, 292, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 309, 310, 311, 312, 313, 314, 316, 320, 321, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 337, 338, 339, 341, 342, 343, 344, 345, 348, 349, 350, 351, 352, 354, 355, 356, 358, 360, 361, 363, 364, 365, 366, 369, 371, 373, 374, 375, 378, 380, 381, 382], NumPruned=22784]
134301 parameters will be pruned
-------------

2023-04-04 16:48:50.784 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.59.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 6, 7, 8, 10, 11, 13, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.59.conv (Conv2d(11, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 6, 7, 8, 10, 11, 13, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38], NumPruned=2673]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 6, 7, 8, 10, 11, 13, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.60.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 6, 7, 8, 10, 11, 13, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 295, 306, 330, 354])>, Index=[257, 258, 259, 262, 263, 264, 266, 267, 269, 272, 273, 274, 276, 277, 278, 280, 281, 282, 283, 284, 285, 289, 290, 291, 292, 293, 294], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(354, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 259, 262, 263, 264, 266, 267, 269, 272, 273, 274, 276, 277, 278, 280, 281, 282, 283, 284, 285, 289, 290, 291, 292, 293, 294], NumPruned=6912]
40743 parameters will be pruned
-------------

2023-04-04 16:48:50.785 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.60.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 44, 46, 47, 51, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 71, 72, 73, 74, 76, 78, 79, 81, 82, 84, 86, 87, 88, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 118, 119, 121, 124, 125, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.60.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 44, 46, 47, 51, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 71, 72, 73, 74, 76, 78, 79, 81, 82, 84, 86, 87, 88, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 118, 119, 121, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 44, 46, 47, 51, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 71, 72, 73, 74, 76, 78, 79, 81, 82, 84, 86, 87, 88, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 118, 119, 121, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.61.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 44, 46, 47, 51, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 71, 72, 73, 74, 76, 78, 79, 81, 82, 84, 86, 87, 88, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 118, 119, 121, 124, 125, 126, 127], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 268, 279, 303, 327])>, Index=[128, 129, 130, 131, 133, 134, 136, 137, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 167, 169, 170, 172, 174, 175, 179, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 196, 199, 200, 201, 202, 204, 206, 207, 209, 210, 212, 214, 215, 216, 219, 220, 221, 222, 225, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 240, 241, 243, 244, 246, 247, 249, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(327, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 133, 134, 136, 137, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 167, 169, 170, 172, 174, 175, 179, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 196, 199, 200, 201, 202, 204, 206, 207, 209, 210, 212, 214, 215, 216, 219, 220, 221, 222, 225, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 240, 241, 243, 244, 246, 247, 249, 252, 253, 254, 255], NumPruned=22784]
135102 parameters will be pruned
-------------

2023-04-04 16:48:50.799 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.60.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 22, 25, 27, 30, 31, 32, 33, 35, 37], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.60.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 22, 25, 27, 30, 31, 32, 33, 35, 37], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 22, 25, 27, 30, 31, 32, 33, 35, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.61.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 22, 25, 27, 30, 31, 32, 33, 35, 37], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 167, 179, 190, 214, 238])>, Index=[128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 147, 148, 150, 153, 155, 158, 159, 160, 161, 163, 165], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(238, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 147, 148, 150, 153, 155, 158, 159, 160, 161, 163, 165], NumPruned=6912]
40986 parameters will be pruned
-------------

2023-04-04 16:48:50.800 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.61.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[3, 4, 9, 10, 12, 14, 15, 18, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.61.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[3, 4, 9, 10, 12, 14, 15, 18, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[3, 4, 9, 10, 12, 14, 15, 18, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 140, 152, 163, 187, 211])>, Index=[3, 4, 9, 10, 12, 14, 15, 18, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(211, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[3, 4, 9, 10, 12, 14, 15, 18, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=22784]
32574 parameters will be pruned
-------------

2023-04-04 16:48:50.815 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.61.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 5, 6, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.61.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 5, 6, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 5, 6, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 39, 51, 63, 74, 98, 122])>, Index=[1, 2, 3, 5, 6, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(122, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 5, 6, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38], NumPruned=6912]
9882 parameters will be pruned
-------------

2023-04-04 16:48:50.816 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.63.conv (Conv2d(95, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 21, 22, 23, 25, 27, 28, 30, 32, 33, 35, 37, 40, 43, 44, 45, 48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 89, 91, 92, 93, 95, 96, 98, 99, 100, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 123, 124, 125, 127, 130, 131, 133, 134, 135, 136, 138, 140, 142, 143, 145, 146, 147, 149, 150, 151, 152, 153, 156, 158, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 176, 178, 179, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 208, 209, 210, 211, 213, 215, 216, 218, 219, 220, 221, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 250, 251, 253, 254, 255], NumPruned=17005]
[ <DEP: prune_conv => prune_batchnorm on model.63.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 21, 22, 23, 25, 27, 28, 30, 32, 33, 35, 37, 40, 43, 44, 45, 48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 89, 91, 92, 93, 95, 96, 98, 99, 100, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 123, 124, 125, 127, 130, 131, 133, 134, 135, 136, 138, 140, 142, 143, 145, 146, 147, 149, 150, 151, 152, 153, 156, 158, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 176, 178, 179, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 208, 209, 210, 211, 213, 215, 216, 218, 219, 220, 221, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 250, 251, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 21, 22, 23, 25, 27, 28, 30, 32, 33, 35, 37, 40, 43, 44, 45, 48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 89, 91, 92, 93, 95, 96, 98, 99, 100, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 123, 124, 125, 127, 130, 131, 133, 134, 135, 136, 138, 140, 142, 143, 145, 146, 147, 149, 150, 151, 152, 153, 156, 158, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 176, 178, 179, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 208, 209, 210, 211, 213, 215, 216, 218, 219, 220, 221, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 250, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.64.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 21, 22, 23, 25, 27, 28, 30, 32, 33, 35, 37, 40, 43, 44, 45, 48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 89, 91, 92, 93, 95, 96, 98, 99, 100, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 123, 124, 125, 127, 130, 131, 133, 134, 135, 136, 138, 140, 142, 143, 145, 146, 147, 149, 150, 151, 152, 153, 156, 158, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 176, 178, 179, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 208, 209, 210, 211, 213, 215, 216, 218, 219, 220, 221, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 250, 251, 253, 254, 255], NumPruned=22912]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 512])>, Index=[257, 258, 259, 260, 262, 263, 264, 265, 266, 268, 269, 270, 271, 273, 274, 277, 278, 279, 281, 283, 284, 286, 288, 289, 291, 293, 296, 299, 300, 301, 304, 305, 306, 307, 308, 311, 313, 314, 315, 316, 317, 318, 319, 321, 324, 325, 326, 327, 329, 331, 332, 333, 335, 336, 338, 339, 340, 341, 342, 345, 347, 348, 349, 351, 352, 354, 355, 356, 358, 359, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 374, 375, 376, 377, 379, 380, 381, 383, 386, 387, 389, 390, 391, 392, 394, 396, 398, 399, 401, 402, 403, 405, 406, 407, 408, 409, 412, 414, 418, 419, 420, 422, 423, 424, 425, 426, 427, 429, 430, 432, 434, 435, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 460, 461, 464, 465, 466, 467, 469, 471, 472, 474, 475, 476, 477, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 492, 493, 494, 495, 496, 497, 499, 500, 501, 502, 503, 506, 507, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 259, 260, 262, 263, 264, 265, 266, 268, 269, 270, 271, 273, 274, 277, 278, 279, 281, 283, 284, 286, 288, 289, 291, 293, 296, 299, 300, 301, 304, 305, 306, 307, 308, 311, 313, 314, 315, 316, 317, 318, 319, 321, 324, 325, 326, 327, 329, 331, 332, 333, 335, 336, 338, 339, 340, 341, 342, 345, 347, 348, 349, 351, 352, 354, 355, 356, 358, 359, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 374, 375, 376, 377, 379, 380, 381, 383, 386, 387, 389, 390, 391, 392, 394, 396, 398, 399, 401, 402, 403, 405, 406, 407, 408, 409, 412, 414, 418, 419, 420, 422, 423, 424, 425, 426, 427, 429, 430, 432, 434, 435, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 460, 461, 464, 465, 466, 467, 469, 471, 472, 474, 475, 476, 477, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 492, 493, 494, 495, 496, 497, 499, 500, 501, 502, 503, 506, 507, 509, 510, 511], NumPruned=45824]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 259, 260, 262, 263, 264, 265, 266, 268, 269, 270, 271, 273, 274, 277, 278, 279, 281, 283, 284, 286, 288, 289, 291, 293, 296, 299, 300, 301, 304, 305, 306, 307, 308, 311, 313, 314, 315, 316, 317, 318, 319, 321, 324, 325, 326, 327, 329, 331, 332, 333, 335, 336, 338, 339, 340, 341, 342, 345, 347, 348, 349, 351, 352, 354, 355, 356, 358, 359, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 374, 375, 376, 377, 379, 380, 381, 383, 386, 387, 389, 390, 391, 392, 394, 396, 398, 399, 401, 402, 403, 405, 406, 407, 408, 409, 412, 414, 418, 419, 420, 422, 423, 424, 425, 426, 427, 429, 430, 432, 434, 435, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 460, 461, 464, 465, 466, 467, 469, 471, 472, 474, 475, 476, 477, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 492, 493, 494, 495, 496, 497, 499, 500, 501, 502, 503, 506, 507, 509, 510, 511], NumPruned=45824]
131923 parameters will be pruned
-------------

2023-04-04 16:48:50.830 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.63.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 58, 59, 61, 62, 66, 68, 69, 70, 72, 74], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.63.conv (Conv2d(95, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 58, 59, 61, 62, 66, 68, 69, 70, 72, 74], NumPruned=5035]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 58, 59, 61, 62, 66, 68, 69, 70, 72, 74], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.64.conv (Conv2d(77, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 58, 59, 61, 62, 66, 68, 69, 70, 72, 74], NumPruned=6784]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 333])>, Index=[256, 257, 260, 261, 262, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 282, 284, 286, 287, 288, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 302, 303, 307, 308, 309, 310, 311, 314, 315, 317, 318, 322, 324, 325, 326, 328, 330], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 260, 261, 262, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 282, 284, 286, 287, 288, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 302, 303, 307, 308, 309, 310, 311, 314, 315, 317, 318, 322, 324, 325, 326, 328, 330], NumPruned=13568]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 260, 261, 262, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 282, 284, 286, 287, 288, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 302, 303, 307, 308, 309, 310, 311, 314, 315, 317, 318, 322, 324, 325, 326, 328, 330], NumPruned=13568]
39061 parameters will be pruned
-------------

2023-04-04 16:48:50.831 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.64.conv (Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 37, 39, 40, 41, 42, 44, 45, 47, 50, 52, 53, 54, 55, 56, 58, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 89, 91, 93, 94, 95, 100, 101, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 120, 122, 123, 126, 127], NumPruned=2136]
[ <DEP: prune_conv => prune_batchnorm on model.64.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 37, 39, 40, 41, 42, 44, 45, 47, 50, 52, 53, 54, 55, 56, 58, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 89, 91, 93, 94, 95, 100, 101, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 120, 122, 123, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 37, 39, 40, 41, 42, 44, 45, 47, 50, 52, 53, 54, 55, 56, 58, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 89, 91, 93, 94, 95, 100, 101, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 120, 122, 123, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 37, 39, 40, 41, 42, 44, 45, 47, 50, 52, 53, 54, 55, 56, 58, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 89, 91, 93, 94, 95, 100, 101, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 120, 122, 123, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256])>, Index=[128, 129, 130, 131, 132, 133, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 158, 160, 161, 162, 165, 167, 168, 169, 170, 172, 173, 175, 178, 180, 181, 182, 183, 184, 186, 191, 192, 193, 194, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 210, 212, 213, 214, 215, 217, 219, 221, 222, 223, 228, 229, 230, 231, 233, 234, 235, 236, 238, 239, 240, 241, 242, 243, 244, 245, 248, 250, 251, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.69.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 158, 160, 161, 162, 165, 167, 168, 169, 170, 172, 173, 175, 178, 180, 181, 182, 183, 184, 186, 191, 192, 193, 194, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 210, 212, 213, 214, 215, 217, 219, 221, 222, 223, 228, 229, 230, 231, 233, 234, 235, 236, 238, 239, 240, 241, 242, 243, 244, 245, 248, 250, 251, 254, 255], NumPruned=11392]
[ <DEP: _prune_concat => prune_related_conv on model.68.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 158, 160, 161, 162, 165, 167, 168, 169, 170, 172, 173, 175, 178, 180, 181, 182, 183, 184, 186, 191, 192, 193, 194, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 210, 212, 213, 214, 215, 217, 219, 221, 222, 223, 228, 229, 230, 231, 233, 234, 235, 236, 238, 239, 240, 241, 242, 243, 244, 245, 248, 250, 251, 254, 255], NumPruned=11392]
25098 parameters will be pruned
-------------

2023-04-04 16:48:50.845 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.64.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 34, 35, 36], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.64.conv (Conv2d(24, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 34, 35, 36], NumPruned=648]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 34, 35, 36], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 34, 35, 36], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 167])>, Index=[130, 131, 132, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 155, 158, 160, 161, 162, 163, 164], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.69.conv (Conv2d(167, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[130, 131, 132, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 155, 158, 160, 161, 162, 163, 164], NumPruned=3456]
[ <DEP: _prune_concat => prune_related_conv on model.68.conv (Conv2d(167, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[130, 131, 132, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 155, 158, 160, 161, 162, 163, 164], NumPruned=3456]
7614 parameters will be pruned
-------------

2023-04-04 16:48:50.846 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.66.conv (Conv2d(47, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=4183]
[ <DEP: prune_conv => prune_batchnorm on model.66.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 140])>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.69.conv (Conv2d(140, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=11392]
[ <DEP: _prune_concat => prune_related_conv on model.68.conv (Conv2d(140, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=11392]
27145 parameters will be pruned
-------------

2023-04-04 16:48:50.861 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.66.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.66.conv (Conv2d(47, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=1269]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 39, 51])>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.69.conv (Conv2d(51, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=3456]
[ <DEP: _prune_concat => prune_related_conv on model.68.conv (Conv2d(51, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=3456]
8235 parameters will be pruned
-------------

2023-04-04 16:48:50.862 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.68.conv (Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 35, 37, 38, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 59, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 97, 100, 101, 102, 108, 109, 110, 112, 113, 114, 117, 118, 119, 120, 121, 125, 126, 127], NumPruned=2136]
[ <DEP: prune_conv => prune_batchnorm on model.68.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 35, 37, 38, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 59, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 97, 100, 101, 102, 108, 109, 110, 112, 113, 114, 117, 118, 119, 120, 121, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 35, 37, 38, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 59, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 97, 100, 101, 102, 108, 109, 110, 112, 113, 114, 117, 118, 119, 120, 121, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256, 384, 512])>, Index=[384, 385, 390, 391, 392, 393, 394, 395, 397, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 415, 416, 417, 419, 421, 422, 425, 426, 429, 430, 431, 432, 433, 434, 435, 436, 437, 440, 442, 443, 445, 446, 447, 448, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 466, 467, 468, 469, 470, 471, 474, 476, 477, 478, 479, 480, 481, 484, 485, 486, 492, 493, 494, 496, 497, 498, 501, 502, 503, 504, 505, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 385, 390, 391, 392, 393, 394, 395, 397, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 415, 416, 417, 419, 421, 422, 425, 426, 429, 430, 431, 432, 433, 434, 435, 436, 437, 440, 442, 443, 445, 446, 447, 448, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 466, 467, 468, 469, 470, 471, 474, 476, 477, 478, 479, 480, 481, 484, 485, 486, 492, 493, 494, 496, 497, 498, 501, 502, 503, 504, 505, 509, 510, 511], NumPruned=11392]
13706 parameters will be pruned
-------------

2023-04-04 16:48:50.877 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.68.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 12, 15, 16, 17, 20, 21, 22, 23, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.68.conv (Conv2d(24, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 12, 15, 16, 17, 20, 21, 22, 23, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37], NumPruned=648]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 12, 15, 16, 17, 20, 21, 22, 23, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256, 384, 423])>, Index=[384, 385, 386, 387, 389, 390, 392, 393, 394, 396, 399, 400, 401, 404, 405, 406, 407, 409, 411, 413, 414, 416, 417, 418, 419, 420, 421], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(423, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 385, 386, 387, 389, 390, 392, 393, 394, 396, 399, 400, 401, 404, 405, 406, 407, 409, 411, 413, 414, 416, 417, 418, 419, 420, 421], NumPruned=3456]
4158 parameters will be pruned
-------------

2023-04-04 16:48:50.878 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.69.conv (Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 7, 11, 12, 13, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 59, 60, 61, 62, 64, 66, 67, 68, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 122, 123, 127], NumPruned=2136]
[ <DEP: prune_conv => prune_batchnorm on model.69.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 6, 7, 11, 12, 13, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 59, 60, 61, 62, 64, 66, 67, 68, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 122, 123, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 6, 7, 11, 12, 13, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 59, 60, 61, 62, 64, 66, 67, 68, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 122, 123, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.70.conv (Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 7, 11, 12, 13, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 59, 60, 61, 62, 64, 66, 67, 68, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 122, 123, 127], NumPruned=51264]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256, 384, 396])>, Index=[256, 257, 259, 260, 262, 263, 267, 268, 269, 271, 272, 273, 275, 276, 277, 279, 282, 283, 284, 285, 287, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 303, 304, 305, 307, 309, 311, 312, 315, 316, 317, 318, 320, 322, 323, 324, 328, 329, 330, 331, 333, 334, 335, 337, 338, 339, 341, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 356, 358, 359, 360, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 383], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(396, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 259, 260, 262, 263, 267, 268, 269, 271, 272, 273, 275, 276, 277, 279, 282, 283, 284, 285, 287, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 303, 304, 305, 307, 309, 311, 312, 315, 316, 317, 318, 320, 322, 323, 324, 328, 329, 330, 331, 333, 334, 335, 337, 338, 339, 341, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 356, 358, 359, 360, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 383], NumPruned=11392]
64970 parameters will be pruned
-------------

2023-04-04 16:48:50.894 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.69.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 5, 6, 7, 8, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 27, 29, 30, 31, 33, 34, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.69.conv (Conv2d(24, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 5, 6, 7, 8, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 27, 29, 30, 31, 33, 34, 36, 37, 38], NumPruned=648]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 5, 6, 7, 8, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 27, 29, 30, 31, 33, 34, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.70.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 5, 6, 7, 8, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 27, 29, 30, 31, 33, 34, 36, 37, 38], NumPruned=15552]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256, 295, 307])>, Index=[256, 257, 258, 261, 262, 263, 264, 267, 268, 269, 271, 272, 273, 274, 276, 277, 279, 280, 283, 285, 286, 287, 289, 290, 292, 293, 294], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(307, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 261, 262, 263, 264, 267, 268, 269, 271, 272, 273, 274, 276, 277, 279, 280, 283, 285, 286, 287, 289, 290, 292, 293, 294], NumPruned=3456]
19710 parameters will be pruned
-------------

2023-04-04 16:48:50.896 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.70.conv (Conv2d(12, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 6, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 31, 32, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 56, 58, 59, 60, 62, 63], NumPruned=4752]
[ <DEP: prune_conv => prune_batchnorm on model.70.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 6, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 31, 32, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 56, 58, 59, 60, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 6, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 31, 32, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 56, 58, 59, 60, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.71.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 6, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 31, 32, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 56, 58, 59, 60, 62, 63], NumPruned=25344]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256, 268, 280])>, Index=[193, 195, 198, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 215, 217, 218, 219, 220, 221, 223, 224, 227, 228, 230, 231, 233, 234, 235, 236, 237, 238, 240, 241, 242, 244, 245, 248, 250, 251, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[193, 195, 198, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 215, 217, 218, 219, 220, 221, 223, 224, 227, 228, 230, 231, 233, 234, 235, 236, 237, 238, 240, 241, 242, 244, 245, 248, 250, 251, 252, 254, 255], NumPruned=5632]
35816 parameters will be pruned
-------------

2023-04-04 16:48:50.897 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.70.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 16, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.70.conv (Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 16, 18, 19], NumPruned=1512]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 16, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.71.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 16, 18, 19], NumPruned=8064]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 212, 224, 236])>, Index=[193, 194, 195, 196, 197, 198, 199, 203, 204, 205, 206, 208, 210, 211], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(236, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[193, 194, 195, 196, 197, 198, 199, 203, 204, 205, 206, 208, 210, 211], NumPruned=1792]
11396 parameters will be pruned
-------------

2023-04-04 16:48:50.910 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.71.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 45, 47, 48, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.71.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 45, 47, 48, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 45, 47, 48, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.72.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 45, 47, 48, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62], NumPruned=25344]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 198, 210, 222])>, Index=[129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 165, 173, 175, 176, 179, 181, 182, 183, 184, 185, 187, 188, 189, 190], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(222, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 165, 173, 175, 176, 179, 181, 182, 183, 184, 185, 187, 188, 189, 190], NumPruned=5632]
33440 parameters will be pruned
-------------

2023-04-04 16:48:50.912 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.71.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 7, 9, 12, 13, 14, 15, 17, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.71.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 9, 12, 13, 14, 15, 17, 18, 19], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 9, 12, 13, 14, 15, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.72.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 9, 12, 13, 14, 15, 17, 18, 19], NumPruned=8064]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 148, 154, 166, 178])>, Index=[128, 130, 132, 133, 134, 135, 137, 140, 141, 142, 143, 145, 146, 147], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(178, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 130, 132, 133, 134, 135, 137, 140, 141, 142, 143, 145, 146, 147], NumPruned=1792]
10640 parameters will be pruned
-------------

2023-04-04 16:48:50.913 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.72.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 56, 57, 59, 60], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.72.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 56, 57, 59, 60], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 56, 57, 59, 60], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.73.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 56, 57, 59, 60], NumPruned=25344]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 134, 140, 152, 164])>, Index=[64, 67, 70, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 98, 99, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 116, 118, 120, 121, 123, 124], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(164, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 67, 70, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 98, 99, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 116, 118, 120, 121, 123, 124], NumPruned=5632]
33440 parameters will be pruned
-------------

2023-04-04 16:48:50.925 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.72.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 14, 15, 16, 18], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.72.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 14, 15, 16, 18], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 14, 15, 16, 18], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.73.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 14, 15, 16, 18], NumPruned=8064]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 84, 90, 96, 108, 120])>, Index=[64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 78, 79, 80, 82], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 78, 79, 80, 82], NumPruned=1792]
10640 parameters will be pruned
-------------

2023-04-04 16:48:50.926 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.73.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 42, 44, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 61, 62], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.73.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 42, 44, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 61, 62], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 42, 44, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 61, 62], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 70, 76, 82, 94, 106])>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 42, 44, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 61, 62], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(106, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 42, 44, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 61, 62], NumPruned=5632]
8096 parameters will be pruned
-------------

2023-04-04 16:48:50.927 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.73.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.73.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 20, 26, 32, 38, 50, 62])>, Index=[0, 2, 3, 4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(62, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], NumPruned=1792]
2576 parameters will be pruned
-------------

2023-04-04 16:48:50.940 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.75.conv (Conv2d(48, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=4272]
[ <DEP: prune_conv => prune_batchnorm on model.75.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.102.rbr_dense.0 (Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=205056]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.102.rbr_1x1.0 (Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=22784]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.78.conv (Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=11392]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.77.conv (Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=11392]
255074 parameters will be pruned
-------------

2023-04-04 16:48:50.957 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.75.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.75.conv (Conv2d(48, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=1296]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.102.rbr_dense.0 (Conv2d(39, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=62208]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.102.rbr_1x1.0 (Conv2d(39, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=6912]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.78.conv (Conv2d(39, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=3456]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.77.conv (Conv2d(39, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=3456]
77382 parameters will be pruned
-------------

2023-04-04 16:48:50.959 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.77.conv (Conv2d(12, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 64, 67, 68, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 84, 86, 87, 88, 91, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 126, 127], NumPruned=1068]
[ <DEP: prune_conv => prune_batchnorm on model.77.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 64, 67, 68, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 84, 86, 87, 88, 91, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 64, 67, 68, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 84, 86, 87, 88, 91, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 280])>, Index=[128, 129, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 150, 151, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 186, 192, 195, 196, 198, 199, 200, 201, 203, 204, 205, 207, 208, 209, 212, 214, 215, 216, 219, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 239, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 150, 151, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 186, 192, 195, 196, 198, 199, 200, 201, 203, 204, 205, 207, 208, 209, 212, 214, 215, 216, 219, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 239, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 252, 254, 255], NumPruned=22784]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 150, 151, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 186, 192, 195, 196, 198, 199, 200, 201, 203, 204, 205, 207, 208, 209, 212, 214, 215, 216, 219, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 239, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 252, 254, 255], NumPruned=22784]
46814 parameters will be pruned
-------------

2023-04-04 16:48:50.973 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.77.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 18, 20, 21, 24, 26, 27, 28, 29, 30, 31, 33, 35, 36], NumPruned=56]
[ <DEP: prune_batchnorm => prune_conv on model.77.conv (Conv2d(12, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 18, 20, 21, 24, 26, 27, 28, 29, 30, 31, 33, 35, 36], NumPruned=336]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 18, 20, 21, 24, 26, 27, 28, 29, 30, 31, 33, 35, 36], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 167, 191])>, Index=[128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 146, 148, 149, 152, 154, 155, 156, 157, 158, 159, 161, 163, 164], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(191, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 146, 148, 149, 152, 154, 155, 156, 157, 158, 159, 161, 163, 164], NumPruned=7168]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(191, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 146, 148, 149, 152, 154, 155, 156, 157, 158, 159, 161, 163, 164], NumPruned=7168]
14728 parameters will be pruned
-------------

2023-04-04 16:48:50.974 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.78.conv (Conv2d(12, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 20, 21, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 38, 41, 42, 43, 44, 46, 48, 49, 50, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 82, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 104, 105, 106, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=1068]
[ <DEP: prune_conv => prune_batchnorm on model.78.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 20, 21, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 38, 41, 42, 43, 44, 46, 48, 49, 50, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 82, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 104, 105, 106, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 20, 21, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 38, 41, 42, 43, 44, 46, 48, 49, 50, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 82, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 104, 105, 106, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.79.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 20, 21, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 38, 41, 42, 43, 44, 46, 48, 49, 50, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 82, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 104, 105, 106, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=102528]
103774 parameters will be pruned
-------------

2023-04-04 16:48:50.975 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.78.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 4, 5, 8, 9, 10, 11, 12, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.78.conv (Conv2d(12, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 8, 9, 10, 11, 12, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 35, 36, 37, 38], NumPruned=324]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 4, 5, 8, 9, 10, 11, 12, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.79.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 8, 9, 10, 11, 12, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 35, 36, 37, 38], NumPruned=31104]
31482 parameters will be pruned
-------------

2023-04-04 16:48:50.989 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.79.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.79.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 139, 163])>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(163, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=22784]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(163, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=22784]
55358 parameters will be pruned
-------------

2023-04-04 16:48:50.991 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.79.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.79.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 39, 50, 74])>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(74, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=6912]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(74, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=6912]
16794 parameters will be pruned
-------------

2023-04-04 16:48:51.005 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.81.conv (Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 72, 74, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 98, 100, 101, 103, 105, 106, 107, 108, 110, 111, 113, 114, 118, 119, 120, 122, 123, 125, 126, 127, 130, 132, 133, 135, 138, 140, 141, 143, 144, 145, 146, 148, 150, 152, 153, 155, 157, 158, 159, 160, 161, 162, 167, 168, 169, 172, 173, 174, 175, 178, 179, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 217, 218, 219, 220, 222, 223, 225, 226, 229, 230, 231, 232, 233, 234, 235, 238, 239, 244, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=8413]
[ <DEP: prune_conv => prune_batchnorm on model.81.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 72, 74, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 98, 100, 101, 103, 105, 106, 107, 108, 110, 111, 113, 114, 118, 119, 120, 122, 123, 125, 126, 127, 130, 132, 133, 135, 138, 140, 141, 143, 144, 145, 146, 148, 150, 152, 153, 155, 157, 158, 159, 160, 161, 162, 167, 168, 169, 172, 173, 174, 175, 178, 179, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 217, 218, 219, 220, 222, 223, 225, 226, 229, 230, 231, 232, 233, 234, 235, 238, 239, 244, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 72, 74, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 98, 100, 101, 103, 105, 106, 107, 108, 110, 111, 113, 114, 118, 119, 120, 122, 123, 125, 126, 127, 130, 132, 133, 135, 138, 140, 141, 143, 144, 145, 146, 148, 150, 152, 153, 155, 157, 158, 159, 160, 161, 162, 167, 168, 169, 172, 173, 174, 175, 178, 179, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 217, 218, 219, 220, 222, 223, 225, 226, 229, 230, 231, 232, 233, 234, 235, 238, 239, 244, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 1024])>, Index=[769, 771, 772, 773, 776, 777, 778, 779, 780, 781, 782, 783, 786, 787, 788, 789, 791, 792, 793, 794, 795, 796, 797, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 819, 820, 821, 823, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 837, 838, 840, 842, 844, 847, 848, 849, 850, 851, 852, 853, 854, 855, 858, 860, 861, 862, 863, 864, 866, 868, 869, 871, 873, 874, 875, 876, 878, 879, 881, 882, 886, 887, 888, 890, 891, 893, 894, 895, 898, 900, 901, 903, 906, 908, 909, 911, 912, 913, 914, 916, 918, 920, 921, 923, 925, 926, 927, 928, 929, 930, 935, 936, 937, 940, 941, 942, 943, 946, 947, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 965, 966, 968, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 985, 986, 987, 988, 990, 991, 993, 994, 997, 998, 999, 1000, 1001, 1002, 1003, 1006, 1007, 1012, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1023], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[769, 771, 772, 773, 776, 777, 778, 779, 780, 781, 782, 783, 786, 787, 788, 789, 791, 792, 793, 794, 795, 796, 797, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 819, 820, 821, 823, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 837, 838, 840, 842, 844, 847, 848, 849, 850, 851, 852, 853, 854, 855, 858, 860, 861, 862, 863, 864, 866, 868, 869, 871, 873, 874, 875, 876, 878, 879, 881, 882, 886, 887, 888, 890, 891, 893, 894, 895, 898, 900, 901, 903, 906, 908, 909, 911, 912, 913, 914, 916, 918, 920, 921, 923, 925, 926, 927, 928, 929, 930, 935, 936, 937, 940, 941, 942, 943, 946, 947, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 965, 966, 968, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 985, 986, 987, 988, 990, 991, 993, 994, 997, 998, 999, 1000, 1001, 1002, 1003, 1006, 1007, 1012, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1023], NumPruned=45824]
54595 parameters will be pruned
-------------

2023-04-04 16:48:51.020 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.81.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 5, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58, 60, 61, 63, 64, 65, 69, 70, 71, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.81.conv (Conv2d(47, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58, 60, 61, 63, 64, 65, 69, 70, 71, 74, 75, 76], NumPruned=2491]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58, 60, 61, 63, 64, 65, 69, 70, 71, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 845])>, Index=[768, 771, 772, 773, 775, 777, 778, 780, 781, 783, 785, 786, 787, 788, 789, 790, 791, 792, 793, 796, 798, 799, 800, 804, 805, 806, 807, 808, 809, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 822, 824, 826, 828, 829, 831, 832, 833, 837, 838, 839, 842, 843, 844], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(845, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 771, 772, 773, 775, 777, 778, 780, 781, 783, 785, 786, 787, 788, 789, 790, 791, 792, 793, 796, 798, 799, 800, 804, 805, 806, 807, 808, 809, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 822, 824, 826, 828, 829, 831, 832, 833, 837, 838, 839, 842, 843, 844], NumPruned=13568]
16165 parameters will be pruned
-------------

2023-04-04 16:48:51.022 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.82.conv (Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 24, 25, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 58, 59, 63, 65, 67, 68, 69, 71, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 93, 95, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 119, 121, 122, 123, 124, 126, 127, 130, 131, 133, 135, 136, 139, 140, 141, 142, 143, 144, 145, 148, 150, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 192, 193, 195, 196, 197, 200, 202, 204, 206, 209, 210, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=8413]
[ <DEP: prune_conv => prune_batchnorm on model.82.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 24, 25, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 58, 59, 63, 65, 67, 68, 69, 71, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 93, 95, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 119, 121, 122, 123, 124, 126, 127, 130, 131, 133, 135, 136, 139, 140, 141, 142, 143, 144, 145, 148, 150, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 192, 193, 195, 196, 197, 200, 202, 204, 206, 209, 210, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 24, 25, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 58, 59, 63, 65, 67, 68, 69, 71, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 93, 95, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 119, 121, 122, 123, 124, 126, 127, 130, 131, 133, 135, 136, 139, 140, 141, 142, 143, 144, 145, 148, 150, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 192, 193, 195, 196, 197, 200, 202, 204, 206, 209, 210, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.83.conv (Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 24, 25, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 58, 59, 63, 65, 67, 68, 69, 71, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 93, 95, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 119, 121, 122, 123, 124, 126, 127, 130, 131, 133, 135, 136, 139, 140, 141, 142, 143, 144, 145, 148, 150, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 192, 193, 195, 196, 197, 200, 202, 204, 206, 209, 210, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=206208]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 792])>, Index=[513, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 528, 530, 531, 532, 534, 536, 537, 540, 541, 543, 544, 545, 546, 547, 549, 551, 552, 554, 555, 556, 557, 558, 559, 560, 562, 564, 565, 566, 567, 570, 571, 575, 577, 579, 580, 581, 583, 586, 587, 588, 589, 590, 592, 593, 595, 596, 597, 599, 600, 605, 607, 610, 611, 614, 615, 616, 617, 619, 620, 621, 622, 623, 625, 626, 628, 629, 631, 633, 634, 635, 636, 638, 639, 642, 643, 645, 647, 648, 651, 652, 653, 654, 655, 656, 657, 660, 662, 663, 665, 666, 669, 670, 671, 672, 673, 674, 675, 676, 677, 679, 682, 683, 684, 685, 687, 688, 689, 690, 691, 692, 693, 695, 696, 697, 698, 700, 701, 702, 704, 705, 707, 708, 709, 712, 714, 716, 718, 721, 722, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 739, 741, 742, 743, 744, 745, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 758, 760, 761, 762, 763, 765, 766, 767], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(792, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[513, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 528, 530, 531, 532, 534, 536, 537, 540, 541, 543, 544, 545, 546, 547, 549, 551, 552, 554, 555, 556, 557, 558, 559, 560, 562, 564, 565, 566, 567, 570, 571, 575, 577, 579, 580, 581, 583, 586, 587, 588, 589, 590, 592, 593, 595, 596, 597, 599, 600, 605, 607, 610, 611, 614, 615, 616, 617, 619, 620, 621, 622, 623, 625, 626, 628, 629, 631, 633, 634, 635, 636, 638, 639, 642, 643, 645, 647, 648, 651, 652, 653, 654, 655, 656, 657, 660, 662, 663, 665, 666, 669, 670, 671, 672, 673, 674, 675, 676, 677, 679, 682, 683, 684, 685, 687, 688, 689, 690, 691, 692, 693, 695, 696, 697, 698, 700, 701, 702, 704, 705, 707, 708, 709, 712, 714, 716, 718, 721, 722, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 739, 741, 742, 743, 744, 745, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 758, 760, 761, 762, 763, 765, 766, 767], NumPruned=45824]
260803 parameters will be pruned
-------------

2023-04-04 16:48:51.036 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.82.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 54, 56, 58, 59, 60, 62, 63, 66, 68, 71, 73, 74], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.82.conv (Conv2d(47, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 54, 56, 58, 59, 60, 62, 63, 66, 68, 71, 73, 74], NumPruned=2491]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 54, 56, 58, 59, 60, 62, 63, 66, 68, 71, 73, 74], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.83.conv (Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 54, 56, 58, 59, 60, 62, 63, 66, 68, 71, 73, 74], NumPruned=61056]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 589, 613])>, Index=[512, 513, 516, 517, 518, 519, 520, 521, 522, 526, 527, 528, 531, 532, 533, 534, 535, 536, 537, 538, 540, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 553, 554, 555, 556, 557, 558, 559, 561, 562, 563, 566, 568, 570, 571, 572, 574, 575, 578, 580, 583, 585, 586], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(613, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 513, 516, 517, 518, 519, 520, 521, 522, 526, 527, 528, 531, 532, 533, 534, 535, 536, 537, 538, 540, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 553, 554, 555, 556, 557, 558, 559, 561, 562, 563, 566, 568, 570, 571, 572, 574, 575, 578, 580, 583, 585, 586], NumPruned=13568]
77221 parameters will be pruned
-------------

2023-04-04 16:48:51.038 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.83.conv (Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 81, 82, 83, 85, 86, 87, 90, 94, 95, 97, 99, 101, 102, 104, 105, 106, 109, 110, 111, 112, 113, 115, 117, 118, 122, 123, 124, 126, 127], NumPruned=19224]
[ <DEP: prune_conv => prune_batchnorm on model.83.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 81, 82, 83, 85, 86, 87, 90, 94, 95, 97, 99, 101, 102, 104, 105, 106, 109, 110, 111, 112, 113, 115, 117, 118, 122, 123, 124, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 81, 82, 83, 85, 86, 87, 90, 94, 95, 97, 99, 101, 102, 104, 105, 106, 109, 110, 111, 112, 113, 115, 117, 118, 122, 123, 124, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.84.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 81, 82, 83, 85, 86, 87, 90, 94, 95, 97, 99, 101, 102, 104, 105, 106, 109, 110, 111, 112, 113, 115, 117, 118, 122, 123, 124, 126, 127], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 536, 560])>, Index=[384, 385, 387, 388, 389, 390, 392, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 426, 427, 429, 430, 431, 432, 433, 435, 436, 437, 439, 440, 442, 444, 445, 447, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 463, 465, 466, 467, 469, 470, 471, 474, 478, 479, 481, 483, 485, 486, 488, 489, 490, 493, 494, 495, 496, 497, 499, 501, 502, 506, 507, 508, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(560, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 385, 387, 388, 389, 390, 392, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 426, 427, 429, 430, 431, 432, 433, 435, 436, 437, 439, 440, 442, 444, 445, 447, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 463, 465, 466, 467, 469, 470, 471, 474, 478, 479, 481, 483, 485, 486, 488, 489, 490, 493, 494, 495, 496, 497, 499, 501, 502, 506, 507, 508, 510, 511], NumPruned=22784]
144714 parameters will be pruned
-------------

2023-04-04 16:48:51.051 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.83.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 5, 6, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.83.conv (Conv2d(24, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 5, 6, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38], NumPruned=5832]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 5, 6, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.84.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 5, 6, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 423, 447, 471])>, Index=[384, 387, 389, 390, 394, 396, 397, 398, 399, 401, 404, 405, 406, 407, 408, 409, 410, 412, 414, 415, 416, 417, 418, 419, 420, 421, 422], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(471, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 387, 389, 390, 394, 396, 397, 398, 399, 401, 404, 405, 406, 407, 408, 409, 410, 412, 414, 415, 416, 417, 418, 419, 420, 421, 422], NumPruned=6912]
43902 parameters will be pruned
-------------

2023-04-04 16:48:51.052 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.84.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 6, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 70, 72, 75, 80, 81, 82, 83, 86, 87, 89, 91, 94, 95, 97, 98, 99, 100, 101, 102, 106, 107, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 121, 123, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.84.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 5, 6, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 70, 72, 75, 80, 81, 82, 83, 86, 87, 89, 91, 94, 95, 97, 98, 99, 100, 101, 102, 106, 107, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 121, 123, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 5, 6, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 70, 72, 75, 80, 81, 82, 83, 86, 87, 89, 91, 94, 95, 97, 98, 99, 100, 101, 102, 106, 107, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 121, 123, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.85.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 6, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 70, 72, 75, 80, 81, 82, 83, 86, 87, 89, 91, 94, 95, 97, 98, 99, 100, 101, 102, 106, 107, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 121, 123, 126, 127], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 396, 420, 444])>, Index=[257, 260, 261, 262, 264, 265, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 298, 299, 300, 301, 302, 303, 305, 306, 307, 308, 309, 310, 311, 313, 315, 316, 317, 318, 319, 321, 322, 323, 326, 328, 331, 336, 337, 338, 339, 342, 343, 345, 347, 350, 351, 353, 354, 355, 356, 357, 358, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 377, 379, 382, 383], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(444, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 260, 261, 262, 264, 265, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 298, 299, 300, 301, 302, 303, 305, 306, 307, 308, 309, 310, 311, 313, 315, 316, 317, 318, 319, 321, 322, 323, 326, 328, 331, 336, 337, 338, 339, 342, 343, 345, 347, 350, 351, 353, 354, 355, 356, 357, 358, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 377, 379, 382, 383], NumPruned=22784]
135102 parameters will be pruned
-------------

2023-04-04 16:48:51.067 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.84.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 5, 6, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 37], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.84.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 5, 6, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 37], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 5, 6, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.85.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 5, 6, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 37], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 295, 307, 331, 355])>, Index=[256, 258, 261, 262, 265, 266, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 285, 286, 287, 288, 289, 290, 293], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(355, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 258, 261, 262, 265, 266, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 285, 286, 287, 288, 289, 290, 293], NumPruned=6912]
40986 parameters will be pruned
-------------

2023-04-04 16:48:51.068 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.85.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 5, 6, 7, 9, 13, 14, 16, 17, 19, 21, 22, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 38, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 77, 79, 80, 81, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 96, 99, 101, 102, 103, 104, 105, 106, 107, 108, 110, 112, 113, 114, 115, 116, 118, 119, 120, 123, 124, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.85.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 5, 6, 7, 9, 13, 14, 16, 17, 19, 21, 22, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 38, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 77, 79, 80, 81, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 96, 99, 101, 102, 103, 104, 105, 106, 107, 108, 110, 112, 113, 114, 115, 116, 118, 119, 120, 123, 124, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 5, 6, 7, 9, 13, 14, 16, 17, 19, 21, 22, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 38, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 77, 79, 80, 81, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 96, 99, 101, 102, 103, 104, 105, 106, 107, 108, 110, 112, 113, 114, 115, 116, 118, 119, 120, 123, 124, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.86.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 5, 6, 7, 9, 13, 14, 16, 17, 19, 21, 22, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 38, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 77, 79, 80, 81, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 96, 99, 101, 102, 103, 104, 105, 106, 107, 108, 110, 112, 113, 114, 115, 116, 118, 119, 120, 123, 124, 126, 127], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 268, 280, 304, 328])>, Index=[129, 131, 133, 134, 135, 137, 141, 142, 144, 145, 147, 149, 150, 152, 153, 155, 156, 158, 159, 160, 161, 162, 163, 166, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 205, 207, 208, 209, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 224, 227, 229, 230, 231, 232, 233, 234, 235, 236, 238, 240, 241, 242, 243, 244, 246, 247, 248, 251, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(328, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[129, 131, 133, 134, 135, 137, 141, 142, 144, 145, 147, 149, 150, 152, 153, 155, 156, 158, 159, 160, 161, 162, 163, 166, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 205, 207, 208, 209, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 224, 227, 229, 230, 231, 232, 233, 234, 235, 236, 238, 240, 241, 242, 243, 244, 246, 247, 248, 251, 252, 254, 255], NumPruned=22784]
135102 parameters will be pruned
-------------

2023-04-04 16:48:51.083 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.85.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 5, 6, 7, 8, 9, 11, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 26, 28, 29, 32, 33, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.85.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 6, 7, 8, 9, 11, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 26, 28, 29, 32, 33, 35, 36, 37, 38], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 5, 6, 7, 8, 9, 11, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 26, 28, 29, 32, 33, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.86.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 6, 7, 8, 9, 11, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 26, 28, 29, 32, 33, 35, 36, 37, 38], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 167, 179, 191, 215, 239])>, Index=[129, 132, 133, 134, 135, 136, 137, 139, 141, 142, 144, 145, 147, 148, 150, 151, 152, 153, 154, 156, 157, 160, 161, 163, 164, 165, 166], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(239, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[129, 132, 133, 134, 135, 136, 137, 139, 141, 142, 144, 145, 147, 148, 150, 151, 152, 153, 154, 156, 157, 160, 161, 163, 164, 165, 166], NumPruned=6912]
40986 parameters will be pruned
-------------

2023-04-04 16:48:51.085 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.86.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 29, 30, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 54, 58, 59, 62, 65, 66, 68, 70, 71, 72, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 105, 108, 109, 110, 112, 114, 118, 119, 120, 121, 122, 123, 124, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.86.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 29, 30, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 54, 58, 59, 62, 65, 66, 68, 70, 71, 72, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 105, 108, 109, 110, 112, 114, 118, 119, 120, 121, 122, 123, 124, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 29, 30, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 54, 58, 59, 62, 65, 66, 68, 70, 71, 72, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 105, 108, 109, 110, 112, 114, 118, 119, 120, 121, 122, 123, 124, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 140, 152, 164, 188, 212])>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 29, 30, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 54, 58, 59, 62, 65, 66, 68, 70, 71, 72, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 105, 108, 109, 110, 112, 114, 118, 119, 120, 121, 122, 123, 124, 126, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(212, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 29, 30, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 54, 58, 59, 62, 65, 66, 68, 70, 71, 72, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 105, 108, 109, 110, 112, 114, 118, 119, 120, 121, 122, 123, 124, 126, 127], NumPruned=22784]
32574 parameters will be pruned
-------------

2023-04-04 16:48:51.099 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.86.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 7, 8, 11, 12, 13, 15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.86.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 7, 8, 11, 12, 13, 15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 7, 8, 11, 12, 13, 15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 39, 51, 63, 75, 99, 123])>, Index=[0, 1, 2, 4, 5, 7, 8, 11, 12, 13, 15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(123, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 7, 8, 11, 12, 13, 15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37], NumPruned=6912]
9882 parameters will be pruned
-------------

2023-04-04 16:48:51.100 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.88.conv (Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 21, 23, 25, 27, 28, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 44, 45, 47, 48, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 78, 79, 80, 81, 82, 83, 85, 86, 87, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 110, 111, 115, 116, 117, 118, 120, 121, 122, 124, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 147, 149, 152, 153, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 202, 203, 205, 206, 207, 208, 209, 210, 211, 213, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 237, 241, 243, 244, 245, 246, 247, 249, 250, 253, 255], NumPruned=17184]
[ <DEP: prune_conv => prune_batchnorm on model.88.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 21, 23, 25, 27, 28, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 44, 45, 47, 48, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 78, 79, 80, 81, 82, 83, 85, 86, 87, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 110, 111, 115, 116, 117, 118, 120, 121, 122, 124, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 147, 149, 152, 153, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 202, 203, 205, 206, 207, 208, 209, 210, 211, 213, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 237, 241, 243, 244, 245, 246, 247, 249, 250, 253, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 21, 23, 25, 27, 28, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 44, 45, 47, 48, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 78, 79, 80, 81, 82, 83, 85, 86, 87, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 110, 111, 115, 116, 117, 118, 120, 121, 122, 124, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 147, 149, 152, 153, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 202, 203, 205, 206, 207, 208, 209, 210, 211, 213, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 237, 241, 243, 244, 245, 246, 247, 249, 250, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.103.rbr_dense.0 (Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 21, 23, 25, 27, 28, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 44, 45, 47, 48, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 78, 79, 80, 81, 82, 83, 85, 86, 87, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 110, 111, 115, 116, 117, 118, 120, 121, 122, 124, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 147, 149, 152, 153, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 202, 203, 205, 206, 207, 208, 209, 210, 211, 213, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 237, 241, 243, 244, 245, 246, 247, 249, 250, 253, 255], NumPruned=824832]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.103.rbr_1x1.0 (Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 21, 23, 25, 27, 28, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 44, 45, 47, 48, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 78, 79, 80, 81, 82, 83, 85, 86, 87, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 110, 111, 115, 116, 117, 118, 120, 121, 122, 124, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 147, 149, 152, 153, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 202, 203, 205, 206, 207, 208, 209, 210, 211, 213, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 237, 241, 243, 244, 245, 246, 247, 249, 250, 253, 255], NumPruned=91648]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.91.conv (Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 21, 23, 25, 27, 28, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 44, 45, 47, 48, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 78, 79, 80, 81, 82, 83, 85, 86, 87, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 110, 111, 115, 116, 117, 118, 120, 121, 122, 124, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 147, 149, 152, 153, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 202, 203, 205, 206, 207, 208, 209, 210, 211, 213, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 237, 241, 243, 244, 245, 246, 247, 249, 250, 253, 255], NumPruned=45824]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 21, 23, 25, 27, 28, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 44, 45, 47, 48, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 78, 79, 80, 81, 82, 83, 85, 86, 87, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 110, 111, 115, 116, 117, 118, 120, 121, 122, 124, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 147, 149, 152, 153, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 202, 203, 205, 206, 207, 208, 209, 210, 211, 213, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 237, 241, 243, 244, 245, 246, 247, 249, 250, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.90.conv (Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 21, 23, 25, 27, 28, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 44, 45, 47, 48, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 78, 79, 80, 81, 82, 83, 85, 86, 87, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 110, 111, 115, 116, 117, 118, 120, 121, 122, 124, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 147, 149, 152, 153, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 202, 203, 205, 206, 207, 208, 209, 210, 211, 213, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 237, 241, 243, 244, 245, 246, 247, 249, 250, 253, 255], NumPruned=45824]
1025670 parameters will be pruned
-------------

2023-04-04 16:48:51.117 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.88.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[3, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 21, 22, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.88.conv (Conv2d(96, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[3, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 21, 22, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=5088]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[3, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 21, 22, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.103.rbr_dense.0 (Conv2d(77, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[3, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 21, 22, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=244224]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.103.rbr_1x1.0 (Conv2d(77, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[3, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 21, 22, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=27136]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.91.conv (Conv2d(77, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[3, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 21, 22, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=13568]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[3, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 21, 22, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.90.conv (Conv2d(77, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[3, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 21, 22, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=13568]
303690 parameters will be pruned
-------------

2023-04-04 16:48:51.119 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.90.conv (Conv2d(24, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 9, 10, 12, 16, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 35, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 61, 65, 66, 68, 70, 71, 72, 74, 75, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 96, 97, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 140, 142, 143, 145, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 173, 177, 178, 179, 183, 184, 185, 186, 187, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 212, 213, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 230, 233, 234, 235, 236, 237, 238, 239, 240, 242, 244, 245, 246, 247, 249, 250, 251, 253], NumPruned=4296]
[ <DEP: prune_conv => prune_batchnorm on model.90.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 9, 10, 12, 16, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 35, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 61, 65, 66, 68, 70, 71, 72, 74, 75, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 96, 97, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 140, 142, 143, 145, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 173, 177, 178, 179, 183, 184, 185, 186, 187, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 212, 213, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 230, 233, 234, 235, 236, 237, 238, 239, 240, 242, 244, 245, 246, 247, 249, 250, 251, 253], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 9, 10, 12, 16, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 35, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 61, 65, 66, 68, 70, 71, 72, 74, 75, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 96, 97, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 140, 142, 143, 145, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 173, 177, 178, 179, 183, 184, 185, 186, 187, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 212, 213, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 230, 233, 234, 235, 236, 237, 238, 239, 240, 242, 244, 245, 246, 247, 249, 250, 251, 253], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 1024])>, Index=[256, 257, 258, 259, 260, 262, 265, 266, 268, 272, 274, 276, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 291, 294, 295, 296, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 312, 314, 315, 317, 321, 322, 324, 326, 327, 328, 330, 331, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 350, 352, 353, 355, 356, 357, 358, 359, 361, 362, 363, 364, 365, 366, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 396, 398, 399, 401, 407, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 422, 423, 424, 425, 426, 429, 433, 434, 435, 439, 440, 441, 442, 443, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 468, 469, 471, 473, 474, 475, 477, 478, 479, 480, 481, 482, 484, 486, 489, 490, 491, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 505, 506, 507, 509], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.95.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 260, 262, 265, 266, 268, 272, 274, 276, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 291, 294, 295, 296, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 312, 314, 315, 317, 321, 322, 324, 326, 327, 328, 330, 331, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 350, 352, 353, 355, 356, 357, 358, 359, 361, 362, 363, 364, 365, 366, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 396, 398, 399, 401, 407, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 422, 423, 424, 425, 426, 429, 433, 434, 435, 439, 440, 441, 442, 443, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 468, 469, 471, 473, 474, 475, 477, 478, 479, 480, 481, 482, 484, 486, 489, 490, 491, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 505, 506, 507, 509], NumPruned=91648]
[ <DEP: _prune_concat => prune_related_conv on model.94.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 260, 262, 265, 266, 268, 272, 274, 276, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 291, 294, 295, 296, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 312, 314, 315, 317, 321, 322, 324, 326, 327, 328, 330, 331, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 350, 352, 353, 355, 356, 357, 358, 359, 361, 362, 363, 364, 365, 366, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 396, 398, 399, 401, 407, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 422, 423, 424, 425, 426, 429, 433, 434, 435, 439, 440, 441, 442, 443, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 468, 469, 471, 473, 474, 475, 477, 478, 479, 480, 481, 482, 484, 486, 489, 490, 491, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 505, 506, 507, 509], NumPruned=91648]
187950 parameters will be pruned
-------------

2023-04-04 16:48:51.133 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.90.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 25, 27, 28, 30, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 52, 53, 54, 55, 60, 61, 62, 64, 66, 68, 69, 70, 71, 73, 74, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.90.conv (Conv2d(24, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 25, 27, 28, 30, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 52, 53, 54, 55, 60, 61, 62, 64, 66, 68, 69, 70, 71, 73, 74, 76], NumPruned=1272]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 25, 27, 28, 30, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 52, 53, 54, 55, 60, 61, 62, 64, 66, 68, 69, 70, 71, 73, 74, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 333, 845])>, Index=[257, 258, 259, 260, 261, 262, 263, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277, 281, 283, 284, 286, 288, 289, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 306, 308, 309, 310, 311, 316, 317, 318, 320, 322, 324, 325, 326, 327, 329, 330, 332], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.95.conv (Conv2d(845, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 259, 260, 261, 262, 263, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277, 281, 283, 284, 286, 288, 289, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 306, 308, 309, 310, 311, 316, 317, 318, 320, 322, 324, 325, 326, 327, 329, 330, 332], NumPruned=27136]
[ <DEP: _prune_concat => prune_related_conv on model.94.conv (Conv2d(845, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 259, 260, 261, 262, 263, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277, 281, 283, 284, 286, 288, 289, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 306, 308, 309, 310, 311, 316, 317, 318, 320, 322, 324, 325, 326, 327, 329, 330, 332], NumPruned=27136]
55650 parameters will be pruned
-------------

2023-04-04 16:48:51.136 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.91.conv (Conv2d(24, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 11, 15, 16, 17, 18, 19, 21, 24, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 55, 60, 61, 62, 64, 67, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 81, 82, 85, 86, 87, 91, 92, 93, 95, 96, 97, 98, 99, 101, 102, 105, 106, 107, 109, 110, 111, 113, 115, 118, 119, 120, 121, 122, 125, 127, 129, 132, 133, 134, 136, 137, 138, 139, 141, 142, 143, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 158, 159, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 198, 199, 201, 202, 203, 204, 205, 207, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 246, 250, 251, 252, 254, 255], NumPruned=4296]
[ <DEP: prune_conv => prune_batchnorm on model.91.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 6, 7, 8, 11, 15, 16, 17, 18, 19, 21, 24, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 55, 60, 61, 62, 64, 67, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 81, 82, 85, 86, 87, 91, 92, 93, 95, 96, 97, 98, 99, 101, 102, 105, 106, 107, 109, 110, 111, 113, 115, 118, 119, 120, 121, 122, 125, 127, 129, 132, 133, 134, 136, 137, 138, 139, 141, 142, 143, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 158, 159, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 198, 199, 201, 202, 203, 204, 205, 207, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 246, 250, 251, 252, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 6, 7, 8, 11, 15, 16, 17, 18, 19, 21, 24, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 55, 60, 61, 62, 64, 67, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 81, 82, 85, 86, 87, 91, 92, 93, 95, 96, 97, 98, 99, 101, 102, 105, 106, 107, 109, 110, 111, 113, 115, 118, 119, 120, 121, 122, 125, 127, 129, 132, 133, 134, 136, 137, 138, 139, 141, 142, 143, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 158, 159, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 198, 199, 201, 202, 203, 204, 205, 207, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 246, 250, 251, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.92.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 11, 15, 16, 17, 18, 19, 21, 24, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 55, 60, 61, 62, 64, 67, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 81, 82, 85, 86, 87, 91, 92, 93, 95, 96, 97, 98, 99, 101, 102, 105, 106, 107, 109, 110, 111, 113, 115, 118, 119, 120, 121, 122, 125, 127, 129, 132, 133, 134, 136, 137, 138, 139, 141, 142, 143, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 158, 159, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 198, 199, 201, 202, 203, 204, 205, 207, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 246, 250, 251, 252, 254, 255], NumPruned=412416]
417070 parameters will be pruned
-------------

2023-04-04 16:48:51.147 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.91.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58, 60, 64, 66, 67, 68, 70, 71, 73, 74, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.91.conv (Conv2d(24, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58, 60, 64, 66, 67, 68, 70, 71, 73, 74, 76], NumPruned=1272]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58, 60, 64, 66, 67, 68, 70, 71, 73, 74, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.92.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58, 60, 64, 66, 67, 68, 70, 71, 73, 74, 76], NumPruned=122112]
123490 parameters will be pruned
-------------

2023-04-04 16:48:51.148 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.92.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 11, 12, 13, 15, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 56, 58, 59, 60, 63, 64, 65, 66, 68, 69, 71, 72, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 90, 91, 92, 94, 95, 96, 97, 101, 102, 103, 105, 106, 109, 110, 111, 112, 115, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 130, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 164, 166, 167, 168, 169, 172, 173, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 201, 202, 203, 207, 209, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 226, 227, 228, 229, 231, 232, 233, 234, 236, 238, 240, 242, 243, 244, 247, 248, 251, 253, 254, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.92.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 6, 7, 11, 12, 13, 15, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 56, 58, 59, 60, 63, 64, 65, 66, 68, 69, 71, 72, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 90, 91, 92, 94, 95, 96, 97, 101, 102, 103, 105, 106, 109, 110, 111, 112, 115, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 130, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 164, 166, 167, 168, 169, 172, 173, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 201, 202, 203, 207, 209, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 226, 227, 228, 229, 231, 232, 233, 234, 236, 238, 240, 242, 243, 244, 247, 248, 251, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 6, 7, 11, 12, 13, 15, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 56, 58, 59, 60, 63, 64, 65, 66, 68, 69, 71, 72, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 90, 91, 92, 94, 95, 96, 97, 101, 102, 103, 105, 106, 109, 110, 111, 112, 115, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 130, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 164, 166, 167, 168, 169, 172, 173, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 201, 202, 203, 207, 209, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 226, 227, 228, 229, 231, 232, 233, 234, 236, 238, 240, 242, 243, 244, 247, 248, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 280, 792])>, Index=[0, 2, 3, 4, 6, 7, 11, 12, 13, 15, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 56, 58, 59, 60, 63, 64, 65, 66, 68, 69, 71, 72, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 90, 91, 92, 94, 95, 96, 97, 101, 102, 103, 105, 106, 109, 110, 111, 112, 115, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 130, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 164, 166, 167, 168, 169, 172, 173, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 201, 202, 203, 207, 209, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 226, 227, 228, 229, 231, 232, 233, 234, 236, 238, 240, 242, 243, 244, 247, 248, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.95.conv (Conv2d(792, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 11, 12, 13, 15, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 56, 58, 59, 60, 63, 64, 65, 66, 68, 69, 71, 72, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 90, 91, 92, 94, 95, 96, 97, 101, 102, 103, 105, 106, 109, 110, 111, 112, 115, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 130, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 164, 166, 167, 168, 169, 172, 173, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 201, 202, 203, 207, 209, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 226, 227, 228, 229, 231, 232, 233, 234, 236, 238, 240, 242, 243, 244, 247, 248, 251, 253, 254, 255], NumPruned=91648]
[ <DEP: _prune_concat => prune_related_conv on model.94.conv (Conv2d(792, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 11, 12, 13, 15, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 56, 58, 59, 60, 63, 64, 65, 66, 68, 69, 71, 72, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 90, 91, 92, 94, 95, 96, 97, 101, 102, 103, 105, 106, 109, 110, 111, 112, 115, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 130, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 164, 166, 167, 168, 169, 172, 173, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 201, 202, 203, 207, 209, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 226, 227, 228, 229, 231, 232, 233, 234, 236, 238, 240, 242, 243, 244, 247, 248, 251, 253, 254, 255], NumPruned=91648]
222318 parameters will be pruned
-------------

2023-04-04 16:48:51.165 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.92.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 52, 54, 55, 57, 58, 61, 63, 64, 65, 66, 68, 69, 71, 73, 74, 75], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.92.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 52, 54, 55, 57, 58, 61, 63, 64, 65, 66, 68, 69, 71, 73, 74, 75], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 52, 54, 55, 57, 58, 61, 63, 64, 65, 66, 68, 69, 71, 73, 74, 75], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 77, 101, 613])>, Index=[1, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 52, 54, 55, 57, 58, 61, 63, 64, 65, 66, 68, 69, 71, 73, 74, 75], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.95.conv (Conv2d(613, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 52, 54, 55, 57, 58, 61, 63, 64, 65, 66, 68, 69, 71, 73, 74, 75], NumPruned=27136]
[ <DEP: _prune_concat => prune_related_conv on model.94.conv (Conv2d(613, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 52, 54, 55, 57, 58, 61, 63, 64, 65, 66, 68, 69, 71, 73, 74, 75], NumPruned=27136]
65826 parameters will be pruned
-------------

2023-04-04 16:48:51.168 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.94.conv (Conv2d(560, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 32, 35, 37, 38, 40, 41, 42, 44, 45, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 68, 69, 71, 72, 73, 75, 76, 78, 79, 81, 84, 85, 88, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 134, 135, 136, 138, 139, 140, 141, 142, 144, 145, 148, 149, 150, 151, 152, 153, 155, 157, 158, 159, 160, 162, 164, 165, 166, 167, 168, 169, 172, 173, 175, 178, 179, 180, 182, 185, 188, 189, 191, 192, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 213, 214, 215, 219, 220, 221, 223, 225, 226, 227, 228, 230, 231, 232, 235, 236, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 255, 257, 258, 259, 261, 262, 263, 264, 265, 267, 269, 270, 272, 273, 274, 276, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 290, 291, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 314, 315, 317, 318, 319, 320, 323, 324, 325, 327, 328, 329, 332, 336, 339, 341, 342, 343, 344, 345, 346, 349, 350, 351, 352, 354, 355, 357, 358, 360, 364, 366, 367, 369, 370, 372, 373, 374, 378, 379, 380, 381, 383, 384, 385, 386, 388, 389, 390, 391, 392, 394, 395, 396, 397, 398, 400, 401, 403, 404, 405, 406, 407, 408, 410, 411, 412, 413, 416, 417, 418, 419, 420, 421, 422, 423, 424, 426, 427, 428, 429, 430, 432, 433, 434, 436, 437, 438, 439, 443, 444, 447, 448, 449, 450, 451, 452, 453, 454, 456, 457, 458, 459, 460, 464, 467, 468, 470, 471, 472, 473, 474, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 491, 492, 496, 498, 499, 500, 501, 503, 504, 506, 507, 509], NumPruned=200480]
[ <DEP: prune_conv => prune_batchnorm on model.94.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 32, 35, 37, 38, 40, 41, 42, 44, 45, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 68, 69, 71, 72, 73, 75, 76, 78, 79, 81, 84, 85, 88, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 134, 135, 136, 138, 139, 140, 141, 142, 144, 145, 148, 149, 150, 151, 152, 153, 155, 157, 158, 159, 160, 162, 164, 165, 166, 167, 168, 169, 172, 173, 175, 178, 179, 180, 182, 185, 188, 189, 191, 192, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 213, 214, 215, 219, 220, 221, 223, 225, 226, 227, 228, 230, 231, 232, 235, 236, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 255, 257, 258, 259, 261, 262, 263, 264, 265, 267, 269, 270, 272, 273, 274, 276, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 290, 291, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 314, 315, 317, 318, 319, 320, 323, 324, 325, 327, 328, 329, 332, 336, 339, 341, 342, 343, 344, 345, 346, 349, 350, 351, 352, 354, 355, 357, 358, 360, 364, 366, 367, 369, 370, 372, 373, 374, 378, 379, 380, 381, 383, 384, 385, 386, 388, 389, 390, 391, 392, 394, 395, 396, 397, 398, 400, 401, 403, 404, 405, 406, 407, 408, 410, 411, 412, 413, 416, 417, 418, 419, 420, 421, 422, 423, 424, 426, 427, 428, 429, 430, 432, 433, 434, 436, 437, 438, 439, 443, 444, 447, 448, 449, 450, 451, 452, 453, 454, 456, 457, 458, 459, 460, 464, 467, 468, 470, 471, 472, 473, 474, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 491, 492, 496, 498, 499, 500, 501, 503, 504, 506, 507, 509], NumPruned=716]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 32, 35, 37, 38, 40, 41, 42, 44, 45, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 68, 69, 71, 72, 73, 75, 76, 78, 79, 81, 84, 85, 88, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 134, 135, 136, 138, 139, 140, 141, 142, 144, 145, 148, 149, 150, 151, 152, 153, 155, 157, 158, 159, 160, 162, 164, 165, 166, 167, 168, 169, 172, 173, 175, 178, 179, 180, 182, 185, 188, 189, 191, 192, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 213, 214, 215, 219, 220, 221, 223, 225, 226, 227, 228, 230, 231, 232, 235, 236, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 255, 257, 258, 259, 261, 262, 263, 264, 265, 267, 269, 270, 272, 273, 274, 276, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 290, 291, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 314, 315, 317, 318, 319, 320, 323, 324, 325, 327, 328, 329, 332, 336, 339, 341, 342, 343, 344, 345, 346, 349, 350, 351, 352, 354, 355, 357, 358, 360, 364, 366, 367, 369, 370, 372, 373, 374, 378, 379, 380, 381, 383, 384, 385, 386, 388, 389, 390, 391, 392, 394, 395, 396, 397, 398, 400, 401, 403, 404, 405, 406, 407, 408, 410, 411, 412, 413, 416, 417, 418, 419, 420, 421, 422, 423, 424, 426, 427, 428, 429, 430, 432, 433, 434, 436, 437, 438, 439, 443, 444, 447, 448, 449, 450, 451, 452, 453, 454, 456, 457, 458, 459, 460, 464, 467, 468, 470, 471, 472, 473, 474, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 491, 492, 496, 498, 499, 500, 501, 503, 504, 506, 507, 509], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 1024, 1536, 2048])>, Index=[1536, 1538, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1563, 1564, 1566, 1568, 1571, 1573, 1574, 1576, 1577, 1578, 1580, 1581, 1582, 1583, 1586, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1596, 1597, 1598, 1599, 1600, 1604, 1605, 1607, 1608, 1609, 1611, 1612, 1614, 1615, 1617, 1620, 1621, 1624, 1625, 1626, 1628, 1630, 1631, 1632, 1633, 1635, 1636, 1637, 1638, 1642, 1643, 1644, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1656, 1657, 1658, 1659, 1660, 1662, 1663, 1664, 1665, 1666, 1668, 1670, 1671, 1672, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1684, 1685, 1686, 1687, 1688, 1689, 1691, 1693, 1694, 1695, 1696, 1698, 1700, 1701, 1702, 1703, 1704, 1705, 1708, 1709, 1711, 1714, 1715, 1716, 1718, 1721, 1724, 1725, 1727, 1728, 1730, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1742, 1743, 1744, 1749, 1750, 1751, 1755, 1756, 1757, 1759, 1761, 1762, 1763, 1764, 1766, 1767, 1768, 1771, 1772, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1788, 1791, 1793, 1794, 1795, 1797, 1798, 1799, 1800, 1801, 1803, 1805, 1806, 1808, 1809, 1810, 1812, 1814, 1815, 1816, 1817, 1818, 1819, 1821, 1822, 1823, 1824, 1826, 1827, 1829, 1830, 1831, 1832, 1833, 1835, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1847, 1849, 1850, 1851, 1853, 1854, 1855, 1856, 1859, 1860, 1861, 1863, 1864, 1865, 1868, 1872, 1875, 1877, 1878, 1879, 1880, 1881, 1882, 1885, 1886, 1887, 1888, 1890, 1891, 1893, 1894, 1896, 1900, 1902, 1903, 1905, 1906, 1908, 1909, 1910, 1914, 1915, 1916, 1917, 1919, 1920, 1921, 1922, 1924, 1925, 1926, 1927, 1928, 1930, 1931, 1932, 1933, 1934, 1936, 1937, 1939, 1940, 1941, 1942, 1943, 1944, 1946, 1947, 1948, 1949, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1962, 1963, 1964, 1965, 1966, 1968, 1969, 1970, 1972, 1973, 1974, 1975, 1979, 1980, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1992, 1993, 1994, 1995, 1996, 2000, 2003, 2004, 2006, 2007, 2008, 2009, 2010, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2022, 2023, 2024, 2025, 2027, 2028, 2032, 2034, 2035, 2036, 2037, 2039, 2040, 2042, 2043, 2045], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1536, 1538, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1563, 1564, 1566, 1568, 1571, 1573, 1574, 1576, 1577, 1578, 1580, 1581, 1582, 1583, 1586, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1596, 1597, 1598, 1599, 1600, 1604, 1605, 1607, 1608, 1609, 1611, 1612, 1614, 1615, 1617, 1620, 1621, 1624, 1625, 1626, 1628, 1630, 1631, 1632, 1633, 1635, 1636, 1637, 1638, 1642, 1643, 1644, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1656, 1657, 1658, 1659, 1660, 1662, 1663, 1664, 1665, 1666, 1668, 1670, 1671, 1672, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1684, 1685, 1686, 1687, 1688, 1689, 1691, 1693, 1694, 1695, 1696, 1698, 1700, 1701, 1702, 1703, 1704, 1705, 1708, 1709, 1711, 1714, 1715, 1716, 1718, 1721, 1724, 1725, 1727, 1728, 1730, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1742, 1743, 1744, 1749, 1750, 1751, 1755, 1756, 1757, 1759, 1761, 1762, 1763, 1764, 1766, 1767, 1768, 1771, 1772, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1788, 1791, 1793, 1794, 1795, 1797, 1798, 1799, 1800, 1801, 1803, 1805, 1806, 1808, 1809, 1810, 1812, 1814, 1815, 1816, 1817, 1818, 1819, 1821, 1822, 1823, 1824, 1826, 1827, 1829, 1830, 1831, 1832, 1833, 1835, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1847, 1849, 1850, 1851, 1853, 1854, 1855, 1856, 1859, 1860, 1861, 1863, 1864, 1865, 1868, 1872, 1875, 1877, 1878, 1879, 1880, 1881, 1882, 1885, 1886, 1887, 1888, 1890, 1891, 1893, 1894, 1896, 1900, 1902, 1903, 1905, 1906, 1908, 1909, 1910, 1914, 1915, 1916, 1917, 1919, 1920, 1921, 1922, 1924, 1925, 1926, 1927, 1928, 1930, 1931, 1932, 1933, 1934, 1936, 1937, 1939, 1940, 1941, 1942, 1943, 1944, 1946, 1947, 1948, 1949, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1962, 1963, 1964, 1965, 1966, 1968, 1969, 1970, 1972, 1973, 1974, 1975, 1979, 1980, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1992, 1993, 1994, 1995, 1996, 2000, 2003, 2004, 2006, 2007, 2008, 2009, 2010, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2022, 2023, 2024, 2025, 2027, 2028, 2032, 2034, 2035, 2036, 2037, 2039, 2040, 2042, 2043, 2045], NumPruned=183296]
384492 parameters will be pruned
-------------

2023-04-04 16:48:51.181 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.94.bn (BatchNorm2d(154, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 61, 62, 63, 65, 66, 70, 73, 75, 76, 79, 80, 81, 82, 83, 84, 85, 87, 90, 91, 94, 95, 96, 97, 98, 99, 101, 103, 105, 106, 107, 109, 111, 112, 114, 116, 117, 119, 122, 123, 124, 126, 127, 128, 130, 131, 133, 134, 135, 138, 139, 140, 142, 144, 145, 146, 147, 149, 150, 152, 153], NumPruned=216]
[ <DEP: prune_batchnorm => prune_conv on model.94.conv (Conv2d(560, 154, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 61, 62, 63, 65, 66, 70, 73, 75, 76, 79, 80, 81, 82, 83, 84, 85, 87, 90, 91, 94, 95, 96, 97, 98, 99, 101, 103, 105, 106, 107, 109, 111, 112, 114, 116, 117, 119, 122, 123, 124, 126, 127, 128, 130, 131, 133, 134, 135, 138, 139, 140, 142, 144, 145, 146, 147, 149, 150, 152, 153], NumPruned=60480]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 61, 62, 63, 65, 66, 70, 73, 75, 76, 79, 80, 81, 82, 83, 84, 85, 87, 90, 91, 94, 95, 96, 97, 98, 99, 101, 103, 105, 106, 107, 109, 111, 112, 114, 116, 117, 119, 122, 123, 124, 126, 127, 128, 130, 131, 133, 134, 135, 138, 139, 140, 142, 144, 145, 146, 147, 149, 150, 152, 153], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 1024, 1536, 1690])>, Index=[1536, 1537, 1538, 1539, 1541, 1542, 1543, 1545, 1546, 1548, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1569, 1570, 1571, 1572, 1574, 1575, 1577, 1578, 1579, 1580, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1594, 1597, 1598, 1599, 1601, 1602, 1606, 1609, 1611, 1612, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1623, 1626, 1627, 1630, 1631, 1632, 1633, 1634, 1635, 1637, 1639, 1641, 1642, 1643, 1645, 1647, 1648, 1650, 1652, 1653, 1655, 1658, 1659, 1660, 1662, 1663, 1664, 1666, 1667, 1669, 1670, 1671, 1674, 1675, 1676, 1678, 1680, 1681, 1682, 1683, 1685, 1686, 1688, 1689], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(1690, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1536, 1537, 1538, 1539, 1541, 1542, 1543, 1545, 1546, 1548, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1569, 1570, 1571, 1572, 1574, 1575, 1577, 1578, 1579, 1580, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1594, 1597, 1598, 1599, 1601, 1602, 1606, 1609, 1611, 1612, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1623, 1626, 1627, 1630, 1631, 1632, 1633, 1634, 1635, 1637, 1639, 1641, 1642, 1643, 1645, 1647, 1648, 1650, 1652, 1653, 1655, 1658, 1659, 1660, 1662, 1663, 1664, 1666, 1667, 1669, 1670, 1671, 1674, 1675, 1676, 1678, 1680, 1681, 1682, 1683, 1685, 1686, 1688, 1689], NumPruned=55296]
115992 parameters will be pruned
-------------

2023-04-04 16:48:51.184 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.95.conv (Conv2d(560, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 11, 12, 13, 18, 19, 21, 23, 24, 25, 26, 27, 29, 30, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 91, 93, 95, 96, 97, 98, 99, 101, 102, 103, 105, 106, 107, 109, 110, 111, 112, 114, 115, 116, 117, 120, 121, 123, 124, 126, 129, 132, 133, 134, 136, 140, 141, 146, 147, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 167, 168, 169, 170, 171, 176, 179, 180, 181, 182, 183, 185, 186, 191, 193, 196, 197, 199, 200, 201, 202, 204, 205, 206, 207, 208, 210, 211, 213, 214, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 247, 250, 252, 254, 255, 258, 259, 260, 261, 262, 263, 265, 266, 268, 269, 270, 271, 273, 275, 276, 278, 281, 282, 283, 284, 289, 290, 291, 292, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 318, 319, 320, 321, 322, 324, 325, 326, 328, 329, 330, 331, 337, 338, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 353, 354, 355, 356, 358, 360, 361, 362, 363, 364, 368, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 387, 389, 390, 391, 392, 393, 397, 398, 399, 401, 402, 403, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 418, 419, 421, 422, 423, 425, 426, 427, 429, 432, 433, 434, 435, 436, 437, 439, 441, 442, 443, 446, 447, 448, 449, 451, 452, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 469, 470, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 484, 486, 487, 488, 489, 493, 494, 496, 498, 500, 502, 503, 504, 505, 506, 507, 508, 509, 511], NumPruned=200480]
[ <DEP: prune_conv => prune_batchnorm on model.95.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 11, 12, 13, 18, 19, 21, 23, 24, 25, 26, 27, 29, 30, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 91, 93, 95, 96, 97, 98, 99, 101, 102, 103, 105, 106, 107, 109, 110, 111, 112, 114, 115, 116, 117, 120, 121, 123, 124, 126, 129, 132, 133, 134, 136, 140, 141, 146, 147, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 167, 168, 169, 170, 171, 176, 179, 180, 181, 182, 183, 185, 186, 191, 193, 196, 197, 199, 200, 201, 202, 204, 205, 206, 207, 208, 210, 211, 213, 214, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 247, 250, 252, 254, 255, 258, 259, 260, 261, 262, 263, 265, 266, 268, 269, 270, 271, 273, 275, 276, 278, 281, 282, 283, 284, 289, 290, 291, 292, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 318, 319, 320, 321, 322, 324, 325, 326, 328, 329, 330, 331, 337, 338, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 353, 354, 355, 356, 358, 360, 361, 362, 363, 364, 368, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 387, 389, 390, 391, 392, 393, 397, 398, 399, 401, 402, 403, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 418, 419, 421, 422, 423, 425, 426, 427, 429, 432, 433, 434, 435, 436, 437, 439, 441, 442, 443, 446, 447, 448, 449, 451, 452, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 469, 470, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 484, 486, 487, 488, 489, 493, 494, 496, 498, 500, 502, 503, 504, 505, 506, 507, 508, 509, 511], NumPruned=716]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 11, 12, 13, 18, 19, 21, 23, 24, 25, 26, 27, 29, 30, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 91, 93, 95, 96, 97, 98, 99, 101, 102, 103, 105, 106, 107, 109, 110, 111, 112, 114, 115, 116, 117, 120, 121, 123, 124, 126, 129, 132, 133, 134, 136, 140, 141, 146, 147, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 167, 168, 169, 170, 171, 176, 179, 180, 181, 182, 183, 185, 186, 191, 193, 196, 197, 199, 200, 201, 202, 204, 205, 206, 207, 208, 210, 211, 213, 214, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 247, 250, 252, 254, 255, 258, 259, 260, 261, 262, 263, 265, 266, 268, 269, 270, 271, 273, 275, 276, 278, 281, 282, 283, 284, 289, 290, 291, 292, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 318, 319, 320, 321, 322, 324, 325, 326, 328, 329, 330, 331, 337, 338, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 353, 354, 355, 356, 358, 360, 361, 362, 363, 364, 368, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 387, 389, 390, 391, 392, 393, 397, 398, 399, 401, 402, 403, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 418, 419, 421, 422, 423, 425, 426, 427, 429, 432, 433, 434, 435, 436, 437, 439, 441, 442, 443, 446, 447, 448, 449, 451, 452, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 469, 470, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 484, 486, 487, 488, 489, 493, 494, 496, 498, 500, 502, 503, 504, 505, 506, 507, 508, 509, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.96.conv (Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 11, 12, 13, 18, 19, 21, 23, 24, 25, 26, 27, 29, 30, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 91, 93, 95, 96, 97, 98, 99, 101, 102, 103, 105, 106, 107, 109, 110, 111, 112, 114, 115, 116, 117, 120, 121, 123, 124, 126, 129, 132, 133, 134, 136, 140, 141, 146, 147, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 167, 168, 169, 170, 171, 176, 179, 180, 181, 182, 183, 185, 186, 191, 193, 196, 197, 199, 200, 201, 202, 204, 205, 206, 207, 208, 210, 211, 213, 214, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 247, 250, 252, 254, 255, 258, 259, 260, 261, 262, 263, 265, 266, 268, 269, 270, 271, 273, 275, 276, 278, 281, 282, 283, 284, 289, 290, 291, 292, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 318, 319, 320, 321, 322, 324, 325, 326, 328, 329, 330, 331, 337, 338, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 353, 354, 355, 356, 358, 360, 361, 362, 363, 364, 368, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 387, 389, 390, 391, 392, 393, 397, 398, 399, 401, 402, 403, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 418, 419, 421, 422, 423, 425, 426, 427, 429, 432, 433, 434, 435, 436, 437, 439, 441, 442, 443, 446, 447, 448, 449, 451, 452, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 469, 470, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 484, 486, 487, 488, 489, 493, 494, 496, 498, 500, 502, 503, 504, 505, 506, 507, 508, 509, 511], NumPruned=824832]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 1024, 1536, 1582])>, Index=[1024, 1025, 1026, 1027, 1028, 1030, 1032, 1033, 1035, 1036, 1037, 1042, 1043, 1045, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1058, 1059, 1060, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1098, 1100, 1101, 1102, 1104, 1105, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1115, 1117, 1119, 1120, 1121, 1122, 1123, 1125, 1126, 1127, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1138, 1139, 1140, 1141, 1144, 1145, 1147, 1148, 1150, 1153, 1156, 1157, 1158, 1160, 1164, 1165, 1170, 1171, 1173, 1174, 1175, 1176, 1177, 1178, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1191, 1192, 1193, 1194, 1195, 1200, 1203, 1204, 1205, 1206, 1207, 1209, 1210, 1215, 1217, 1220, 1221, 1223, 1224, 1225, 1226, 1228, 1229, 1230, 1231, 1232, 1234, 1235, 1237, 1238, 1242, 1243, 1244, 1245, 1246, 1247, 1250, 1251, 1252, 1253, 1255, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1271, 1274, 1276, 1278, 1279, 1282, 1283, 1284, 1285, 1286, 1287, 1289, 1290, 1292, 1293, 1294, 1295, 1297, 1299, 1300, 1302, 1305, 1306, 1307, 1308, 1313, 1314, 1315, 1316, 1320, 1321, 1322, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1342, 1343, 1344, 1345, 1346, 1348, 1349, 1350, 1352, 1353, 1354, 1355, 1361, 1362, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1377, 1378, 1379, 1380, 1382, 1384, 1385, 1386, 1387, 1388, 1392, 1394, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1411, 1413, 1414, 1415, 1416, 1417, 1421, 1422, 1423, 1425, 1426, 1427, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1440, 1442, 1443, 1445, 1446, 1447, 1449, 1450, 1451, 1453, 1456, 1457, 1458, 1459, 1460, 1461, 1463, 1465, 1466, 1467, 1470, 1471, 1472, 1473, 1475, 1476, 1481, 1482, 1483, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1493, 1494, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1510, 1511, 1512, 1513, 1517, 1518, 1520, 1522, 1524, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1535], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(1582, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1024, 1025, 1026, 1027, 1028, 1030, 1032, 1033, 1035, 1036, 1037, 1042, 1043, 1045, 1047, 1048, 1049, 1050, 1051, 1053, 1054, 1058, 1059, 1060, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1098, 1100, 1101, 1102, 1104, 1105, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1115, 1117, 1119, 1120, 1121, 1122, 1123, 1125, 1126, 1127, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1138, 1139, 1140, 1141, 1144, 1145, 1147, 1148, 1150, 1153, 1156, 1157, 1158, 1160, 1164, 1165, 1170, 1171, 1173, 1174, 1175, 1176, 1177, 1178, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1191, 1192, 1193, 1194, 1195, 1200, 1203, 1204, 1205, 1206, 1207, 1209, 1210, 1215, 1217, 1220, 1221, 1223, 1224, 1225, 1226, 1228, 1229, 1230, 1231, 1232, 1234, 1235, 1237, 1238, 1242, 1243, 1244, 1245, 1246, 1247, 1250, 1251, 1252, 1253, 1255, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1271, 1274, 1276, 1278, 1279, 1282, 1283, 1284, 1285, 1286, 1287, 1289, 1290, 1292, 1293, 1294, 1295, 1297, 1299, 1300, 1302, 1305, 1306, 1307, 1308, 1313, 1314, 1315, 1316, 1320, 1321, 1322, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1342, 1343, 1344, 1345, 1346, 1348, 1349, 1350, 1352, 1353, 1354, 1355, 1361, 1362, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1377, 1378, 1379, 1380, 1382, 1384, 1385, 1386, 1387, 1388, 1392, 1394, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1411, 1413, 1414, 1415, 1416, 1417, 1421, 1422, 1423, 1425, 1426, 1427, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1440, 1442, 1443, 1445, 1446, 1447, 1449, 1450, 1451, 1453, 1456, 1457, 1458, 1459, 1460, 1461, 1463, 1465, 1466, 1467, 1470, 1471, 1472, 1473, 1475, 1476, 1481, 1482, 1483, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1493, 1494, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1510, 1511, 1512, 1513, 1517, 1518, 1520, 1522, 1524, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1535], NumPruned=183296]
1209324 parameters will be pruned
-------------

2023-04-04 16:48:51.198 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.95.bn (BatchNorm2d(154, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 45, 46, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 100, 103, 104, 105, 106, 107, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 122, 123, 124, 126, 128, 130, 132, 134, 135, 138, 139, 142, 143, 144, 145, 147, 148, 149, 151, 152], NumPruned=214]
[ <DEP: prune_batchnorm => prune_conv on model.95.conv (Conv2d(560, 154, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 45, 46, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 100, 103, 104, 105, 106, 107, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 122, 123, 124, 126, 128, 130, 132, 134, 135, 138, 139, 142, 143, 144, 145, 147, 148, 149, 151, 152], NumPruned=59920]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 45, 46, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 100, 103, 104, 105, 106, 107, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 122, 123, 124, 126, 128, 130, 132, 134, 135, 138, 139, 142, 143, 144, 145, 147, 148, 149, 151, 152], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.96.conv (Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 45, 46, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 100, 103, 104, 105, 106, 107, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 122, 123, 124, 126, 128, 130, 132, 134, 135, 138, 139, 142, 143, 144, 145, 147, 148, 149, 151, 152], NumPruned=246528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 1024, 1178, 1224])>, Index=[1025, 1026, 1027, 1030, 1031, 1033, 1034, 1035, 1037, 1038, 1039, 1040, 1041, 1042, 1044, 1045, 1046, 1048, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1060, 1062, 1063, 1064, 1065, 1066, 1067, 1069, 1070, 1072, 1075, 1076, 1077, 1078, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1092, 1095, 1096, 1097, 1099, 1100, 1101, 1102, 1103, 1104, 1106, 1110, 1111, 1113, 1114, 1115, 1116, 1117, 1119, 1120, 1121, 1122, 1124, 1127, 1128, 1129, 1130, 1131, 1133, 1135, 1136, 1137, 1138, 1139, 1140, 1142, 1143, 1144, 1146, 1147, 1148, 1150, 1152, 1154, 1156, 1158, 1159, 1162, 1163, 1166, 1167, 1168, 1169, 1171, 1172, 1173, 1175, 1176], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(1224, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1025, 1026, 1027, 1030, 1031, 1033, 1034, 1035, 1037, 1038, 1039, 1040, 1041, 1042, 1044, 1045, 1046, 1048, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1060, 1062, 1063, 1064, 1065, 1066, 1067, 1069, 1070, 1072, 1075, 1076, 1077, 1078, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1092, 1095, 1096, 1097, 1099, 1100, 1101, 1102, 1103, 1104, 1106, 1110, 1111, 1113, 1114, 1115, 1116, 1117, 1119, 1120, 1121, 1122, 1124, 1127, 1128, 1129, 1130, 1131, 1133, 1135, 1136, 1137, 1138, 1139, 1140, 1142, 1143, 1144, 1146, 1147, 1148, 1150, 1152, 1154, 1156, 1158, 1159, 1162, 1163, 1166, 1167, 1168, 1169, 1171, 1172, 1173, 1175, 1176], NumPruned=54784]
361446 parameters will be pruned
-------------

2023-04-04 16:48:51.213 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.96.conv (Conv2d(47, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 6, 7, 8, 10, 11, 14, 16, 17, 18, 20, 21, 22, 23, 29, 30, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 80, 81, 82, 83, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 153, 154, 155, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 176, 179, 180, 181, 185, 186, 187, 188, 189, 190, 191, 192, 194, 197, 198, 199, 200, 201, 202, 203, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 218, 221, 223, 224, 225, 228, 229, 231, 232, 233, 236, 237, 239, 240, 241, 245, 246, 247, 248, 249, 251, 254, 255], NumPruned=75717]
[ <DEP: prune_conv => prune_batchnorm on model.96.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 6, 7, 8, 10, 11, 14, 16, 17, 18, 20, 21, 22, 23, 29, 30, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 80, 81, 82, 83, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 153, 154, 155, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 176, 179, 180, 181, 185, 186, 187, 188, 189, 190, 191, 192, 194, 197, 198, 199, 200, 201, 202, 203, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 218, 221, 223, 224, 225, 228, 229, 231, 232, 233, 236, 237, 239, 240, 241, 245, 246, 247, 248, 249, 251, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 6, 7, 8, 10, 11, 14, 16, 17, 18, 20, 21, 22, 23, 29, 30, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 80, 81, 82, 83, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 153, 154, 155, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 176, 179, 180, 181, 185, 186, 187, 188, 189, 190, 191, 192, 194, 197, 198, 199, 200, 201, 202, 203, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 218, 221, 223, 224, 225, 228, 229, 231, 232, 233, 236, 237, 239, 240, 241, 245, 246, 247, 248, 249, 251, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.97.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 6, 7, 8, 10, 11, 14, 16, 17, 18, 20, 21, 22, 23, 29, 30, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 80, 81, 82, 83, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 153, 154, 155, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 176, 179, 180, 181, 185, 186, 187, 188, 189, 190, 191, 192, 194, 197, 198, 199, 200, 201, 202, 203, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 218, 221, 223, 224, 225, 228, 229, 231, 232, 233, 236, 237, 239, 240, 241, 245, 246, 247, 248, 249, 251, 254, 255], NumPruned=412416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 1024, 1071, 1117])>, Index=[768, 770, 774, 775, 776, 778, 779, 782, 784, 785, 786, 788, 789, 790, 791, 797, 798, 800, 801, 802, 803, 804, 805, 807, 809, 810, 811, 812, 813, 814, 815, 818, 819, 820, 821, 823, 824, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 843, 848, 849, 850, 851, 855, 856, 857, 859, 860, 861, 862, 864, 865, 866, 869, 870, 871, 872, 873, 874, 875, 878, 879, 880, 882, 883, 884, 885, 886, 887, 888, 890, 892, 893, 894, 895, 896, 898, 899, 900, 901, 902, 903, 905, 906, 907, 908, 909, 910, 911, 913, 914, 916, 917, 918, 920, 921, 922, 923, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 940, 941, 944, 947, 948, 949, 953, 954, 955, 956, 957, 958, 959, 960, 962, 965, 966, 967, 968, 969, 970, 971, 974, 975, 976, 977, 978, 979, 980, 981, 982, 984, 986, 989, 991, 992, 993, 996, 997, 999, 1000, 1001, 1004, 1005, 1007, 1008, 1009, 1013, 1014, 1015, 1016, 1017, 1019, 1022, 1023], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(1117, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 770, 774, 775, 776, 778, 779, 782, 784, 785, 786, 788, 789, 790, 791, 797, 798, 800, 801, 802, 803, 804, 805, 807, 809, 810, 811, 812, 813, 814, 815, 818, 819, 820, 821, 823, 824, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 843, 848, 849, 850, 851, 855, 856, 857, 859, 860, 861, 862, 864, 865, 866, 869, 870, 871, 872, 873, 874, 875, 878, 879, 880, 882, 883, 884, 885, 886, 887, 888, 890, 892, 893, 894, 895, 896, 898, 899, 900, 901, 902, 903, 905, 906, 907, 908, 909, 910, 911, 913, 914, 916, 917, 918, 920, 921, 922, 923, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 940, 941, 944, 947, 948, 949, 953, 954, 955, 956, 957, 958, 959, 960, 962, 965, 966, 967, 968, 969, 970, 971, 974, 975, 976, 977, 978, 979, 980, 981, 982, 984, 986, 989, 991, 992, 993, 996, 997, 999, 1000, 1001, 1004, 1005, 1007, 1008, 1009, 1013, 1014, 1015, 1016, 1017, 1019, 1022, 1023], NumPruned=91648]
580139 parameters will be pruned
-------------

2023-04-04 16:48:51.229 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.96.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 16, 19, 21, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 57, 60, 62, 63, 64, 66, 67, 69, 71, 73, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.96.conv (Conv2d(47, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 16, 19, 21, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 57, 60, 62, 63, 64, 66, 67, 69, 71, 73, 75, 76], NumPruned=22419]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 16, 19, 21, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 57, 60, 62, 63, 64, 66, 67, 69, 71, 73, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.97.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 16, 19, 21, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 57, 60, 62, 63, 64, 66, 67, 69, 71, 73, 75, 76], NumPruned=122112]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 845, 892, 938])>, Index=[769, 770, 771, 772, 773, 775, 776, 777, 779, 780, 782, 783, 784, 787, 789, 790, 792, 793, 794, 795, 796, 798, 799, 800, 801, 802, 804, 805, 806, 807, 808, 809, 811, 813, 814, 815, 816, 817, 818, 819, 820, 825, 828, 830, 831, 832, 834, 835, 837, 839, 841, 843, 844], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(938, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[769, 770, 771, 772, 773, 775, 776, 777, 779, 780, 782, 783, 784, 787, 789, 790, 792, 793, 794, 795, 796, 798, 799, 800, 801, 802, 804, 805, 806, 807, 808, 809, 811, 813, 814, 815, 816, 817, 818, 819, 820, 825, 828, 830, 831, 832, 834, 835, 837, 839, 841, 843, 844], NumPruned=27136]
171773 parameters will be pruned
-------------

2023-04-04 16:48:51.231 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.97.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 6, 7, 9, 10, 12, 14, 15, 17, 18, 19, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 37, 39, 40, 41, 43, 44, 46, 47, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 83, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 102, 104, 106, 107, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 125, 126, 128, 129, 131, 133, 135, 136, 137, 140, 141, 142, 144, 145, 147, 148, 149, 150, 152, 153, 154, 157, 159, 160, 161, 162, 163, 164, 166, 167, 169, 170, 171, 172, 173, 175, 176, 177, 179, 180, 181, 182, 184, 186, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 218, 219, 220, 221, 222, 223, 226, 228, 230, 231, 233, 235, 236, 237, 238, 240, 241, 244, 245, 248, 249, 250, 251, 253], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.97.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 6, 7, 9, 10, 12, 14, 15, 17, 18, 19, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 37, 39, 40, 41, 43, 44, 46, 47, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 83, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 102, 104, 106, 107, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 125, 126, 128, 129, 131, 133, 135, 136, 137, 140, 141, 142, 144, 145, 147, 148, 149, 150, 152, 153, 154, 157, 159, 160, 161, 162, 163, 164, 166, 167, 169, 170, 171, 172, 173, 175, 176, 177, 179, 180, 181, 182, 184, 186, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 218, 219, 220, 221, 222, 223, 226, 228, 230, 231, 233, 235, 236, 237, 238, 240, 241, 244, 245, 248, 249, 250, 251, 253], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 6, 7, 9, 10, 12, 14, 15, 17, 18, 19, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 37, 39, 40, 41, 43, 44, 46, 47, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 83, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 102, 104, 106, 107, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 125, 126, 128, 129, 131, 133, 135, 136, 137, 140, 141, 142, 144, 145, 147, 148, 149, 150, 152, 153, 154, 157, 159, 160, 161, 162, 163, 164, 166, 167, 169, 170, 171, 172, 173, 175, 176, 177, 179, 180, 181, 182, 184, 186, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 218, 219, 220, 221, 222, 223, 226, 228, 230, 231, 233, 235, 236, 237, 238, 240, 241, 244, 245, 248, 249, 250, 251, 253], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.98.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 6, 7, 9, 10, 12, 14, 15, 17, 18, 19, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 37, 39, 40, 41, 43, 44, 46, 47, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 83, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 102, 104, 106, 107, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 125, 126, 128, 129, 131, 133, 135, 136, 137, 140, 141, 142, 144, 145, 147, 148, 149, 150, 152, 153, 154, 157, 159, 160, 161, 162, 163, 164, 166, 167, 169, 170, 171, 172, 173, 175, 176, 177, 179, 180, 181, 182, 184, 186, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 218, 219, 220, 221, 222, 223, 226, 228, 230, 231, 233, 235, 236, 237, 238, 240, 241, 244, 245, 248, 249, 250, 251, 253], NumPruned=412416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 792, 839, 885])>, Index=[512, 513, 514, 516, 518, 519, 521, 522, 524, 526, 527, 529, 530, 531, 534, 535, 536, 540, 541, 542, 543, 545, 546, 547, 549, 551, 552, 553, 555, 556, 558, 559, 562, 564, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 577, 580, 581, 582, 583, 584, 586, 587, 588, 589, 591, 592, 595, 598, 599, 600, 602, 603, 604, 605, 606, 608, 609, 610, 611, 614, 616, 618, 619, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 632, 634, 635, 637, 638, 640, 641, 643, 645, 647, 648, 649, 652, 653, 654, 656, 657, 659, 660, 661, 662, 664, 665, 666, 669, 671, 672, 673, 674, 675, 676, 678, 679, 681, 682, 683, 684, 685, 687, 688, 689, 691, 692, 693, 694, 696, 698, 700, 701, 702, 703, 704, 705, 706, 708, 709, 710, 712, 713, 714, 715, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 728, 730, 731, 732, 733, 734, 735, 738, 740, 742, 743, 745, 747, 748, 749, 750, 752, 753, 756, 757, 760, 761, 762, 763, 765], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(885, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 513, 514, 516, 518, 519, 521, 522, 524, 526, 527, 529, 530, 531, 534, 535, 536, 540, 541, 542, 543, 545, 546, 547, 549, 551, 552, 553, 555, 556, 558, 559, 562, 564, 565, 566, 567, 568, 569, 571, 572, 573, 574, 575, 577, 580, 581, 582, 583, 584, 586, 587, 588, 589, 591, 592, 595, 598, 599, 600, 602, 603, 604, 605, 606, 608, 609, 610, 611, 614, 616, 618, 619, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 632, 634, 635, 637, 638, 640, 641, 643, 645, 647, 648, 649, 652, 653, 654, 656, 657, 659, 660, 661, 662, 664, 665, 666, 669, 671, 672, 673, 674, 675, 676, 678, 679, 681, 682, 683, 684, 685, 687, 688, 689, 691, 692, 693, 694, 696, 698, 700, 701, 702, 703, 704, 705, 706, 708, 709, 710, 712, 713, 714, 715, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 728, 730, 731, 732, 733, 734, 735, 738, 740, 742, 743, 745, 747, 748, 749, 750, 752, 753, 756, 757, 760, 761, 762, 763, 765], NumPruned=91648]
543086 parameters will be pruned
-------------

2023-04-04 16:48:51.244 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.97.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 32, 35, 37, 39, 40, 41, 42, 47, 48, 49, 51, 52, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 75], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.97.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 32, 35, 37, 39, 40, 41, 42, 47, 48, 49, 51, 52, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 75], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 32, 35, 37, 39, 40, 41, 42, 47, 48, 49, 51, 52, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 75], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.98.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 32, 35, 37, 39, 40, 41, 42, 47, 48, 49, 51, 52, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 75], NumPruned=122112]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 589, 613, 660, 706])>, Index=[512, 515, 516, 518, 519, 520, 521, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 537, 538, 539, 540, 542, 544, 547, 549, 551, 552, 553, 554, 559, 560, 561, 563, 564, 568, 569, 570, 572, 573, 574, 575, 576, 577, 578, 579, 582, 583, 584, 585, 587], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(706, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 515, 516, 518, 519, 520, 521, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 537, 538, 539, 540, 542, 544, 547, 549, 551, 552, 553, 554, 559, 560, 561, 563, 564, 568, 569, 570, 572, 573, 574, 575, 576, 577, 578, 579, 582, 583, 584, 585, 587], NumPruned=27136]
160802 parameters will be pruned
-------------

2023-04-04 16:48:51.246 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.98.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 36, 38, 39, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 62, 63, 64, 66, 67, 69, 70, 71, 72, 73, 76, 77, 79, 83, 84, 85, 86, 88, 89, 91, 94, 95, 98, 99, 101, 104, 105, 106, 107, 108, 109, 111, 113, 114, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 177, 178, 179, 180, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 200, 202, 203, 206, 207, 210, 211, 216, 217, 218, 220, 221, 222, 223, 224, 226, 227, 228, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 246, 247, 248, 249, 250, 252, 253, 254], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.98.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 36, 38, 39, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 62, 63, 64, 66, 67, 69, 70, 71, 72, 73, 76, 77, 79, 83, 84, 85, 86, 88, 89, 91, 94, 95, 98, 99, 101, 104, 105, 106, 107, 108, 109, 111, 113, 114, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 177, 178, 179, 180, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 200, 202, 203, 206, 207, 210, 211, 216, 217, 218, 220, 221, 222, 223, 224, 226, 227, 228, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 246, 247, 248, 249, 250, 252, 253, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 36, 38, 39, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 62, 63, 64, 66, 67, 69, 70, 71, 72, 73, 76, 77, 79, 83, 84, 85, 86, 88, 89, 91, 94, 95, 98, 99, 101, 104, 105, 106, 107, 108, 109, 111, 113, 114, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 177, 178, 179, 180, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 200, 202, 203, 206, 207, 210, 211, 216, 217, 218, 220, 221, 222, 223, 224, 226, 227, 228, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 246, 247, 248, 249, 250, 252, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.99.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 36, 38, 39, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 62, 63, 64, 66, 67, 69, 70, 71, 72, 73, 76, 77, 79, 83, 84, 85, 86, 88, 89, 91, 94, 95, 98, 99, 101, 104, 105, 106, 107, 108, 109, 111, 113, 114, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 177, 178, 179, 180, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 200, 202, 203, 206, 207, 210, 211, 216, 217, 218, 220, 221, 222, 223, 224, 226, 227, 228, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 246, 247, 248, 249, 250, 252, 253, 254], NumPruned=412416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 536, 560, 607, 653])>, Index=[257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 269, 270, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 284, 285, 286, 288, 289, 292, 294, 295, 300, 301, 302, 304, 305, 306, 307, 308, 310, 311, 312, 314, 315, 316, 318, 319, 320, 322, 323, 325, 326, 327, 328, 329, 332, 333, 335, 339, 340, 341, 342, 344, 345, 347, 350, 351, 354, 355, 357, 360, 361, 362, 363, 364, 365, 367, 369, 370, 371, 372, 374, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 388, 389, 390, 394, 395, 396, 397, 399, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 418, 419, 420, 422, 423, 424, 425, 426, 427, 429, 430, 433, 434, 435, 436, 438, 439, 440, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 454, 456, 458, 459, 462, 463, 466, 467, 472, 473, 474, 476, 477, 478, 479, 480, 482, 483, 484, 488, 489, 490, 491, 493, 494, 495, 496, 497, 498, 502, 503, 504, 505, 506, 508, 509, 510], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(653, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 269, 270, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 284, 285, 286, 288, 289, 292, 294, 295, 300, 301, 302, 304, 305, 306, 307, 308, 310, 311, 312, 314, 315, 316, 318, 319, 320, 322, 323, 325, 326, 327, 328, 329, 332, 333, 335, 339, 340, 341, 342, 344, 345, 347, 350, 351, 354, 355, 357, 360, 361, 362, 363, 364, 365, 367, 369, 370, 371, 372, 374, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 388, 389, 390, 394, 395, 396, 397, 399, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 418, 419, 420, 422, 423, 424, 425, 426, 427, 429, 430, 433, 434, 435, 436, 438, 439, 440, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 454, 456, 458, 459, 462, 463, 466, 467, 472, 473, 474, 476, 477, 478, 479, 480, 482, 483, 484, 488, 489, 490, 491, 493, 494, 495, 496, 497, 498, 502, 503, 504, 505, 506, 508, 509, 510], NumPruned=91648]
543086 parameters will be pruned
-------------

2023-04-04 16:48:51.260 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.98.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 15, 16, 17, 19, 21, 25, 26, 28, 29, 31, 32, 34, 37, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.98.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 15, 16, 17, 19, 21, 25, 26, 28, 29, 31, 32, 34, 37, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 15, 16, 17, 19, 21, 25, 26, 28, 29, 31, 32, 34, 37, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.99.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 15, 16, 17, 19, 21, 25, 26, 28, 29, 31, 32, 34, 37, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74], NumPruned=122112]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 333, 357, 381, 428, 474])>, Index=[256, 257, 258, 259, 260, 261, 262, 264, 265, 266, 267, 268, 271, 272, 273, 275, 277, 281, 282, 284, 285, 287, 288, 290, 293, 295, 296, 297, 299, 300, 301, 302, 303, 305, 307, 308, 309, 310, 311, 312, 313, 316, 318, 319, 320, 323, 324, 325, 326, 327, 328, 329, 330], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(474, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 260, 261, 262, 264, 265, 266, 267, 268, 271, 272, 273, 275, 277, 281, 282, 284, 285, 287, 288, 290, 293, 295, 296, 297, 299, 300, 301, 302, 303, 305, 307, 308, 309, 310, 311, 312, 313, 316, 318, 319, 320, 323, 324, 325, 326, 327, 328, 329, 330], NumPruned=27136]
160802 parameters will be pruned
-------------

2023-04-04 16:48:51.261 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.99.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 10, 13, 15, 16, 17, 19, 20, 22, 23, 24, 26, 28, 30, 31, 32, 33, 34, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 80, 82, 83, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 104, 105, 106, 108, 109, 110, 113, 114, 115, 116, 120, 121, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 140, 142, 143, 145, 146, 147, 149, 150, 154, 155, 156, 158, 159, 160, 161, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 184, 185, 186, 187, 190, 191, 193, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 211, 212, 213, 218, 219, 220, 221, 222, 223, 225, 226, 228, 229, 231, 233, 234, 235, 236, 237, 239, 240, 241, 243, 245, 246, 250, 251, 252, 254], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.99.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 10, 13, 15, 16, 17, 19, 20, 22, 23, 24, 26, 28, 30, 31, 32, 33, 34, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 80, 82, 83, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 104, 105, 106, 108, 109, 110, 113, 114, 115, 116, 120, 121, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 140, 142, 143, 145, 146, 147, 149, 150, 154, 155, 156, 158, 159, 160, 161, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 184, 185, 186, 187, 190, 191, 193, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 211, 212, 213, 218, 219, 220, 221, 222, 223, 225, 226, 228, 229, 231, 233, 234, 235, 236, 237, 239, 240, 241, 243, 245, 246, 250, 251, 252, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 10, 13, 15, 16, 17, 19, 20, 22, 23, 24, 26, 28, 30, 31, 32, 33, 34, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 80, 82, 83, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 104, 105, 106, 108, 109, 110, 113, 114, 115, 116, 120, 121, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 140, 142, 143, 145, 146, 147, 149, 150, 154, 155, 156, 158, 159, 160, 161, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 184, 185, 186, 187, 190, 191, 193, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 211, 212, 213, 218, 219, 220, 221, 222, 223, 225, 226, 228, 229, 231, 233, 234, 235, 236, 237, 239, 240, 241, 243, 245, 246, 250, 251, 252, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 280, 304, 328, 375, 421])>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 10, 13, 15, 16, 17, 19, 20, 22, 23, 24, 26, 28, 30, 31, 32, 33, 34, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 80, 82, 83, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 104, 105, 106, 108, 109, 110, 113, 114, 115, 116, 120, 121, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 140, 142, 143, 145, 146, 147, 149, 150, 154, 155, 156, 158, 159, 160, 161, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 184, 185, 186, 187, 190, 191, 193, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 211, 212, 213, 218, 219, 220, 221, 222, 223, 225, 226, 228, 229, 231, 233, 234, 235, 236, 237, 239, 240, 241, 243, 245, 246, 250, 251, 252, 254], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(421, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 10, 13, 15, 16, 17, 19, 20, 22, 23, 24, 26, 28, 30, 31, 32, 33, 34, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 80, 82, 83, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 104, 105, 106, 108, 109, 110, 113, 114, 115, 116, 120, 121, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 140, 142, 143, 145, 146, 147, 149, 150, 154, 155, 156, 158, 159, 160, 161, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 184, 185, 186, 187, 190, 191, 193, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 211, 212, 213, 218, 219, 220, 221, 222, 223, 225, 226, 228, 229, 231, 233, 234, 235, 236, 237, 239, 240, 241, 243, 245, 246, 250, 251, 252, 254], NumPruned=91648]
130670 parameters will be pruned
-------------

2023-04-04 16:48:51.275 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.99.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 72, 73, 75], NumPruned=108]
[ <DEP: prune_batchnorm => prune_conv on model.99.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 72, 73, 75], NumPruned=11664]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 72, 73, 75], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 77, 101, 125, 149, 196, 242])>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 72, 73, 75], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.101.conv (Conv2d(242, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 72, 73, 75], NumPruned=27648]
39420 parameters will be pruned
-------------

2023-04-04 16:48:51.276 | INFO     | __main__:layer_pruning:84 -   Params: 37299042 => 12536449

2023-04-04 16:48:51.284 | ERROR    | __main__:<module>:98 - An error has been caught in function '<module>', process 'MainProcess' (2224), thread 'MainThread' (11208):
Traceback (most recent call last):

> File "E:\PyCharm2022.1.3\PycharmProjects\yolov7-main\tools\pruneModel.py", line 98, in <module>
    layer_pruning('../cfg/deploy/yolov7.pt')
    └ <function layer_pruning at 0x0000026F66DECAF0>

  File "E:\PyCharm2022.1.3\PycharmProjects\yolov7-main\tools\pruneModel.py", line 93, in layer_pruning
    torch.save(model_, '../model_data/layer_pruning.pt')
    │     │    └ {'model': Model(
    │     │        (model): Sequential(
    │     │          (0): Conv(
    │     │            (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=...
    │     └ <function save at 0x0000026F5482CA60>
    └ <module 'torch' from 'D:\\XUNXIE\\anaconda3\\envs\\gluon\\lib\\site-packages\\torch\\__init__.py'>

  File "D:\XUNXIE\anaconda3\envs\gluon\lib\site-packages\torch\serialization.py", line 377, in save
    with _open_file_like(f, 'wb') as opened_file:
         │               └ '../model_data/layer_pruning.pt'
         └ <function _open_file_like at 0x0000026F5482C040>

  File "D:\XUNXIE\anaconda3\envs\gluon\lib\site-packages\torch\serialization.py", line 231, in _open_file_like
    return _open_file(name_or_buffer, mode)
           │          │               └ 'wb'
           │          └ '../model_data/layer_pruning.pt'
           └ <class 'torch.serialization._open_file'>

  File "D:\XUNXIE\anaconda3\envs\gluon\lib\site-packages\torch\serialization.py", line 212, in __init__
    super(_open_file, self).__init__(open(name, mode))
          │           │                   │     └ 'wb'
          │           │                   └ '../model_data/layer_pruning.pt'
          │           └ <torch.serialization._open_file object at 0x0000026F1BD03B20>
          └ <class 'torch.serialization._open_file'>

FileNotFoundError: [Errno 2] No such file or directory: '../model_data/layer_pruning.pt'
2023-04-04 16:49:45.130 | INFO     | __main__:layer_pruning:63 - [Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)]
2023-04-04 16:49:45.136 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.0.conv (Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 24, 25, 26, 27, 29, 30, 31], NumPruned=594]
[ <DEP: prune_conv => prune_batchnorm on model.0.bn (BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 24, 25, 26, 27, 29, 30, 31], NumPruned=44]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 24, 25, 26, 27, 29, 30, 31], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.1.conv (Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 24, 25, 26, 27, 29, 30, 31], NumPruned=12672]
13310 parameters will be pruned
-------------

2023-04-04 16:49:45.137 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.0.bn (BatchNorm2d(10, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 7, 9], NumPruned=14]
[ <DEP: prune_batchnorm => prune_conv on model.0.conv (Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 9], NumPruned=189]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 9], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.1.conv (Conv2d(10, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 9], NumPruned=4032]
4235 parameters will be pruned
-------------

2023-04-04 16:49:45.138 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.1.conv (Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 18, 22, 23, 25, 26, 27, 28, 30, 32, 33, 34, 35, 37, 38, 39, 40, 44, 45, 46, 48, 49, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63], NumPruned=1188]
[ <DEP: prune_conv => prune_batchnorm on model.1.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 18, 22, 23, 25, 26, 27, 28, 30, 32, 33, 34, 35, 37, 38, 39, 40, 44, 45, 46, 48, 49, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 18, 22, 23, 25, 26, 27, 28, 30, 32, 33, 34, 35, 37, 38, 39, 40, 44, 45, 46, 48, 49, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.2.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 18, 22, 23, 25, 26, 27, 28, 30, 32, 33, 34, 35, 37, 38, 39, 40, 44, 45, 46, 48, 49, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63], NumPruned=25344]
26620 parameters will be pruned
-------------

2023-04-04 16:49:45.139 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.1.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.1.conv (Conv2d(3, 20, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18], NumPruned=378]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.2.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 10, 12, 13, 14, 15, 16, 17, 18], NumPruned=8064]
8470 parameters will be pruned
-------------

2023-04-04 16:49:45.152 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.2.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 6, 8, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 56, 58, 59, 62, 63], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.2.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 6, 8, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 56, 58, 59, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 6, 8, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 56, 58, 59, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.3.conv (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 3, 6, 8, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 56, 58, 59, 62, 63], NumPruned=50688]
53152 parameters will be pruned
-------------

2023-04-04 16:49:45.153 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.2.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 5, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.2.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 5, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.3.conv (Conv2d(20, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19], NumPruned=16128]
16912 parameters will be pruned
-------------

2023-04-04 16:49:45.154 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.3.conv (Conv2d(6, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 50, 52, 57, 60, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 78, 79, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127], NumPruned=4806]
[ <DEP: prune_conv => prune_batchnorm on model.3.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 50, 52, 57, 60, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 78, 79, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 50, 52, 57, 60, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 78, 79, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.5.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 50, 52, 57, 60, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 78, 79, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127], NumPruned=5696]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.4.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 50, 52, 57, 60, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 78, 79, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127], NumPruned=5696]
16376 parameters will be pruned
-------------

2023-04-04 16:49:45.167 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.3.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 36, 37], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.3.conv (Conv2d(6, 39, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 36, 37], NumPruned=1458]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 36, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.5.conv (Conv2d(39, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 36, 37], NumPruned=1728]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.4.conv (Conv2d(39, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 36, 37], NumPruned=1728]
4968 parameters will be pruned
-------------

2023-04-04 16:49:45.168 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.4.conv (Conv2d(12, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 3, 4, 6, 8, 11, 12, 14, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 50, 51, 53, 54, 56, 58, 61, 63], NumPruned=528]
[ <DEP: prune_conv => prune_batchnorm on model.4.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 6, 8, 11, 12, 14, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 50, 51, 53, 54, 56, 58, 61, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 6, 8, 11, 12, 14, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 50, 51, 53, 54, 56, 58, 61, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256])>, Index=[194, 195, 196, 198, 200, 203, 204, 206, 208, 209, 210, 211, 212, 214, 215, 216, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 237, 238, 239, 240, 242, 243, 245, 246, 248, 250, 253, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[194, 195, 196, 198, 200, 203, 204, 206, 208, 209, 210, 211, 212, 214, 215, 216, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 237, 238, 239, 240, 242, 243, 245, 246, 248, 250, 253, 255], NumPruned=11264]
11880 parameters will be pruned
-------------

2023-04-04 16:49:45.169 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.4.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 7, 10, 11, 14, 15, 17, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.4.conv (Conv2d(12, 20, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 10, 11, 14, 15, 17, 18, 19], NumPruned=168]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 7, 10, 11, 14, 15, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 212])>, Index=[192, 193, 194, 195, 196, 198, 199, 202, 203, 206, 207, 209, 210, 211], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(212, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[192, 193, 194, 195, 196, 198, 199, 202, 203, 206, 207, 209, 210, 211], NumPruned=3584]
3780 parameters will be pruned
-------------

2023-04-04 16:49:45.184 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.5.conv (Conv2d(12, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 8, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 48, 50, 51, 53, 54, 55, 56, 58, 59, 62, 63], NumPruned=528]
[ <DEP: prune_conv => prune_batchnorm on model.5.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 6, 8, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 48, 50, 51, 53, 54, 55, 56, 58, 59, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 6, 8, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 48, 50, 51, 53, 54, 55, 56, 58, 59, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.6.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 8, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 48, 50, 51, 53, 54, 55, 56, 58, 59, 62, 63], NumPruned=25344]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 198])>, Index=[128, 131, 132, 134, 136, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 173, 174, 176, 178, 179, 181, 182, 183, 184, 186, 187, 190, 191], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(198, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 131, 132, 134, 136, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 173, 174, 176, 178, 179, 181, 182, 183, 184, 186, 187, 190, 191], NumPruned=11264]
37224 parameters will be pruned
-------------

2023-04-04 16:49:45.185 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.5.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.5.conv (Conv2d(12, 20, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17], NumPruned=168]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.6.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17], NumPruned=8064]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 148, 154])>, Index=[130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(154, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145], NumPruned=3584]
11844 parameters will be pruned
-------------

2023-04-04 16:49:45.186 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.6.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 21, 25, 27, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.6.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 21, 25, 27, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 21, 25, 27, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.7.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 21, 25, 27, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63], NumPruned=25344]
27808 parameters will be pruned
-------------

2023-04-04 16:49:45.199 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.6.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.6.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 18, 19], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.7.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 18, 19], NumPruned=8064]
8848 parameters will be pruned
-------------

2023-04-04 16:49:45.200 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.7.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 12, 14, 15, 18, 20, 21, 22, 25, 27, 28, 29, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 62], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.7.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 12, 14, 15, 18, 20, 21, 22, 25, 27, 28, 29, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 62], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 12, 14, 15, 18, 20, 21, 22, 25, 27, 28, 29, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 62], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.8.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 12, 14, 15, 18, 20, 21, 22, 25, 27, 28, 29, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 62], NumPruned=25344]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 134, 140])>, Index=[64, 65, 66, 67, 68, 69, 70, 74, 76, 78, 79, 82, 84, 85, 86, 89, 91, 92, 93, 95, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 119, 120, 121, 122, 123, 124, 126], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(140, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 65, 66, 67, 68, 69, 70, 74, 76, 78, 79, 82, 84, 85, 86, 89, 91, 92, 93, 95, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 119, 120, 121, 122, 123, 124, 126], NumPruned=11264]
39072 parameters will be pruned
-------------

2023-04-04 16:49:45.201 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.7.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.7.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.8.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18], NumPruned=8064]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 84, 90, 96])>, Index=[64, 65, 67, 69, 71, 72, 73, 75, 76, 77, 79, 80, 81, 82], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 65, 67, 69, 71, 72, 73, 75, 76, 77, 79, 80, 81, 82], NumPruned=3584]
12432 parameters will be pruned
-------------

2023-04-04 16:49:45.215 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.8.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 7, 10, 14, 15, 18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.8.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 7, 10, 14, 15, 18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 7, 10, 14, 15, 18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.9.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 7, 10, 14, 15, 18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], NumPruned=25344]
27808 parameters will be pruned
-------------

2023-04-04 16:49:45.216 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.8.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], NumPruned=30]
[ <DEP: prune_batchnorm => prune_conv on model.8.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], NumPruned=810]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.9.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], NumPruned=8640]
9480 parameters will be pruned
-------------

2023-04-04 16:49:45.217 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.9.conv (Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 33, 37, 39, 40, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63], NumPruned=1980]
[ <DEP: prune_conv => prune_batchnorm on model.9.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 33, 37, 39, 40, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 33, 37, 39, 40, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 70, 76, 82])>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 33, 37, 39, 40, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(82, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 33, 37, 39, 40, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63], NumPruned=11264]
13332 parameters will be pruned
-------------

2023-04-04 16:49:45.231 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.9.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.9.conv (Conv2d(5, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 18, 19], NumPruned=630]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 20, 26, 32, 38])>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(38, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 18, 19], NumPruned=3584]
4242 parameters will be pruned
-------------

2023-04-04 16:49:45.233 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.11.conv (Conv2d(24, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=4296]
[ <DEP: prune_conv => prune_batchnorm on model.11.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.14.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=22912]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.13.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 139, 141, 142, 143, 144, 145, 147, 152, 153, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 208, 211, 213, 214, 215, 216, 217, 219, 222, 223, 225, 227, 228, 229, 230, 231, 233, 236, 237, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 253, 254], NumPruned=22912]
50478 parameters will be pruned
-------------

2023-04-04 16:49:45.248 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.11.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=108]
[ <DEP: prune_batchnorm => prune_conv on model.11.conv (Conv2d(24, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=1296]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.14.conv (Conv2d(77, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=6912]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.13.conv (Conv2d(77, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 63, 64, 70, 71, 73, 74, 75], NumPruned=6912]
15228 parameters will be pruned
-------------

2023-04-04 16:49:45.249 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.13.conv (Conv2d(23, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 19, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 44, 45, 46, 47, 48, 52, 53, 54, 57, 59, 60, 61, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 98, 99, 103, 106, 107, 108, 109, 110, 113, 115, 117, 119, 122, 123, 124, 125, 126, 127], NumPruned=2047]
[ <DEP: prune_conv => prune_batchnorm on model.13.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 19, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 44, 45, 46, 47, 48, 52, 53, 54, 57, 59, 60, 61, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 98, 99, 103, 106, 107, 108, 109, 110, 113, 115, 117, 119, 122, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 19, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 44, 45, 46, 47, 48, 52, 53, 54, 57, 59, 60, 61, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 98, 99, 103, 106, 107, 108, 109, 110, 113, 115, 117, 119, 122, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256])>, Index=[128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 147, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 164, 165, 166, 167, 172, 173, 174, 175, 176, 180, 181, 182, 185, 187, 188, 189, 190, 192, 193, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 214, 215, 216, 218, 220, 221, 222, 223, 224, 226, 227, 231, 234, 235, 236, 237, 238, 241, 243, 245, 247, 250, 251, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.18.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 147, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 164, 165, 166, 167, 172, 173, 174, 175, 176, 180, 181, 182, 185, 187, 188, 189, 190, 192, 193, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 214, 215, 216, 218, 220, 221, 222, 223, 224, 226, 227, 231, 234, 235, 236, 237, 238, 241, 243, 245, 247, 250, 251, 252, 253, 254, 255], NumPruned=11392]
[ <DEP: _prune_concat => prune_related_conv on model.17.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 147, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 164, 165, 166, 167, 172, 173, 174, 175, 176, 180, 181, 182, 185, 187, 188, 189, 190, 192, 193, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 214, 215, 216, 218, 220, 221, 222, 223, 224, 226, 227, 231, 234, 235, 236, 237, 238, 241, 243, 245, 247, 250, 251, 252, 253, 254, 255], NumPruned=11392]
25009 parameters will be pruned
-------------

2023-04-04 16:49:45.264 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.13.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.13.conv (Conv2d(23, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38], NumPruned=621]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 10, 11, 13, 14, 15, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 167])>, Index=[128, 130, 132, 133, 134, 135, 138, 139, 141, 142, 143, 146, 147, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 162, 164, 165, 166], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.18.conv (Conv2d(167, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 130, 132, 133, 134, 135, 138, 139, 141, 142, 143, 146, 147, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 162, 164, 165, 166], NumPruned=3456]
[ <DEP: _prune_concat => prune_related_conv on model.17.conv (Conv2d(167, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 130, 132, 133, 134, 135, 138, 139, 141, 142, 143, 146, 147, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 162, 164, 165, 166], NumPruned=3456]
7587 parameters will be pruned
-------------

2023-04-04 16:49:45.265 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.14.conv (Conv2d(23, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 34, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 71, 72, 73, 75, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 127], NumPruned=2047]
[ <DEP: prune_conv => prune_batchnorm on model.14.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 34, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 71, 72, 73, 75, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 34, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 71, 72, 73, 75, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.15.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 34, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 71, 72, 73, 75, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 127], NumPruned=102528]
104753 parameters will be pruned
-------------

2023-04-04 16:49:45.266 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.14.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 14, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 31, 33, 34, 35, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.14.conv (Conv2d(23, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 14, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 31, 33, 34, 35, 38], NumPruned=621]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 14, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 31, 33, 34, 35, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.15.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 14, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 31, 33, 34, 35, 38], NumPruned=31104]
31779 parameters will be pruned
-------------

2023-04-04 16:49:45.279 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.15.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.15.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 140])>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.18.conv (Conv2d(140, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=11392]
[ <DEP: _prune_concat => prune_related_conv on model.17.conv (Conv2d(140, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21, 22, 24, 26, 29, 31, 32, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 74, 76, 77, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127], NumPruned=11392]
32574 parameters will be pruned
-------------

2023-04-04 16:49:45.280 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.15.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.15.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 39, 51])>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.18.conv (Conv2d(51, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=3456]
[ <DEP: _prune_concat => prune_related_conv on model.17.conv (Conv2d(51, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 15, 16, 17, 18, 19, 22, 23, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38], NumPruned=3456]
9882 parameters will be pruned
-------------

2023-04-04 16:49:45.296 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.17.conv (Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 102, 104, 105, 106, 108, 110, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125], NumPruned=2136]
[ <DEP: prune_conv => prune_batchnorm on model.17.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 102, 104, 105, 106, 108, 110, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 102, 104, 105, 106, 108, 110, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512])>, Index=[385, 386, 387, 393, 394, 395, 396, 398, 399, 402, 403, 404, 405, 407, 408, 409, 410, 412, 414, 415, 416, 417, 418, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 436, 439, 440, 441, 442, 443, 444, 447, 448, 449, 450, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 468, 471, 472, 473, 474, 475, 476, 479, 480, 481, 482, 483, 486, 488, 489, 490, 492, 494, 497, 498, 500, 501, 502, 503, 505, 507, 508, 509], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[385, 386, 387, 393, 394, 395, 396, 398, 399, 402, 403, 404, 405, 407, 408, 409, 410, 412, 414, 415, 416, 417, 418, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 436, 439, 440, 441, 442, 443, 444, 447, 448, 449, 450, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 468, 471, 472, 473, 474, 475, 476, 479, 480, 481, 482, 483, 486, 488, 489, 490, 492, 494, 497, 498, 500, 501, 502, 503, 505, 507, 508, 509], NumPruned=45568]
47882 parameters will be pruned
-------------

2023-04-04 16:49:45.298 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.17.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 23, 24, 26, 29, 31, 32, 34, 35, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.17.conv (Conv2d(24, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 23, 24, 26, 29, 31, 32, 34, 35, 37, 38], NumPruned=648]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 23, 24, 26, 29, 31, 32, 34, 35, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 423])>, Index=[385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 399, 400, 401, 402, 404, 407, 408, 410, 413, 415, 416, 418, 419, 421, 422], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(423, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 399, 400, 401, 402, 404, 407, 408, 410, 413, 415, 416, 418, 419, 421, 422], NumPruned=13824]
14526 parameters will be pruned
-------------

2023-04-04 16:49:45.312 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.18.conv (Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 55, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 73, 76, 77, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 94, 95, 100, 102, 104, 106, 108, 109, 110, 113, 114, 116, 117, 118, 121, 122, 123, 124, 125, 126], NumPruned=2136]
[ <DEP: prune_conv => prune_batchnorm on model.18.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 55, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 73, 76, 77, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 94, 95, 100, 102, 104, 106, 108, 109, 110, 113, 114, 116, 117, 118, 121, 122, 123, 124, 125, 126], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 55, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 73, 76, 77, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 94, 95, 100, 102, 104, 106, 108, 109, 110, 113, 114, 116, 117, 118, 121, 122, 123, 124, 125, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.19.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 55, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 73, 76, 77, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 94, 95, 100, 102, 104, 106, 108, 109, 110, 113, 114, 116, 117, 118, 121, 122, 123, 124, 125, 126], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 396])>, Index=[256, 257, 258, 259, 260, 261, 264, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 285, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 306, 307, 308, 311, 314, 315, 316, 317, 318, 320, 321, 323, 324, 325, 326, 328, 329, 332, 333, 335, 336, 337, 338, 339, 340, 343, 344, 345, 346, 348, 350, 351, 356, 358, 360, 362, 364, 365, 366, 369, 370, 372, 373, 374, 377, 378, 379, 380, 381, 382], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(396, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 260, 261, 264, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 285, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 306, 307, 308, 311, 314, 315, 316, 317, 318, 320, 321, 323, 324, 325, 326, 328, 329, 332, 333, 335, 336, 337, 338, 339, 340, 343, 344, 345, 346, 348, 350, 351, 356, 358, 360, 362, 364, 365, 366, 369, 370, 372, 373, 374, 377, 378, 379, 380, 381, 382], NumPruned=45568]
150410 parameters will be pruned
-------------

2023-04-04 16:49:45.313 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.18.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.18.conv (Conv2d(24, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36], NumPruned=648]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.19.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 295, 307])>, Index=[257, 258, 259, 260, 261, 262, 263, 267, 268, 269, 271, 272, 273, 276, 277, 278, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(307, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 259, 260, 261, 262, 263, 267, 268, 269, 271, 272, 273, 276, 277, 278, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292], NumPruned=13824]
45630 parameters will be pruned
-------------

2023-04-04 16:49:45.328 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.19.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 49, 50, 52, 53, 54, 55, 57, 58, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 109, 110, 112, 114, 118, 121, 122, 123, 124, 125, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.19.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 49, 50, 52, 53, 54, 55, 57, 58, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 109, 110, 112, 114, 118, 121, 122, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 49, 50, 52, 53, 54, 55, 57, 58, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 109, 110, 112, 114, 118, 121, 122, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.20.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 49, 50, 52, 53, 54, 55, 57, 58, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 109, 110, 112, 114, 118, 121, 122, 123, 124, 125, 126, 127], NumPruned=102528]
112318 parameters will be pruned
-------------

2023-04-04 16:49:45.329 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.19.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 19, 20, 21, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.19.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 19, 20, 21, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 19, 20, 21, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.20.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 19, 20, 21, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38], NumPruned=31104]
34074 parameters will be pruned
-------------

2023-04-04 16:49:45.330 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.20.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 55, 56, 58, 59, 63, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 96, 97, 99, 101, 103, 104, 105, 107, 108, 111, 112, 114, 116, 117, 118, 119, 121, 122, 123, 125, 126], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.20.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 4, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 55, 56, 58, 59, 63, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 96, 97, 99, 101, 103, 104, 105, 107, 108, 111, 112, 114, 116, 117, 118, 119, 121, 122, 123, 125, 126], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 4, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 55, 56, 58, 59, 63, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 96, 97, 99, 101, 103, 104, 105, 107, 108, 111, 112, 114, 116, 117, 118, 119, 121, 122, 123, 125, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.21.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 55, 56, 58, 59, 63, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 96, 97, 99, 101, 103, 104, 105, 107, 108, 111, 112, 114, 116, 117, 118, 119, 121, 122, 123, 125, 126], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 268, 280])>, Index=[128, 129, 132, 133, 134, 135, 137, 139, 141, 142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 164, 165, 166, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 181, 183, 184, 186, 187, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 208, 209, 210, 211, 213, 214, 216, 217, 218, 220, 221, 224, 225, 227, 229, 231, 232, 233, 235, 236, 239, 240, 242, 244, 245, 246, 247, 249, 250, 251, 253, 254], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(280, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 132, 133, 134, 135, 137, 139, 141, 142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 164, 165, 166, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 181, 183, 184, 186, 187, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 208, 209, 210, 211, 213, 214, 216, 217, 218, 220, 221, 224, 225, 227, 229, 231, 232, 233, 235, 236, 239, 240, 242, 244, 245, 246, 247, 249, 250, 251, 253, 254], NumPruned=45568]
157886 parameters will be pruned
-------------

2023-04-04 16:49:45.344 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.20.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 21, 23, 24, 25, 26, 30, 31, 33, 36, 37], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.20.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 21, 23, 24, 25, 26, 30, 31, 33, 36, 37], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 21, 23, 24, 25, 26, 30, 31, 33, 36, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.21.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 21, 23, 24, 25, 26, 30, 31, 33, 36, 37], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 167, 179, 191])>, Index=[128, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 146, 148, 149, 151, 152, 153, 154, 158, 159, 161, 164, 165], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(191, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 146, 148, 149, 151, 152, 153, 154, 158, 159, 161, 164, 165], NumPruned=13824]
47898 parameters will be pruned
-------------

2023-04-04 16:49:45.346 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.21.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 63, 65, 66, 68, 69, 70, 71, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 105, 108, 109, 110, 111, 112, 114, 115, 117, 120, 121, 123, 124, 126], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.21.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 63, 65, 66, 68, 69, 70, 71, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 105, 108, 109, 110, 111, 112, 114, 115, 117, 120, 121, 123, 124, 126], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 63, 65, 66, 68, 69, 70, 71, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 105, 108, 109, 110, 111, 112, 114, 115, 117, 120, 121, 123, 124, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.22.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 63, 65, 66, 68, 69, 70, 71, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 105, 108, 109, 110, 111, 112, 114, 115, 117, 120, 121, 123, 124, 126], NumPruned=102528]
112318 parameters will be pruned
-------------

2023-04-04 16:49:45.347 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.21.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 32, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.21.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 32, 36, 37, 38], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 32, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.22.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 32, 36, 37, 38], NumPruned=31104]
34074 parameters will be pruned
-------------

2023-04-04 16:49:45.360 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.22.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 65, 69, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 94, 96, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 112, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.22.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 65, 69, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 94, 96, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 112, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 65, 69, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 94, 96, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 112, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 140, 152, 164])>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 65, 69, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 94, 96, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 112, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(164, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 65, 69, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 92, 93, 94, 96, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 112, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127], NumPruned=45568]
55358 parameters will be pruned
-------------

2023-04-04 16:49:45.361 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.22.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.22.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 39, 51, 63, 75])>, Index=[2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(75, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33], NumPruned=13824]
16794 parameters will be pruned
-------------

2023-04-04 16:49:45.362 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.24.conv (Conv2d(48, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=17184]
[ <DEP: prune_conv => prune_batchnorm on model.24.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=716]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.66.conv (Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=45824]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.27.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=91648]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.26.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 7, 12, 13, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 85, 86, 93, 95, 96, 98, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 129, 130, 133, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 203, 204, 206, 207, 208, 210, 212, 213, 217, 218, 219, 224, 226, 227, 230, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 279, 280, 282, 284, 285, 286, 287, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 355, 357, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 392, 395, 396, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 422, 424, 425, 428, 429, 430, 431, 432, 437, 439, 440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 466, 468, 469, 473, 474, 475, 476, 478, 479, 481, 484, 485, 486, 487, 488, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 508, 510, 511], NumPruned=91648]
247020 parameters will be pruned
-------------

2023-04-04 16:49:45.376 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.24.bn (BatchNorm2d(154, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=214]
[ <DEP: prune_batchnorm => prune_conv on model.24.conv (Conv2d(48, 154, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=5136]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.66.conv (Conv2d(154, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=13696]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.27.conv (Conv2d(154, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=27392]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.26.conv (Conv2d(154, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 63, 64, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 140, 141, 142, 147, 148, 150, 151, 152], NumPruned=27392]
73830 parameters will be pruned
-------------

2023-04-04 16:49:45.392 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.26.conv (Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 15, 18, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 74, 75, 76, 79, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 109, 110, 112, 113, 115, 118, 119, 121, 122, 123, 125, 126, 127, 129, 132, 134, 135, 136, 137, 139, 140, 141, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 162, 163, 165, 166, 168, 169, 173, 174, 175, 178, 180, 181, 182, 183, 184, 185, 186, 190, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 211, 215, 217, 218, 219, 220, 221, 222, 223, 225, 228, 229, 230, 231, 232, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 254, 255], NumPruned=8413]
[ <DEP: prune_conv => prune_batchnorm on model.26.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 15, 18, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 74, 75, 76, 79, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 109, 110, 112, 113, 115, 118, 119, 121, 122, 123, 125, 126, 127, 129, 132, 134, 135, 136, 137, 139, 140, 141, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 162, 163, 165, 166, 168, 169, 173, 174, 175, 178, 180, 181, 182, 183, 184, 185, 186, 190, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 211, 215, 217, 218, 219, 220, 221, 222, 223, 225, 228, 229, 230, 231, 232, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 15, 18, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 74, 75, 76, 79, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 109, 110, 112, 113, 115, 118, 119, 121, 122, 123, 125, 126, 127, 129, 132, 134, 135, 136, 137, 139, 140, 141, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 162, 163, 165, 166, 168, 169, 173, 174, 175, 178, 180, 181, 182, 183, 184, 185, 186, 190, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 209, 210, 211, 215, 217, 218, 219, 220, 221, 222, 223, 225, 228, 229, 230, 231, 232, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512])>, Index=[256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 268, 270, 271, 274, 276, 277, 278, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 294, 295, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 316, 317, 318, 319, 320, 321, 322, 323, 326, 327, 328, 330, 331, 332, 335, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 359, 360, 361, 362, 365, 366, 368, 369, 371, 374, 375, 377, 378, 379, 381, 382, 383, 385, 388, 390, 391, 392, 393, 395, 396, 397, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 418, 419, 421, 422, 424, 425, 429, 430, 431, 434, 436, 437, 438, 439, 440, 441, 442, 446, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467, 471, 473, 474, 475, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.31.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 268, 270, 271, 274, 276, 277, 278, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 294, 295, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 316, 317, 318, 319, 320, 321, 322, 323, 326, 327, 328, 330, 331, 332, 335, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 359, 360, 361, 362, 365, 366, 368, 369, 371, 374, 375, 377, 378, 379, 381, 382, 383, 385, 388, 390, 391, 392, 393, 395, 396, 397, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 418, 419, 421, 422, 424, 425, 429, 430, 431, 434, 436, 437, 438, 439, 440, 441, 442, 446, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467, 471, 473, 474, 475, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 510, 511], NumPruned=45824]
[ <DEP: _prune_concat => prune_related_conv on model.30.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 268, 270, 271, 274, 276, 277, 278, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 294, 295, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 316, 317, 318, 319, 320, 321, 322, 323, 326, 327, 328, 330, 331, 332, 335, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 359, 360, 361, 362, 365, 366, 368, 369, 371, 374, 375, 377, 378, 379, 381, 382, 383, 385, 388, 390, 391, 392, 393, 395, 396, 397, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 418, 419, 421, 422, 424, 425, 429, 430, 431, 434, 436, 437, 438, 439, 440, 441, 442, 446, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467, 471, 473, 474, 475, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 510, 511], NumPruned=45824]
100419 parameters will be pruned
-------------

2023-04-04 16:49:45.408 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.26.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 17, 20, 21, 22, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 55, 56, 58, 59, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.26.conv (Conv2d(47, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 17, 20, 21, 22, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 55, 56, 58, 59, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76], NumPruned=2491]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 17, 20, 21, 22, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 55, 56, 58, 59, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 333])>, Index=[257, 259, 260, 261, 262, 263, 264, 268, 269, 270, 271, 273, 276, 277, 278, 281, 282, 283, 284, 285, 288, 289, 290, 291, 293, 294, 297, 298, 300, 301, 302, 303, 304, 307, 308, 309, 311, 312, 314, 315, 317, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 332], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.31.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 259, 260, 261, 262, 263, 264, 268, 269, 270, 271, 273, 276, 277, 278, 281, 282, 283, 284, 285, 288, 289, 290, 291, 293, 294, 297, 298, 300, 301, 302, 303, 304, 307, 308, 309, 311, 312, 314, 315, 317, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 332], NumPruned=13568]
[ <DEP: _prune_concat => prune_related_conv on model.30.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 259, 260, 261, 262, 263, 264, 268, 269, 270, 271, 273, 276, 277, 278, 281, 282, 283, 284, 285, 288, 289, 290, 291, 293, 294, 297, 298, 300, 301, 302, 303, 304, 307, 308, 309, 311, 312, 314, 315, 317, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 332], NumPruned=13568]
29733 parameters will be pruned
-------------

2023-04-04 16:49:45.409 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.27.conv (Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 98, 103, 104, 105, 106, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 138, 139, 140, 142, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 155, 157, 158, 161, 164, 166, 167, 168, 169, 170, 172, 173, 175, 176, 177, 178, 179, 180, 182, 183, 185, 186, 187, 189, 190, 192, 193, 194, 196, 198, 199, 200, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 224, 228, 231, 232, 233, 234, 235, 237, 238, 240, 241, 242, 243, 244, 246, 247, 248, 250, 252, 254, 255], NumPruned=8413]
[ <DEP: prune_conv => prune_batchnorm on model.27.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 98, 103, 104, 105, 106, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 138, 139, 140, 142, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 155, 157, 158, 161, 164, 166, 167, 168, 169, 170, 172, 173, 175, 176, 177, 178, 179, 180, 182, 183, 185, 186, 187, 189, 190, 192, 193, 194, 196, 198, 199, 200, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 224, 228, 231, 232, 233, 234, 235, 237, 238, 240, 241, 242, 243, 244, 246, 247, 248, 250, 252, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 98, 103, 104, 105, 106, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 138, 139, 140, 142, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 155, 157, 158, 161, 164, 166, 167, 168, 169, 170, 172, 173, 175, 176, 177, 178, 179, 180, 182, 183, 185, 186, 187, 189, 190, 192, 193, 194, 196, 198, 199, 200, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 224, 228, 231, 232, 233, 234, 235, 237, 238, 240, 241, 242, 243, 244, 246, 247, 248, 250, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.28.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 62, 63, 64, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 98, 103, 104, 105, 106, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 138, 139, 140, 142, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 155, 157, 158, 161, 164, 166, 167, 168, 169, 170, 172, 173, 175, 176, 177, 178, 179, 180, 182, 183, 185, 186, 187, 189, 190, 192, 193, 194, 196, 198, 199, 200, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 224, 228, 231, 232, 233, 234, 235, 237, 238, 240, 241, 242, 243, 244, 246, 247, 248, 250, 252, 254, 255], NumPruned=412416]
421187 parameters will be pruned
-------------

2023-04-04 16:49:45.424 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.27.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 53, 54, 55, 62, 63, 64, 67, 69, 72, 73, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.27.conv (Conv2d(47, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 53, 54, 55, 62, 63, 64, 67, 69, 72, 73, 74, 75, 76], NumPruned=2491]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 53, 54, 55, 62, 63, 64, 67, 69, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.28.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 53, 54, 55, 62, 63, 64, 67, 69, 72, 73, 74, 75, 76], NumPruned=122112]
124709 parameters will be pruned
-------------

2023-04-04 16:49:45.425 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.28.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.28.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 280])>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.31.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=45824]
[ <DEP: _prune_concat => prune_related_conv on model.30.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 116, 118, 122, 124, 126, 127, 129, 130, 131, 134, 135, 136, 137, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 192, 193, 195, 196, 197, 199, 201, 202, 204, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 255], NumPruned=45824]
130670 parameters will be pruned
-------------

2023-04-04 16:49:45.440 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.28.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.28.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 77, 101])>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.31.conv (Conv2d(101, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=13568]
[ <DEP: _prune_concat => prune_related_conv on model.30.conv (Conv2d(101, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76], NumPruned=13568]
38690 parameters will be pruned
-------------

2023-04-04 16:49:45.441 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.30.conv (Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 6, 7, 8, 12, 13, 14, 15, 16, 17, 22, 25, 26, 27, 31, 32, 33, 34, 36, 37, 41, 42, 44, 45, 46, 47, 51, 53, 54, 56, 57, 58, 59, 60, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 82, 83, 84, 85, 86, 88, 90, 92, 93, 94, 95, 98, 100, 102, 103, 104, 106, 107, 108, 111, 112, 113, 114, 115, 116, 122, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 136, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 175, 176, 177, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 202, 203, 204, 205, 207, 208, 209, 210, 211, 214, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 229, 231, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254], NumPruned=8592]
[ <DEP: prune_conv => prune_batchnorm on model.30.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 5, 6, 7, 8, 12, 13, 14, 15, 16, 17, 22, 25, 26, 27, 31, 32, 33, 34, 36, 37, 41, 42, 44, 45, 46, 47, 51, 53, 54, 56, 57, 58, 59, 60, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 82, 83, 84, 85, 86, 88, 90, 92, 93, 94, 95, 98, 100, 102, 103, 104, 106, 107, 108, 111, 112, 113, 114, 115, 116, 122, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 136, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 175, 176, 177, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 202, 203, 204, 205, 207, 208, 209, 210, 211, 214, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 229, 231, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 5, 6, 7, 8, 12, 13, 14, 15, 16, 17, 22, 25, 26, 27, 31, 32, 33, 34, 36, 37, 41, 42, 44, 45, 46, 47, 51, 53, 54, 56, 57, 58, 59, 60, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 82, 83, 84, 85, 86, 88, 90, 92, 93, 94, 95, 98, 100, 102, 103, 104, 106, 107, 108, 111, 112, 113, 114, 115, 116, 122, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 136, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 175, 176, 177, 179, 180, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 202, 203, 204, 205, 207, 208, 209, 210, 211, 214, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 229, 231, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 1024])>, Index=[768, 770, 771, 773, 774, 775, 776, 780, 781, 782, 783, 784, 785, 790, 793, 794, 795, 799, 800, 801, 802, 804, 805, 809, 810, 812, 813, 814, 815, 819, 821, 822, 824, 825, 826, 827, 828, 834, 835, 836, 837, 838, 839, 840, 841, 844, 845, 846, 847, 850, 851, 852, 853, 854, 856, 858, 860, 861, 862, 863, 866, 868, 870, 871, 872, 874, 875, 876, 879, 880, 881, 882, 883, 884, 890, 891, 893, 895, 896, 897, 898, 899, 900, 902, 903, 904, 906, 907, 908, 909, 910, 911, 913, 914, 916, 917, 918, 920, 921, 922, 923, 924, 925, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 943, 944, 945, 947, 948, 951, 952, 953, 954, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 968, 970, 971, 972, 973, 975, 976, 977, 978, 979, 982, 984, 985, 986, 987, 988, 989, 991, 992, 993, 994, 995, 997, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1011, 1012, 1013, 1014, 1016, 1017, 1018, 1019, 1020, 1021, 1022], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 770, 771, 773, 774, 775, 776, 780, 781, 782, 783, 784, 785, 790, 793, 794, 795, 799, 800, 801, 802, 804, 805, 809, 810, 812, 813, 814, 815, 819, 821, 822, 824, 825, 826, 827, 828, 834, 835, 836, 837, 838, 839, 840, 841, 844, 845, 846, 847, 850, 851, 852, 853, 854, 856, 858, 860, 861, 862, 863, 866, 868, 870, 871, 872, 874, 875, 876, 879, 880, 881, 882, 883, 884, 890, 891, 893, 895, 896, 897, 898, 899, 900, 902, 903, 904, 906, 907, 908, 909, 910, 911, 913, 914, 916, 917, 918, 920, 921, 922, 923, 924, 925, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 943, 944, 945, 947, 948, 951, 952, 953, 954, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 968, 970, 971, 972, 973, 975, 976, 977, 978, 979, 982, 984, 985, 986, 987, 988, 989, 991, 992, 993, 994, 995, 997, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1011, 1012, 1013, 1014, 1016, 1017, 1018, 1019, 1020, 1021, 1022], NumPruned=183296]
192246 parameters will be pruned
-------------

2023-04-04 16:49:45.457 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.30.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 6, 7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 72, 73, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.30.conv (Conv2d(48, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 6, 7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 72, 73, 76], NumPruned=2544]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 6, 7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 72, 73, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 845])>, Index=[768, 769, 770, 772, 774, 775, 778, 780, 781, 782, 783, 785, 788, 789, 790, 791, 793, 795, 796, 797, 798, 800, 801, 802, 803, 805, 806, 807, 808, 809, 812, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 831, 832, 833, 834, 836, 837, 840, 841, 844], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(845, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 769, 770, 772, 774, 775, 778, 780, 781, 782, 783, 785, 788, 789, 790, 791, 793, 795, 796, 797, 798, 800, 801, 802, 803, 805, 806, 807, 808, 809, 812, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 831, 832, 833, 834, 836, 837, 840, 841, 844], NumPruned=54272]
56922 parameters will be pruned
-------------

2023-04-04 16:49:45.459 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.31.conv (Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 69, 70, 73, 74, 75, 77, 79, 80, 83, 85, 86, 88, 92, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 114, 115, 116, 118, 119, 121, 123, 124, 126, 127, 128, 129, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 205, 206, 207, 208, 209, 212, 213, 214, 216, 217, 219, 221, 222, 223, 225, 228, 229, 233, 234, 235, 236, 237, 240, 241, 243, 246, 247, 248, 249, 250, 252, 253, 255], NumPruned=8592]
[ <DEP: prune_conv => prune_batchnorm on model.31.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 69, 70, 73, 74, 75, 77, 79, 80, 83, 85, 86, 88, 92, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 114, 115, 116, 118, 119, 121, 123, 124, 126, 127, 128, 129, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 205, 206, 207, 208, 209, 212, 213, 214, 216, 217, 219, 221, 222, 223, 225, 228, 229, 233, 234, 235, 236, 237, 240, 241, 243, 246, 247, 248, 249, 250, 252, 253, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 69, 70, 73, 74, 75, 77, 79, 80, 83, 85, 86, 88, 92, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 114, 115, 116, 118, 119, 121, 123, 124, 126, 127, 128, 129, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 205, 206, 207, 208, 209, 212, 213, 214, 216, 217, 219, 221, 222, 223, 225, 228, 229, 233, 234, 235, 236, 237, 240, 241, 243, 246, 247, 248, 249, 250, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.32.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 68, 69, 70, 73, 74, 75, 77, 79, 80, 83, 85, 86, 88, 92, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 114, 115, 116, 118, 119, 121, 123, 124, 126, 127, 128, 129, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 205, 206, 207, 208, 209, 212, 213, 214, 216, 217, 219, 221, 222, 223, 225, 228, 229, 233, 234, 235, 236, 237, 240, 241, 243, 246, 247, 248, 249, 250, 252, 253, 255], NumPruned=412416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 792])>, Index=[514, 516, 518, 520, 521, 522, 523, 524, 525, 526, 528, 529, 532, 533, 534, 535, 536, 537, 538, 540, 541, 542, 543, 546, 547, 549, 550, 552, 553, 554, 555, 556, 557, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 575, 576, 577, 580, 581, 582, 585, 586, 587, 589, 591, 592, 595, 597, 598, 600, 604, 605, 608, 610, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 626, 627, 628, 630, 631, 633, 635, 636, 638, 639, 640, 641, 647, 648, 649, 650, 651, 652, 653, 654, 656, 657, 658, 659, 660, 661, 663, 664, 666, 667, 669, 670, 671, 672, 673, 675, 676, 677, 678, 679, 680, 681, 688, 689, 690, 691, 692, 693, 694, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 713, 714, 715, 716, 717, 718, 719, 720, 721, 724, 725, 726, 728, 729, 731, 733, 734, 735, 737, 740, 741, 745, 746, 747, 748, 749, 752, 753, 755, 758, 759, 760, 761, 762, 764, 765, 767], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(792, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[514, 516, 518, 520, 521, 522, 523, 524, 525, 526, 528, 529, 532, 533, 534, 535, 536, 537, 538, 540, 541, 542, 543, 546, 547, 549, 550, 552, 553, 554, 555, 556, 557, 560, 561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 575, 576, 577, 580, 581, 582, 585, 586, 587, 589, 591, 592, 595, 597, 598, 600, 604, 605, 608, 610, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 626, 627, 628, 630, 631, 633, 635, 636, 638, 639, 640, 641, 647, 648, 649, 650, 651, 652, 653, 654, 656, 657, 658, 659, 660, 661, 663, 664, 666, 667, 669, 670, 671, 672, 673, 675, 676, 677, 678, 679, 680, 681, 688, 689, 690, 691, 692, 693, 694, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 713, 714, 715, 716, 717, 718, 719, 720, 721, 724, 725, 726, 728, 729, 731, 733, 734, 735, 737, 740, 741, 745, 746, 747, 748, 749, 752, 753, 755, 758, 759, 760, 761, 762, 764, 765, 767], NumPruned=183296]
604662 parameters will be pruned
-------------

2023-04-04 16:49:45.473 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.31.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 27, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76], NumPruned=108]
[ <DEP: prune_batchnorm => prune_conv on model.31.conv (Conv2d(48, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 27, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76], NumPruned=2592]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 27, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.32.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 27, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76], NumPruned=124416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 589, 613])>, Index=[512, 513, 514, 515, 517, 518, 520, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 536, 539, 542, 543, 544, 545, 547, 548, 550, 551, 552, 553, 554, 556, 557, 559, 560, 562, 563, 565, 566, 567, 568, 571, 572, 573, 575, 576, 577, 579, 580, 583, 584, 585, 586, 587, 588], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(613, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 513, 514, 515, 517, 518, 520, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 536, 539, 542, 543, 544, 545, 547, 548, 550, 551, 552, 553, 554, 556, 557, 559, 560, 562, 563, 565, 566, 567, 568, 571, 572, 573, 575, 576, 577, 579, 580, 583, 584, 585, 586, 587, 588], NumPruned=55296]
182412 parameters will be pruned
-------------

2023-04-04 16:49:45.475 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.32.conv (Conv2d(23, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 29, 30, 31, 32, 34, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 63, 64, 65, 67, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 88, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 142, 143, 144, 145, 147, 149, 150, 153, 155, 156, 157, 158, 159, 163, 164, 166, 167, 168, 170, 173, 174, 175, 176, 177, 179, 180, 182, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 198, 200, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 214, 215, 216, 218, 220, 222, 227, 230, 231, 232, 233, 236, 237, 238, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=37053]
[ <DEP: prune_conv => prune_batchnorm on model.32.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 29, 30, 31, 32, 34, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 63, 64, 65, 67, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 88, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 142, 143, 144, 145, 147, 149, 150, 153, 155, 156, 157, 158, 159, 163, 164, 166, 167, 168, 170, 173, 174, 175, 176, 177, 179, 180, 182, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 198, 200, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 214, 215, 216, 218, 220, 222, 227, 230, 231, 232, 233, 236, 237, 238, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 29, 30, 31, 32, 34, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 63, 64, 65, 67, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 88, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 142, 143, 144, 145, 147, 149, 150, 153, 155, 156, 157, 158, 159, 163, 164, 166, 167, 168, 170, 173, 174, 175, 176, 177, 179, 180, 182, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 198, 200, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 214, 215, 216, 218, 220, 222, 227, 230, 231, 232, 233, 236, 237, 238, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.33.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 29, 30, 31, 32, 34, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 63, 64, 65, 67, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 88, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 132, 133, 134, 138, 139, 140, 141, 142, 143, 144, 145, 147, 149, 150, 153, 155, 156, 157, 158, 159, 163, 164, 166, 167, 168, 170, 173, 174, 175, 176, 177, 179, 180, 182, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 198, 200, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 214, 215, 216, 218, 220, 222, 227, 230, 231, 232, 233, 236, 237, 238, 240, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=412416]
449827 parameters will be pruned
-------------

2023-04-04 16:49:45.487 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.32.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 31, 32, 33, 34, 35, 37, 38, 39, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 74], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.32.conv (Conv2d(23, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 31, 32, 33, 34, 35, 37, 38, 39, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 74], NumPruned=10971]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 31, 32, 33, 34, 35, 37, 38, 39, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 74], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.33.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 31, 32, 33, 34, 35, 37, 38, 39, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 74], NumPruned=122112]
133189 parameters will be pruned
-------------

2023-04-04 16:49:45.488 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.33.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 5, 6, 7, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 84, 86, 88, 89, 92, 93, 94, 97, 99, 102, 103, 104, 106, 107, 108, 110, 113, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 141, 143, 145, 146, 147, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 162, 163, 166, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 187, 188, 189, 191, 192, 193, 195, 197, 199, 200, 202, 204, 205, 206, 207, 208, 209, 210, 212, 215, 216, 218, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 237, 239, 242, 243, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.33.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 5, 6, 7, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 84, 86, 88, 89, 92, 93, 94, 97, 99, 102, 103, 104, 106, 107, 108, 110, 113, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 141, 143, 145, 146, 147, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 162, 163, 166, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 187, 188, 189, 191, 192, 193, 195, 197, 199, 200, 202, 204, 205, 206, 207, 208, 209, 210, 212, 215, 216, 218, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 237, 239, 242, 243, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 5, 6, 7, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 84, 86, 88, 89, 92, 93, 94, 97, 99, 102, 103, 104, 106, 107, 108, 110, 113, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 141, 143, 145, 146, 147, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 162, 163, 166, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 187, 188, 189, 191, 192, 193, 195, 197, 199, 200, 202, 204, 205, 206, 207, 208, 209, 210, 212, 215, 216, 218, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 237, 239, 242, 243, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.34.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 5, 6, 7, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 84, 86, 88, 89, 92, 93, 94, 97, 99, 102, 103, 104, 106, 107, 108, 110, 113, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 141, 143, 145, 146, 147, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 162, 163, 166, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 187, 188, 189, 191, 192, 193, 195, 197, 199, 200, 202, 204, 205, 206, 207, 208, 209, 210, 212, 215, 216, 218, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 236, 237, 239, 242, 243, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=412416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 535, 559])>, Index=[257, 261, 262, 263, 265, 266, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 284, 285, 287, 290, 291, 292, 293, 295, 296, 298, 299, 300, 301, 303, 304, 305, 306, 307, 308, 310, 312, 313, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 342, 344, 345, 348, 349, 350, 353, 355, 358, 359, 360, 362, 363, 364, 366, 369, 372, 373, 374, 375, 378, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 394, 395, 397, 399, 401, 402, 403, 405, 406, 407, 409, 411, 412, 413, 414, 416, 417, 418, 419, 422, 424, 425, 426, 427, 428, 429, 430, 432, 433, 434, 435, 437, 438, 439, 443, 444, 445, 447, 448, 449, 451, 453, 455, 456, 458, 460, 461, 462, 463, 464, 465, 466, 468, 471, 472, 474, 476, 478, 479, 480, 481, 483, 484, 485, 486, 487, 489, 490, 492, 493, 495, 498, 499, 502, 503, 504, 505, 506, 508, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(559, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 261, 262, 263, 265, 266, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 284, 285, 287, 290, 291, 292, 293, 295, 296, 298, 299, 300, 301, 303, 304, 305, 306, 307, 308, 310, 312, 313, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 337, 339, 340, 342, 344, 345, 348, 349, 350, 353, 355, 358, 359, 360, 362, 363, 364, 366, 369, 372, 373, 374, 375, 378, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 394, 395, 397, 399, 401, 402, 403, 405, 406, 407, 409, 411, 412, 413, 414, 416, 417, 418, 419, 422, 424, 425, 426, 427, 428, 429, 430, 432, 433, 434, 435, 437, 438, 439, 443, 444, 445, 447, 448, 449, 451, 453, 455, 456, 458, 460, 461, 462, 463, 464, 465, 466, 468, 471, 472, 474, 476, 478, 479, 480, 481, 483, 484, 485, 486, 487, 489, 490, 492, 493, 495, 498, 499, 502, 503, 504, 505, 506, 508, 509, 510, 511], NumPruned=183296]
634734 parameters will be pruned
-------------

2023-04-04 16:49:45.504 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.33.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 17, 19, 20, 21, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 57, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.33.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 17, 19, 20, 21, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 57, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 17, 19, 20, 21, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 57, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.34.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 17, 19, 20, 21, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 57, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76], NumPruned=122112]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 333, 356, 380])>, Index=[256, 258, 259, 260, 261, 262, 264, 265, 266, 268, 269, 270, 273, 275, 276, 277, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 306, 307, 313, 316, 318, 319, 320, 321, 322, 324, 325, 326, 327, 329, 330, 331, 332], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(380, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 258, 259, 260, 261, 262, 264, 265, 266, 268, 269, 270, 273, 275, 276, 277, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 303, 304, 305, 306, 307, 313, 316, 318, 319, 320, 321, 322, 324, 325, 326, 327, 329, 330, 331, 332], NumPruned=54272]
187938 parameters will be pruned
-------------

2023-04-04 16:49:45.506 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.34.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 8, 10, 11, 12, 14, 15, 17, 18, 19, 20, 23, 25, 26, 27, 28, 30, 32, 33, 38, 39, 41, 42, 43, 44, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 118, 120, 123, 124, 126, 127, 128, 129, 130, 131, 134, 135, 137, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 181, 184, 185, 186, 188, 189, 190, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 220, 221, 225, 227, 229, 230, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.34.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 8, 10, 11, 12, 14, 15, 17, 18, 19, 20, 23, 25, 26, 27, 28, 30, 32, 33, 38, 39, 41, 42, 43, 44, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 118, 120, 123, 124, 126, 127, 128, 129, 130, 131, 134, 135, 137, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 181, 184, 185, 186, 188, 189, 190, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 220, 221, 225, 227, 229, 230, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 8, 10, 11, 12, 14, 15, 17, 18, 19, 20, 23, 25, 26, 27, 28, 30, 32, 33, 38, 39, 41, 42, 43, 44, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 118, 120, 123, 124, 126, 127, 128, 129, 130, 131, 134, 135, 137, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 181, 184, 185, 186, 188, 189, 190, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 220, 221, 225, 227, 229, 230, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.35.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 8, 10, 11, 12, 14, 15, 17, 18, 19, 20, 23, 25, 26, 27, 28, 30, 32, 33, 38, 39, 41, 42, 43, 44, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 118, 120, 123, 124, 126, 127, 128, 129, 130, 131, 134, 135, 137, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 181, 184, 185, 186, 188, 189, 190, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 220, 221, 225, 227, 229, 230, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=412416]
451438 parameters will be pruned
-------------

2023-04-04 16:49:45.519 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.34.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 74, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.34.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 74, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 74, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.35.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 74, 76], NumPruned=122112]
133666 parameters will be pruned
-------------

2023-04-04 16:49:45.520 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.35.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 27, 28, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61, 63, 65, 67, 68, 69, 71, 75, 76, 77, 78, 81, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 182, 183, 184, 185, 186, 187, 191, 192, 193, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 209, 212, 213, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 235, 236, 238, 240, 242, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.35.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 27, 28, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61, 63, 65, 67, 68, 69, 71, 75, 76, 77, 78, 81, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 182, 183, 184, 185, 186, 187, 191, 192, 193, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 209, 212, 213, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 235, 236, 238, 240, 242, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 27, 28, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61, 63, 65, 67, 68, 69, 71, 75, 76, 77, 78, 81, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 182, 183, 184, 185, 186, 187, 191, 192, 193, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 209, 212, 213, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 235, 236, 238, 240, 242, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 280, 303, 327])>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 27, 28, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61, 63, 65, 67, 68, 69, 71, 75, 76, 77, 78, 81, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 182, 183, 184, 185, 186, 187, 191, 192, 193, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 209, 212, 213, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 235, 236, 238, 240, 242, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(327, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 27, 28, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61, 63, 65, 67, 68, 69, 71, 75, 76, 77, 78, 81, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 127, 128, 129, 130, 131, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 182, 183, 184, 185, 186, 187, 191, 192, 193, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 209, 212, 213, 218, 219, 220, 221, 222, 225, 227, 228, 229, 230, 232, 233, 235, 236, 238, 240, 242, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=183296]
222318 parameters will be pruned
-------------

2023-04-04 16:49:45.535 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.35.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.35.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 77, 101, 124, 148])>, Index=[2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(148, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76], NumPruned=54272]
65826 parameters will be pruned
-------------

2023-04-04 16:49:45.536 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.37.conv (Conv2d(95, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=68020]
[ <DEP: prune_conv => prune_batchnorm on model.37.bn (BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=1432]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.54.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=183296]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.40.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=366592]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.39.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 60, 63, 64, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 84, 85, 86, 87, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 116, 118, 119, 120, 121, 123, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 145, 146, 147, 150, 154, 155, 157, 159, 161, 162, 163, 164, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 186, 187, 188, 190, 192, 194, 196, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 213, 214, 216, 218, 219, 220, 221, 223, 224, 225, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 248, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 264, 266, 268, 269, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 285, 287, 289, 290, 291, 292, 295, 296, 297, 299, 301, 302, 303, 304, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 327, 328, 332, 333, 334, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 376, 378, 379, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 413, 414, 416, 417, 418, 425, 429, 430, 431, 433, 434, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 452, 453, 455, 457, 458, 459, 460, 463, 465, 466, 467, 469, 472, 474, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 517, 518, 522, 523, 524, 526, 527, 531, 533, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 558, 559, 560, 561, 562, 563, 565, 566, 568, 569, 570, 573, 574, 576, 577, 578, 579, 582, 584, 586, 587, 588, 589, 591, 592, 594, 595, 596, 598, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 613, 616, 617, 618, 621, 622, 623, 624, 625, 627, 628, 630, 632, 633, 634, 635, 638, 639, 640, 641, 642, 644, 645, 646, 647, 648, 650, 651, 653, 654, 655, 656, 659, 661, 662, 664, 665, 667, 668, 669, 670, 671, 673, 675, 676, 677, 679, 680, 681, 683, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 738, 740, 741, 742, 744, 747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 763, 764, 765, 768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 784, 785, 786, 787, 788, 789, 790, 791, 793, 795, 796, 797, 799, 800, 802, 803, 804, 805, 807, 808, 809, 811, 813, 814, 815, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 866, 867, 869, 871, 875, 877, 878, 881, 882, 883, 884, 885, 886, 888, 889, 891, 893, 894, 896, 897, 900, 901, 902, 903, 905, 906, 909, 912, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 929, 930, 932, 933, 934, 935, 936, 937, 939, 940, 941, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 959, 960, 961, 962, 963, 967, 968, 969, 970, 971, 972, 975, 976, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 998, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1010, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022], NumPruned=366592]
985932 parameters will be pruned
-------------

2023-04-04 16:49:45.553 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.37.bn (BatchNorm2d(308, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=430]
[ <DEP: prune_batchnorm => prune_conv on model.37.conv (Conv2d(95, 308, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=20425]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.54.conv (Conv2d(308, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=55040]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.40.conv (Conv2d(308, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=110080]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.39.conv (Conv2d(308, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 113, 115, 116, 121, 122, 125, 127, 128, 130, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 158, 159, 160, 161, 162, 166, 167, 169, 170, 172, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 195, 197, 198, 199, 200, 201, 204, 205, 206, 208, 209, 211, 212, 214, 215, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 235, 236, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 275, 276, 277, 279, 282, 283, 284, 285, 287, 288, 289, 290, 292, 294, 296, 298, 299, 302, 303, 305, 306], NumPruned=110080]
296055 parameters will be pruned
-------------

2023-04-04 16:49:45.567 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.39.conv (Conv2d(93, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 30, 32, 34, 35, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 66, 67, 68, 69, 71, 76, 82, 83, 85, 88, 90, 91, 93, 94, 95, 97, 98, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 120, 122, 124, 126, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 147, 148, 149, 150, 152, 153, 155, 156, 157, 159, 160, 161, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 176, 177, 179, 180, 181, 182, 185, 186, 188, 192, 195, 196, 198, 200, 201, 203, 204, 206, 208, 209, 210, 211, 213, 214, 216, 217, 218, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 231, 233, 234, 237, 238, 239, 240, 241, 244, 245, 247, 249, 251, 252, 253, 254, 256, 257, 258, 259, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 291, 292, 293, 294, 295, 297, 298, 300, 301, 303, 305, 306, 307, 308, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 332, 333, 335, 336, 339, 340, 341, 342, 343, 345, 346, 349, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 364, 365, 366, 368, 370, 371, 372, 373, 376, 377, 378, 379, 381, 384, 385, 387, 389, 391, 392, 393, 394, 395, 396, 397, 399, 401, 402, 404, 405, 407, 409, 411, 412, 413, 414, 415, 417, 420, 421, 422, 423, 424, 426, 427, 429, 430, 431, 432, 433, 434, 435, 436, 438, 440, 441, 442, 445, 446, 447, 448, 450, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 482, 484, 487, 488, 491, 494, 495, 496, 497, 498, 499, 500, 501, 503, 504, 505, 506, 507, 508, 511], NumPruned=33294]
[ <DEP: prune_conv => prune_batchnorm on model.39.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 30, 32, 34, 35, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 66, 67, 68, 69, 71, 76, 82, 83, 85, 88, 90, 91, 93, 94, 95, 97, 98, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 120, 122, 124, 126, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 147, 148, 149, 150, 152, 153, 155, 156, 157, 159, 160, 161, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 176, 177, 179, 180, 181, 182, 185, 186, 188, 192, 195, 196, 198, 200, 201, 203, 204, 206, 208, 209, 210, 211, 213, 214, 216, 217, 218, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 231, 233, 234, 237, 238, 239, 240, 241, 244, 245, 247, 249, 251, 252, 253, 254, 256, 257, 258, 259, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 291, 292, 293, 294, 295, 297, 298, 300, 301, 303, 305, 306, 307, 308, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 332, 333, 335, 336, 339, 340, 341, 342, 343, 345, 346, 349, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 364, 365, 366, 368, 370, 371, 372, 373, 376, 377, 378, 379, 381, 384, 385, 387, 389, 391, 392, 393, 394, 395, 396, 397, 399, 401, 402, 404, 405, 407, 409, 411, 412, 413, 414, 415, 417, 420, 421, 422, 423, 424, 426, 427, 429, 430, 431, 432, 433, 434, 435, 436, 438, 440, 441, 442, 445, 446, 447, 448, 450, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 482, 484, 487, 488, 491, 494, 495, 496, 497, 498, 499, 500, 501, 503, 504, 505, 506, 507, 508, 511], NumPruned=716]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 30, 32, 34, 35, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 66, 67, 68, 69, 71, 76, 82, 83, 85, 88, 90, 91, 93, 94, 95, 97, 98, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 120, 122, 124, 126, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 147, 148, 149, 150, 152, 153, 155, 156, 157, 159, 160, 161, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 176, 177, 179, 180, 181, 182, 185, 186, 188, 192, 195, 196, 198, 200, 201, 203, 204, 206, 208, 209, 210, 211, 213, 214, 216, 217, 218, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 231, 233, 234, 237, 238, 239, 240, 241, 244, 245, 247, 249, 251, 252, 253, 254, 256, 257, 258, 259, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 291, 292, 293, 294, 295, 297, 298, 300, 301, 303, 305, 306, 307, 308, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 332, 333, 335, 336, 339, 340, 341, 342, 343, 345, 346, 349, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 364, 365, 366, 368, 370, 371, 372, 373, 376, 377, 378, 379, 381, 384, 385, 387, 389, 391, 392, 393, 394, 395, 396, 397, 399, 401, 402, 404, 405, 407, 409, 411, 412, 413, 414, 415, 417, 420, 421, 422, 423, 424, 426, 427, 429, 430, 431, 432, 433, 434, 435, 436, 438, 440, 441, 442, 445, 446, 447, 448, 450, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 482, 484, 487, 488, 491, 494, 495, 496, 497, 498, 499, 500, 501, 503, 504, 505, 506, 507, 508, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 512, 1024])>, Index=[512, 514, 515, 516, 517, 518, 519, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 534, 535, 537, 538, 540, 541, 542, 544, 546, 547, 553, 554, 555, 556, 557, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 575, 576, 578, 579, 580, 581, 583, 588, 594, 595, 597, 600, 602, 603, 605, 606, 607, 609, 610, 612, 613, 614, 615, 617, 618, 619, 620, 621, 622, 625, 626, 627, 628, 629, 630, 632, 634, 636, 638, 639, 643, 644, 645, 646, 647, 648, 649, 650, 651, 654, 655, 659, 660, 661, 662, 664, 665, 667, 668, 669, 671, 672, 673, 676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 688, 689, 691, 692, 693, 694, 697, 698, 700, 704, 707, 708, 710, 712, 713, 715, 716, 718, 720, 721, 722, 723, 725, 726, 728, 729, 730, 731, 732, 733, 734, 736, 738, 739, 740, 741, 742, 743, 745, 746, 749, 750, 751, 752, 753, 756, 757, 759, 761, 763, 764, 765, 766, 768, 769, 770, 771, 774, 775, 777, 778, 779, 780, 781, 782, 783, 784, 785, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 798, 799, 800, 801, 803, 804, 805, 806, 807, 809, 810, 812, 813, 815, 817, 818, 819, 820, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 844, 845, 847, 848, 851, 852, 853, 854, 855, 857, 858, 861, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 876, 877, 878, 880, 882, 883, 884, 885, 888, 889, 890, 891, 893, 896, 897, 899, 901, 903, 904, 905, 906, 907, 908, 909, 911, 913, 914, 916, 917, 919, 921, 923, 924, 925, 926, 927, 929, 932, 933, 934, 935, 936, 938, 939, 941, 942, 943, 944, 945, 946, 947, 948, 950, 952, 953, 954, 957, 958, 959, 960, 962, 964, 966, 967, 968, 969, 970, 972, 973, 974, 975, 976, 977, 978, 981, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 994, 996, 999, 1000, 1003, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1015, 1016, 1017, 1018, 1019, 1020, 1023], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.44.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 514, 515, 516, 517, 518, 519, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 534, 535, 537, 538, 540, 541, 542, 544, 546, 547, 553, 554, 555, 556, 557, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 575, 576, 578, 579, 580, 581, 583, 588, 594, 595, 597, 600, 602, 603, 605, 606, 607, 609, 610, 612, 613, 614, 615, 617, 618, 619, 620, 621, 622, 625, 626, 627, 628, 629, 630, 632, 634, 636, 638, 639, 643, 644, 645, 646, 647, 648, 649, 650, 651, 654, 655, 659, 660, 661, 662, 664, 665, 667, 668, 669, 671, 672, 673, 676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 688, 689, 691, 692, 693, 694, 697, 698, 700, 704, 707, 708, 710, 712, 713, 715, 716, 718, 720, 721, 722, 723, 725, 726, 728, 729, 730, 731, 732, 733, 734, 736, 738, 739, 740, 741, 742, 743, 745, 746, 749, 750, 751, 752, 753, 756, 757, 759, 761, 763, 764, 765, 766, 768, 769, 770, 771, 774, 775, 777, 778, 779, 780, 781, 782, 783, 784, 785, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 798, 799, 800, 801, 803, 804, 805, 806, 807, 809, 810, 812, 813, 815, 817, 818, 819, 820, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 844, 845, 847, 848, 851, 852, 853, 854, 855, 857, 858, 861, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 876, 877, 878, 880, 882, 883, 884, 885, 888, 889, 890, 891, 893, 896, 897, 899, 901, 903, 904, 905, 906, 907, 908, 909, 911, 913, 914, 916, 917, 919, 921, 923, 924, 925, 926, 927, 929, 932, 933, 934, 935, 936, 938, 939, 941, 942, 943, 944, 945, 946, 947, 948, 950, 952, 953, 954, 957, 958, 959, 960, 962, 964, 966, 967, 968, 969, 970, 972, 973, 974, 975, 976, 977, 978, 981, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 994, 996, 999, 1000, 1003, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1015, 1016, 1017, 1018, 1019, 1020, 1023], NumPruned=91648]
[ <DEP: _prune_concat => prune_related_conv on model.43.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 514, 515, 516, 517, 518, 519, 522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 534, 535, 537, 538, 540, 541, 542, 544, 546, 547, 553, 554, 555, 556, 557, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 575, 576, 578, 579, 580, 581, 583, 588, 594, 595, 597, 600, 602, 603, 605, 606, 607, 609, 610, 612, 613, 614, 615, 617, 618, 619, 620, 621, 622, 625, 626, 627, 628, 629, 630, 632, 634, 636, 638, 639, 643, 644, 645, 646, 647, 648, 649, 650, 651, 654, 655, 659, 660, 661, 662, 664, 665, 667, 668, 669, 671, 672, 673, 676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 688, 689, 691, 692, 693, 694, 697, 698, 700, 704, 707, 708, 710, 712, 713, 715, 716, 718, 720, 721, 722, 723, 725, 726, 728, 729, 730, 731, 732, 733, 734, 736, 738, 739, 740, 741, 742, 743, 745, 746, 749, 750, 751, 752, 753, 756, 757, 759, 761, 763, 764, 765, 766, 768, 769, 770, 771, 774, 775, 777, 778, 779, 780, 781, 782, 783, 784, 785, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 798, 799, 800, 801, 803, 804, 805, 806, 807, 809, 810, 812, 813, 815, 817, 818, 819, 820, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 844, 845, 847, 848, 851, 852, 853, 854, 855, 857, 858, 861, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 876, 877, 878, 880, 882, 883, 884, 885, 888, 889, 890, 891, 893, 896, 897, 899, 901, 903, 904, 905, 906, 907, 908, 909, 911, 913, 914, 916, 917, 919, 921, 923, 924, 925, 926, 927, 929, 932, 933, 934, 935, 936, 938, 939, 941, 942, 943, 944, 945, 946, 947, 948, 950, 952, 953, 954, 957, 958, 959, 960, 962, 964, 966, 967, 968, 969, 970, 972, 973, 974, 975, 976, 977, 978, 981, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 994, 996, 999, 1000, 1003, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1015, 1016, 1017, 1018, 1019, 1020, 1023], NumPruned=91648]
217306 parameters will be pruned
-------------

2023-04-04 16:49:45.584 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.39.bn (BatchNorm2d(154, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 17, 18, 20, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 44, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 74, 75, 79, 80, 82, 84, 85, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 111, 112, 113, 115, 117, 119, 120, 121, 122, 125, 127, 129, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 152], NumPruned=214]
[ <DEP: prune_batchnorm => prune_conv on model.39.conv (Conv2d(93, 154, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 17, 18, 20, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 44, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 74, 75, 79, 80, 82, 84, 85, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 111, 112, 113, 115, 117, 119, 120, 121, 122, 125, 127, 129, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 152], NumPruned=9951]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 17, 18, 20, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 44, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 74, 75, 79, 80, 82, 84, 85, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 111, 112, 113, 115, 117, 119, 120, 121, 122, 125, 127, 129, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 152], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 512, 666])>, Index=[512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 524, 526, 527, 529, 530, 532, 535, 536, 537, 538, 541, 542, 543, 544, 545, 546, 548, 549, 550, 552, 554, 556, 557, 558, 559, 563, 564, 565, 566, 568, 569, 570, 572, 573, 574, 576, 577, 578, 579, 582, 583, 584, 586, 587, 591, 592, 594, 596, 597, 600, 601, 602, 604, 605, 606, 607, 608, 609, 611, 612, 613, 614, 616, 617, 618, 619, 620, 622, 623, 624, 625, 627, 629, 631, 632, 633, 634, 637, 639, 641, 643, 644, 645, 646, 647, 648, 650, 651, 652, 654, 655, 657, 658, 659, 660, 661, 664], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.44.conv (Conv2d(666, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 524, 526, 527, 529, 530, 532, 535, 536, 537, 538, 541, 542, 543, 544, 545, 546, 548, 549, 550, 552, 554, 556, 557, 558, 559, 563, 564, 565, 566, 568, 569, 570, 572, 573, 574, 576, 577, 578, 579, 582, 583, 584, 586, 587, 591, 592, 594, 596, 597, 600, 601, 602, 604, 605, 606, 607, 608, 609, 611, 612, 613, 614, 616, 617, 618, 619, 620, 622, 623, 624, 625, 627, 629, 631, 632, 633, 634, 637, 639, 641, 643, 644, 645, 646, 647, 648, 650, 651, 652, 654, 655, 657, 658, 659, 660, 661, 664], NumPruned=27392]
[ <DEP: _prune_concat => prune_related_conv on model.43.conv (Conv2d(666, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 524, 526, 527, 529, 530, 532, 535, 536, 537, 538, 541, 542, 543, 544, 545, 546, 548, 549, 550, 552, 554, 556, 557, 558, 559, 563, 564, 565, 566, 568, 569, 570, 572, 573, 574, 576, 577, 578, 579, 582, 583, 584, 586, 587, 591, 592, 594, 596, 597, 600, 601, 602, 604, 605, 606, 607, 608, 609, 611, 612, 613, 614, 616, 617, 618, 619, 620, 622, 623, 624, 625, 627, 629, 631, 632, 633, 634, 637, 639, 641, 643, 644, 645, 646, 647, 648, 650, 651, 652, 654, 655, 657, 658, 659, 660, 661, 664], NumPruned=27392]
64949 parameters will be pruned
-------------

2023-04-04 16:49:45.585 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.40.conv (Conv2d(93, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 23, 25, 29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 44, 45, 47, 50, 51, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 105, 106, 110, 111, 113, 114, 115, 117, 118, 121, 123, 124, 127, 128, 129, 130, 132, 133, 134, 136, 137, 140, 141, 142, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 156, 159, 161, 162, 164, 165, 166, 169, 170, 171, 172, 173, 174, 177, 179, 182, 183, 185, 186, 190, 191, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 208, 210, 211, 212, 213, 215, 216, 218, 219, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 246, 247, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 263, 266, 267, 270, 274, 275, 276, 277, 278, 280, 284, 285, 286, 287, 289, 290, 291, 292, 295, 296, 297, 298, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 315, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 363, 364, 365, 366, 368, 369, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 382, 384, 385, 387, 389, 392, 393, 394, 397, 399, 401, 402, 403, 404, 405, 406, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 423, 425, 426, 427, 428, 430, 433, 434, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 472, 474, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 492, 494, 495, 497, 499, 500, 501, 503, 504, 505, 509, 510, 511], NumPruned=33294]
[ <DEP: prune_conv => prune_batchnorm on model.40.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 23, 25, 29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 44, 45, 47, 50, 51, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 105, 106, 110, 111, 113, 114, 115, 117, 118, 121, 123, 124, 127, 128, 129, 130, 132, 133, 134, 136, 137, 140, 141, 142, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 156, 159, 161, 162, 164, 165, 166, 169, 170, 171, 172, 173, 174, 177, 179, 182, 183, 185, 186, 190, 191, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 208, 210, 211, 212, 213, 215, 216, 218, 219, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 246, 247, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 263, 266, 267, 270, 274, 275, 276, 277, 278, 280, 284, 285, 286, 287, 289, 290, 291, 292, 295, 296, 297, 298, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 315, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 363, 364, 365, 366, 368, 369, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 382, 384, 385, 387, 389, 392, 393, 394, 397, 399, 401, 402, 403, 404, 405, 406, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 423, 425, 426, 427, 428, 430, 433, 434, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 472, 474, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 492, 494, 495, 497, 499, 500, 501, 503, 504, 505, 509, 510, 511], NumPruned=716]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 23, 25, 29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 44, 45, 47, 50, 51, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 105, 106, 110, 111, 113, 114, 115, 117, 118, 121, 123, 124, 127, 128, 129, 130, 132, 133, 134, 136, 137, 140, 141, 142, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 156, 159, 161, 162, 164, 165, 166, 169, 170, 171, 172, 173, 174, 177, 179, 182, 183, 185, 186, 190, 191, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 208, 210, 211, 212, 213, 215, 216, 218, 219, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 246, 247, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 263, 266, 267, 270, 274, 275, 276, 277, 278, 280, 284, 285, 286, 287, 289, 290, 291, 292, 295, 296, 297, 298, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 315, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 363, 364, 365, 366, 368, 369, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 382, 384, 385, 387, 389, 392, 393, 394, 397, 399, 401, 402, 403, 404, 405, 406, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 423, 425, 426, 427, 428, 430, 433, 434, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 472, 474, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 492, 494, 495, 497, 499, 500, 501, 503, 504, 505, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.41.conv (Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 23, 25, 29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 44, 45, 47, 50, 51, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 97, 100, 101, 103, 105, 106, 110, 111, 113, 114, 115, 117, 118, 121, 123, 124, 127, 128, 129, 130, 132, 133, 134, 136, 137, 140, 141, 142, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 156, 159, 161, 162, 164, 165, 166, 169, 170, 171, 172, 173, 174, 177, 179, 182, 183, 185, 186, 190, 191, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 208, 210, 211, 212, 213, 215, 216, 218, 219, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 246, 247, 249, 251, 252, 253, 254, 256, 257, 258, 260, 262, 263, 266, 267, 270, 274, 275, 276, 277, 278, 280, 284, 285, 286, 287, 289, 290, 291, 292, 295, 296, 297, 298, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 315, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 363, 364, 365, 366, 368, 369, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 382, 384, 385, 387, 389, 392, 393, 394, 397, 399, 401, 402, 403, 404, 405, 406, 408, 409, 410, 411, 412, 416, 417, 418, 419, 420, 421, 423, 425, 426, 427, 428, 430, 433, 434, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 452, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 472, 474, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 492, 494, 495, 497, 499, 500, 501, 503, 504, 505, 509, 510, 511], NumPruned=1649664]
1683674 parameters will be pruned
-------------

2023-04-04 16:49:45.601 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.40.bn (BatchNorm2d(154, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 17, 19, 21, 24, 27, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 97, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 123, 125, 128, 131, 132, 135, 137, 139, 140, 142, 144, 145, 146, 147, 149, 151, 152, 153], NumPruned=216]
[ <DEP: prune_batchnorm => prune_conv on model.40.conv (Conv2d(93, 154, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 17, 19, 21, 24, 27, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 97, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 123, 125, 128, 131, 132, 135, 137, 139, 140, 142, 144, 145, 146, 147, 149, 151, 152, 153], NumPruned=10044]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 17, 19, 21, 24, 27, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 97, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 123, 125, 128, 131, 132, 135, 137, 139, 140, 142, 144, 145, 146, 147, 149, 151, 152, 153], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.41.conv (Conv2d(154, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 17, 19, 21, 24, 27, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 97, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 123, 125, 128, 131, 132, 135, 137, 139, 140, 142, 144, 145, 146, 147, 149, 151, 152, 153], NumPruned=497664]
507924 parameters will be pruned
-------------

2023-04-04 16:49:45.603 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.41.conv (Conv2d(46, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=148212]
[ <DEP: prune_conv => prune_batchnorm on model.41.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=716]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 512, 559])>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.44.conv (Conv2d(559, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=91648]
[ <DEP: _prune_concat => prune_related_conv on model.43.conv (Conv2d(559, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 6, 8, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 81, 82, 84, 85, 86, 87, 88, 89, 92, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 142, 144, 146, 147, 149, 152, 153, 154, 157, 160, 161, 162, 165, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 212, 214, 216, 218, 219, 222, 223, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 266, 267, 268, 271, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 285, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 305, 306, 307, 309, 313, 314, 316, 317, 322, 323, 324, 325, 327, 329, 330, 332, 334, 340, 341, 346, 348, 350, 352, 353, 354, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 374, 375, 378, 379, 380, 382, 386, 387, 388, 389, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 411, 414, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446, 447, 449, 450, 451, 453, 454, 456, 457, 458, 459, 460, 461, 464, 465, 466, 468, 469, 470, 472, 473, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 491, 493, 494, 496, 497, 500, 501, 503, 505, 506, 508, 509], NumPruned=91648]
332224 parameters will be pruned
-------------

2023-04-04 16:49:45.615 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.41.bn (BatchNorm2d(154, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=214]
[ <DEP: prune_batchnorm => prune_conv on model.41.conv (Conv2d(46, 154, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=44298]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 154, 201])>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.44.conv (Conv2d(201, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=27392]
[ <DEP: _prune_concat => prune_related_conv on model.43.conv (Conv2d(201, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 49, 50, 53, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 92, 93, 94, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 152, 153], NumPruned=27392]
99296 parameters will be pruned
-------------

2023-04-04 16:49:45.616 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.43.conv (Conv2d(94, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 34, 35, 36, 37, 38, 40, 43, 44, 45, 46, 47, 48, 50, 51, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 81, 82, 83, 84, 89, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 106, 107, 110, 111, 116, 121, 122, 123, 124, 126, 127, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 152, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 183, 184, 185, 186, 187, 189, 191, 193, 194, 195, 197, 198, 200, 201, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 219, 220, 221, 222, 223, 224, 227, 228, 229, 231, 232, 235, 236, 238, 239, 243, 245, 246, 247, 248, 249, 250, 251, 252, 254], NumPruned=16826]
[ <DEP: prune_conv => prune_batchnorm on model.43.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 34, 35, 36, 37, 38, 40, 43, 44, 45, 46, 47, 48, 50, 51, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 81, 82, 83, 84, 89, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 106, 107, 110, 111, 116, 121, 122, 123, 124, 126, 127, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 152, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 183, 184, 185, 186, 187, 189, 191, 193, 194, 195, 197, 198, 200, 201, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 219, 220, 221, 222, 223, 224, 227, 228, 229, 231, 232, 235, 236, 238, 239, 243, 245, 246, 247, 248, 249, 250, 251, 252, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 34, 35, 36, 37, 38, 40, 43, 44, 45, 46, 47, 48, 50, 51, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 81, 82, 83, 84, 89, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 106, 107, 110, 111, 116, 121, 122, 123, 124, 126, 127, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 152, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 183, 184, 185, 186, 187, 189, 191, 193, 194, 195, 197, 198, 200, 201, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 219, 220, 221, 222, 223, 224, 227, 228, 229, 231, 232, 235, 236, 238, 239, 243, 245, 246, 247, 248, 249, 250, 251, 252, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 1024])>, Index=[768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 797, 798, 799, 802, 803, 804, 805, 806, 808, 811, 812, 813, 814, 815, 816, 818, 819, 822, 823, 825, 826, 828, 830, 831, 832, 833, 834, 835, 836, 837, 840, 841, 842, 843, 844, 845, 846, 849, 850, 851, 852, 857, 862, 863, 864, 866, 867, 869, 870, 871, 872, 873, 874, 875, 878, 879, 884, 889, 890, 891, 892, 894, 895, 899, 900, 901, 903, 904, 905, 906, 907, 908, 909, 911, 913, 914, 915, 916, 917, 918, 920, 926, 927, 928, 929, 930, 931, 932, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 949, 951, 952, 953, 954, 955, 957, 959, 961, 962, 963, 965, 966, 968, 969, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 984, 985, 987, 988, 989, 990, 991, 992, 995, 996, 997, 999, 1000, 1003, 1004, 1006, 1007, 1011, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1022], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 769, 770, 771, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 797, 798, 799, 802, 803, 804, 805, 806, 808, 811, 812, 813, 814, 815, 816, 818, 819, 822, 823, 825, 826, 828, 830, 831, 832, 833, 834, 835, 836, 837, 840, 841, 842, 843, 844, 845, 846, 849, 850, 851, 852, 857, 862, 863, 864, 866, 867, 869, 870, 871, 872, 873, 874, 875, 878, 879, 884, 889, 890, 891, 892, 894, 895, 899, 900, 901, 903, 904, 905, 906, 907, 908, 909, 911, 913, 914, 915, 916, 917, 918, 920, 926, 927, 928, 929, 930, 931, 932, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 949, 951, 952, 953, 954, 955, 957, 959, 961, 962, 963, 965, 966, 968, 969, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 984, 985, 987, 988, 989, 990, 991, 992, 995, 996, 997, 999, 1000, 1003, 1004, 1006, 1007, 1011, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1022], NumPruned=183296]
200480 parameters will be pruned
-------------

2023-04-04 16:49:45.632 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.43.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 25, 26, 30, 31, 32, 34, 36, 38, 39, 40, 41, 43, 44, 45, 47, 48, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.43.conv (Conv2d(94, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 25, 26, 30, 31, 32, 34, 36, 38, 39, 40, 41, 43, 44, 45, 47, 48, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76], NumPruned=4982]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 25, 26, 30, 31, 32, 34, 36, 38, 39, 40, 41, 43, 44, 45, 47, 48, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 845])>, Index=[770, 771, 772, 773, 774, 776, 777, 779, 780, 781, 782, 783, 784, 786, 787, 788, 790, 793, 794, 798, 799, 800, 802, 804, 806, 807, 808, 809, 811, 812, 813, 815, 816, 821, 822, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 843, 844], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(845, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[770, 771, 772, 773, 774, 776, 777, 779, 780, 781, 782, 783, 784, 786, 787, 788, 790, 793, 794, 798, 799, 800, 802, 804, 806, 807, 808, 809, 811, 812, 813, 815, 816, 821, 822, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 843, 844], NumPruned=54272]
59360 parameters will be pruned
-------------

2023-04-04 16:49:45.636 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.44.conv (Conv2d(94, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 7, 11, 13, 14, 15, 17, 20, 21, 23, 25, 26, 28, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 55, 56, 57, 60, 61, 62, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 97, 98, 101, 102, 104, 105, 107, 108, 110, 111, 112, 115, 116, 118, 120, 121, 122, 123, 125, 126, 128, 129, 130, 131, 133, 134, 136, 137, 139, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 194, 195, 197, 198, 199, 203, 205, 206, 207, 208, 209, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 246, 247, 248, 249, 250, 251, 252, 254, 255], NumPruned=16826]
[ <DEP: prune_conv => prune_batchnorm on model.44.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 5, 7, 11, 13, 14, 15, 17, 20, 21, 23, 25, 26, 28, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 55, 56, 57, 60, 61, 62, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 97, 98, 101, 102, 104, 105, 107, 108, 110, 111, 112, 115, 116, 118, 120, 121, 122, 123, 125, 126, 128, 129, 130, 131, 133, 134, 136, 137, 139, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 194, 195, 197, 198, 199, 203, 205, 206, 207, 208, 209, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 246, 247, 248, 249, 250, 251, 252, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 5, 7, 11, 13, 14, 15, 17, 20, 21, 23, 25, 26, 28, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 55, 56, 57, 60, 61, 62, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 97, 98, 101, 102, 104, 105, 107, 108, 110, 111, 112, 115, 116, 118, 120, 121, 122, 123, 125, 126, 128, 129, 130, 131, 133, 134, 136, 137, 139, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 194, 195, 197, 198, 199, 203, 205, 206, 207, 208, 209, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 246, 247, 248, 249, 250, 251, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.45.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 7, 11, 13, 14, 15, 17, 20, 21, 23, 25, 26, 28, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 55, 56, 57, 60, 61, 62, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 95, 97, 98, 101, 102, 104, 105, 107, 108, 110, 111, 112, 115, 116, 118, 120, 121, 122, 123, 125, 126, 128, 129, 130, 131, 133, 134, 136, 137, 139, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 194, 195, 197, 198, 199, 203, 205, 206, 207, 208, 209, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 232, 233, 234, 235, 236, 238, 239, 240, 243, 244, 246, 247, 248, 249, 250, 251, 252, 254, 255], NumPruned=412416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 792])>, Index=[512, 514, 515, 517, 519, 523, 525, 526, 527, 529, 532, 533, 535, 537, 538, 540, 541, 542, 546, 547, 548, 550, 551, 552, 553, 554, 555, 556, 557, 560, 561, 563, 564, 565, 567, 568, 569, 572, 573, 574, 579, 580, 581, 583, 584, 585, 586, 587, 588, 589, 590, 592, 593, 594, 595, 596, 597, 598, 599, 600, 602, 604, 605, 607, 609, 610, 613, 614, 616, 617, 619, 620, 622, 623, 624, 627, 628, 630, 632, 633, 634, 635, 637, 638, 640, 641, 642, 643, 645, 646, 648, 649, 651, 653, 654, 655, 656, 657, 659, 660, 661, 662, 663, 665, 668, 669, 670, 671, 672, 673, 675, 676, 677, 678, 680, 683, 684, 685, 686, 687, 690, 691, 692, 693, 694, 695, 696, 697, 698, 701, 702, 703, 704, 706, 707, 709, 710, 711, 715, 717, 718, 719, 720, 721, 723, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 738, 739, 740, 741, 744, 745, 746, 747, 748, 750, 751, 752, 755, 756, 758, 759, 760, 761, 762, 763, 764, 766, 767], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(792, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 514, 515, 517, 519, 523, 525, 526, 527, 529, 532, 533, 535, 537, 538, 540, 541, 542, 546, 547, 548, 550, 551, 552, 553, 554, 555, 556, 557, 560, 561, 563, 564, 565, 567, 568, 569, 572, 573, 574, 579, 580, 581, 583, 584, 585, 586, 587, 588, 589, 590, 592, 593, 594, 595, 596, 597, 598, 599, 600, 602, 604, 605, 607, 609, 610, 613, 614, 616, 617, 619, 620, 622, 623, 624, 627, 628, 630, 632, 633, 634, 635, 637, 638, 640, 641, 642, 643, 645, 646, 648, 649, 651, 653, 654, 655, 656, 657, 659, 660, 661, 662, 663, 665, 668, 669, 670, 671, 672, 673, 675, 676, 677, 678, 680, 683, 684, 685, 686, 687, 690, 691, 692, 693, 694, 695, 696, 697, 698, 701, 702, 703, 704, 706, 707, 709, 710, 711, 715, 717, 718, 719, 720, 721, 723, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 738, 739, 740, 741, 744, 745, 746, 747, 748, 750, 751, 752, 755, 756, 758, 759, 760, 761, 762, 763, 764, 766, 767], NumPruned=183296]
612896 parameters will be pruned
-------------

2023-04-04 16:49:45.648 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.44.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 6, 8, 9, 11, 16, 18, 19, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.44.conv (Conv2d(94, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 3, 6, 8, 9, 11, 16, 18, 19, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75], NumPruned=4982]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 6, 8, 9, 11, 16, 18, 19, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.45.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 6, 8, 9, 11, 16, 18, 19, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75], NumPruned=122112]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 589, 613])>, Index=[514, 515, 518, 520, 521, 523, 528, 530, 531, 534, 535, 536, 537, 539, 540, 542, 543, 544, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 559, 560, 561, 562, 563, 566, 567, 569, 570, 572, 573, 574, 576, 577, 578, 579, 580, 581, 583, 584, 585, 586, 587], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(613, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[514, 515, 518, 520, 521, 523, 528, 530, 531, 534, 535, 536, 537, 539, 540, 542, 543, 544, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 559, 560, 561, 562, 563, 566, 567, 569, 570, 572, 573, 574, 576, 577, 578, 579, 580, 581, 583, 584, 585, 586, 587], NumPruned=54272]
181472 parameters will be pruned
-------------

2023-04-04 16:49:45.651 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.45.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 4, 5, 6, 7, 9, 10, 11, 16, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 84, 85, 87, 89, 90, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 110, 111, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 188, 189, 192, 193, 194, 195, 197, 199, 200, 201, 203, 205, 206, 208, 210, 211, 214, 215, 216, 219, 220, 222, 223, 224, 225, 226, 227, 231, 232, 233, 236, 237, 239, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.45.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 5, 6, 7, 9, 10, 11, 16, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 84, 85, 87, 89, 90, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 110, 111, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 188, 189, 192, 193, 194, 195, 197, 199, 200, 201, 203, 205, 206, 208, 210, 211, 214, 215, 216, 219, 220, 222, 223, 224, 225, 226, 227, 231, 232, 233, 236, 237, 239, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 5, 6, 7, 9, 10, 11, 16, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 84, 85, 87, 89, 90, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 110, 111, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 188, 189, 192, 193, 194, 195, 197, 199, 200, 201, 203, 205, 206, 208, 210, 211, 214, 215, 216, 219, 220, 222, 223, 224, 225, 226, 227, 231, 232, 233, 236, 237, 239, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.46.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 4, 5, 6, 7, 9, 10, 11, 16, 17, 18, 19, 20, 22, 23, 27, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 84, 85, 87, 89, 90, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 110, 111, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 188, 189, 192, 193, 194, 195, 197, 199, 200, 201, 203, 205, 206, 208, 210, 211, 214, 215, 216, 219, 220, 222, 223, 224, 225, 226, 227, 231, 232, 233, 236, 237, 239, 241, 242, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254], NumPruned=412416]
451438 parameters will be pruned
-------------

2023-04-04 16:49:45.663 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.45.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 6, 8, 10, 16, 17, 18, 21, 22, 24, 25, 26, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.45.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 6, 8, 10, 16, 17, 18, 21, 22, 24, 25, 26, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 6, 8, 10, 16, 17, 18, 21, 22, 24, 25, 26, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.46.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 6, 8, 10, 16, 17, 18, 21, 22, 24, 25, 26, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], NumPruned=122112]
133666 parameters will be pruned
-------------

2023-04-04 16:49:45.664 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.46.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 9, 12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 103, 105, 107, 108, 112, 113, 115, 116, 117, 118, 121, 123, 125, 126, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 164, 165, 166, 167, 170, 172, 173, 174, 176, 177, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 210, 211, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 235, 236, 238, 239, 240, 241, 244, 247, 248, 250, 251, 252, 253, 254, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.46.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 5, 6, 7, 9, 12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 103, 105, 107, 108, 112, 113, 115, 116, 117, 118, 121, 123, 125, 126, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 164, 165, 166, 167, 170, 172, 173, 174, 176, 177, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 210, 211, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 235, 236, 238, 239, 240, 241, 244, 247, 248, 250, 251, 252, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 6, 7, 9, 12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 103, 105, 107, 108, 112, 113, 115, 116, 117, 118, 121, 123, 125, 126, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 164, 165, 166, 167, 170, 172, 173, 174, 176, 177, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 210, 211, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 235, 236, 238, 239, 240, 241, 244, 247, 248, 250, 251, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.47.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 9, 12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 103, 105, 107, 108, 112, 113, 115, 116, 117, 118, 121, 123, 125, 126, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 164, 165, 166, 167, 170, 172, 173, 174, 176, 177, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 210, 211, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 235, 236, 238, 239, 240, 241, 244, 247, 248, 250, 251, 252, 253, 254, 255], NumPruned=412416]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 536, 560])>, Index=[256, 259, 260, 261, 262, 263, 265, 268, 270, 271, 272, 273, 275, 276, 277, 279, 280, 281, 284, 285, 286, 287, 291, 292, 293, 294, 295, 296, 297, 298, 299, 302, 303, 304, 306, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 333, 334, 335, 336, 337, 339, 340, 341, 342, 344, 345, 346, 348, 349, 350, 352, 354, 355, 356, 357, 359, 361, 363, 364, 368, 369, 371, 372, 373, 374, 377, 379, 381, 382, 384, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 399, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 416, 417, 418, 420, 421, 422, 423, 426, 428, 429, 430, 432, 433, 436, 438, 439, 440, 441, 442, 443, 444, 445, 446, 449, 450, 451, 452, 453, 454, 456, 457, 458, 459, 460, 461, 462, 463, 466, 467, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481, 482, 483, 485, 486, 487, 488, 491, 492, 494, 495, 496, 497, 500, 503, 504, 506, 507, 508, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(560, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 259, 260, 261, 262, 263, 265, 268, 270, 271, 272, 273, 275, 276, 277, 279, 280, 281, 284, 285, 286, 287, 291, 292, 293, 294, 295, 296, 297, 298, 299, 302, 303, 304, 306, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 333, 334, 335, 336, 337, 339, 340, 341, 342, 344, 345, 346, 348, 349, 350, 352, 354, 355, 356, 357, 359, 361, 363, 364, 368, 369, 371, 372, 373, 374, 377, 379, 381, 382, 384, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 399, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 416, 417, 418, 420, 421, 422, 423, 426, 428, 429, 430, 432, 433, 436, 438, 439, 440, 441, 442, 443, 444, 445, 446, 449, 450, 451, 452, 453, 454, 456, 457, 458, 459, 460, 461, 462, 463, 466, 467, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481, 482, 483, 485, 486, 487, 488, 491, 492, 494, 495, 496, 497, 500, 503, 504, 506, 507, 508, 509, 510, 511], NumPruned=183296]
634734 parameters will be pruned
-------------

2023-04-04 16:49:45.680 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.46.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.46.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.47.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76], NumPruned=122112]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 333, 357, 381])>, Index=[258, 260, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 282, 283, 284, 287, 288, 289, 290, 291, 292, 293, 296, 297, 298, 301, 302, 303, 305, 306, 307, 309, 312, 313, 314, 316, 317, 318, 320, 321, 322, 323, 324, 326, 327, 328, 330, 332], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(381, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[258, 260, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 282, 283, 284, 287, 288, 289, 290, 291, 292, 293, 296, 297, 298, 301, 302, 303, 305, 306, 307, 309, 312, 313, 314, 316, 317, 318, 320, 321, 322, 323, 324, 326, 327, 328, 330, 332], NumPruned=54272]
187938 parameters will be pruned
-------------

2023-04-04 16:49:45.681 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.47.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 32, 34, 36, 37, 38, 44, 46, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 150, 151, 152, 153, 154, 155, 156, 160, 161, 162, 163, 164, 166, 167, 170, 171, 172, 180, 181, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 207, 208, 210, 211, 213, 214, 217, 219, 220, 221, 222, 223, 224, 225, 226, 228, 231, 232, 233, 236, 237, 238, 240, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.47.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 32, 34, 36, 37, 38, 44, 46, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 150, 151, 152, 153, 154, 155, 156, 160, 161, 162, 163, 164, 166, 167, 170, 171, 172, 180, 181, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 207, 208, 210, 211, 213, 214, 217, 219, 220, 221, 222, 223, 224, 225, 226, 228, 231, 232, 233, 236, 237, 238, 240, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 32, 34, 36, 37, 38, 44, 46, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 150, 151, 152, 153, 154, 155, 156, 160, 161, 162, 163, 164, 166, 167, 170, 171, 172, 180, 181, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 207, 208, 210, 211, 213, 214, 217, 219, 220, 221, 222, 223, 224, 225, 226, 228, 231, 232, 233, 236, 237, 238, 240, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.48.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 32, 34, 36, 37, 38, 44, 46, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 150, 151, 152, 153, 154, 155, 156, 160, 161, 162, 163, 164, 166, 167, 170, 171, 172, 180, 181, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 207, 208, 210, 211, 213, 214, 217, 219, 220, 221, 222, 223, 224, 225, 226, 228, 231, 232, 233, 236, 237, 238, 240, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255], NumPruned=412416]
451438 parameters will be pruned
-------------

2023-04-04 16:49:45.695 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.47.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44, 45, 47, 51, 52, 53, 56, 58, 59, 60, 62, 65, 66, 67, 68, 69, 73, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.47.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44, 45, 47, 51, 52, 53, 56, 58, 59, 60, 62, 65, 66, 67, 68, 69, 73, 75, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44, 45, 47, 51, 52, 53, 56, 58, 59, 60, 62, 65, 66, 67, 68, 69, 73, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.48.conv (Conv2d(77, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44, 45, 47, 51, 52, 53, 56, 58, 59, 60, 62, 65, 66, 67, 68, 69, 73, 75, 76], NumPruned=122112]
133666 parameters will be pruned
-------------

2023-04-04 16:49:45.696 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.48.conv (Conv2d(24, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 75, 77, 82, 83, 84, 85, 86, 89, 91, 92, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 137, 138, 139, 140, 143, 145, 146, 148, 149, 150, 151, 152, 155, 157, 158, 160, 161, 163, 164, 165, 167, 170, 171, 172, 173, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255], NumPruned=38664]
[ <DEP: prune_conv => prune_batchnorm on model.48.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 75, 77, 82, 83, 84, 85, 86, 89, 91, 92, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 137, 138, 139, 140, 143, 145, 146, 148, 149, 150, 151, 152, 155, 157, 158, 160, 161, 163, 164, 165, 167, 170, 171, 172, 173, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 75, 77, 82, 83, 84, 85, 86, 89, 91, 92, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 137, 138, 139, 140, 143, 145, 146, 148, 149, 150, 151, 152, 155, 157, 158, 160, 161, 163, 164, 165, 167, 170, 171, 172, 173, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 280, 304, 328])>, Index=[1, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 75, 77, 82, 83, 84, 85, 86, 89, 91, 92, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 137, 138, 139, 140, 143, 145, 146, 148, 149, 150, 151, 152, 155, 157, 158, 160, 161, 163, 164, 165, 167, 170, 171, 172, 173, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(328, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 75, 77, 82, 83, 84, 85, 86, 89, 91, 92, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 137, 138, 139, 140, 143, 145, 146, 148, 149, 150, 151, 152, 155, 157, 158, 160, 161, 163, 164, 165, 167, 170, 171, 172, 173, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 201, 202, 204, 205, 206, 207, 208, 210, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 243, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255], NumPruned=183296]
222318 parameters will be pruned
-------------

2023-04-04 16:49:45.711 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.48.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 6, 7, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 69, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.48.conv (Conv2d(24, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 6, 7, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 69, 74, 75, 76], NumPruned=11448]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 6, 7, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 69, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 77, 101, 125, 149])>, Index=[1, 4, 6, 7, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 69, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(149, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 4, 6, 7, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 69, 74, 75, 76], NumPruned=54272]
65826 parameters will be pruned
-------------

2023-04-04 16:49:45.712 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.50.conv (Conv2d(96, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 53, 56, 57, 59, 60, 62, 64, 65, 67, 69, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 94, 95, 96, 98, 99, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 132, 133, 134, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 178, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 203, 204, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 254, 255, 256, 257, 259, 260, 263, 264, 267, 268, 271, 272, 273, 274, 276, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 340, 342, 343, 344, 345, 346, 349, 350, 351, 353, 355, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 370, 372, 373, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 405, 408, 409, 411, 412, 413, 415, 417, 419, 420, 423, 424, 425, 426, 427, 428, 430, 431, 434, 435, 436, 440, 442, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 470, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 487, 488, 489, 492, 496, 497, 498, 499, 501, 503, 506, 507, 508, 511, 512, 513, 514, 515, 517, 519, 520, 521, 523, 524, 526, 528, 529, 531, 532, 533, 534, 535, 536, 537, 539, 540, 542, 545, 547, 550, 551, 553, 554, 555, 558, 559, 561, 563, 564, 565, 566, 567, 568, 570, 571, 573, 574, 575, 576, 577, 579, 580, 582, 583, 586, 587, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 609, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 639, 640, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 665, 666, 667, 668, 672, 673, 674, 675, 676, 677, 678, 679, 680, 684, 685, 689, 691, 692, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 707, 709, 711, 712, 713, 714, 715, 716, 717, 719, 720, 722, 726, 727, 728, 729, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 743, 744, 745, 747, 748, 751, 752, 753, 754, 756, 757, 759, 760, 764, 765, 766, 767, 768, 770, 771, 773, 774, 777, 778, 779, 781, 782, 783, 784, 786, 787, 789, 790, 791, 792, 793, 795, 797, 798, 799, 801, 803, 805, 806, 807, 809, 810, 811, 812, 813, 814, 816, 817, 819, 824, 825, 826, 827, 828, 829, 830, 832, 833, 834, 837, 838, 839, 840, 842, 843, 846, 849, 851, 853, 854, 855, 856, 857, 858, 859, 861, 862, 863, 864, 865, 867, 868, 870, 872, 875, 876, 877, 878, 879, 881, 882, 883, 885, 886, 887, 888, 890, 891, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 912, 913, 914, 916, 920, 922, 925, 926, 927, 929, 931, 933, 934, 935, 938, 939, 940, 942, 943, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 956, 957, 958, 959, 964, 966, 967, 970, 971, 972, 973, 975, 977, 979, 982, 984, 985, 989, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1020, 1021, 1022, 1023], NumPruned=68736]
[ <DEP: prune_conv => prune_batchnorm on model.50.bn (BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 53, 56, 57, 59, 60, 62, 64, 65, 67, 69, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 94, 95, 96, 98, 99, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 132, 133, 134, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 178, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 203, 204, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 254, 255, 256, 257, 259, 260, 263, 264, 267, 268, 271, 272, 273, 274, 276, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 340, 342, 343, 344, 345, 346, 349, 350, 351, 353, 355, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 370, 372, 373, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 405, 408, 409, 411, 412, 413, 415, 417, 419, 420, 423, 424, 425, 426, 427, 428, 430, 431, 434, 435, 436, 440, 442, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 470, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 487, 488, 489, 492, 496, 497, 498, 499, 501, 503, 506, 507, 508, 511, 512, 513, 514, 515, 517, 519, 520, 521, 523, 524, 526, 528, 529, 531, 532, 533, 534, 535, 536, 537, 539, 540, 542, 545, 547, 550, 551, 553, 554, 555, 558, 559, 561, 563, 564, 565, 566, 567, 568, 570, 571, 573, 574, 575, 576, 577, 579, 580, 582, 583, 586, 587, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 609, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 639, 640, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 665, 666, 667, 668, 672, 673, 674, 675, 676, 677, 678, 679, 680, 684, 685, 689, 691, 692, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 707, 709, 711, 712, 713, 714, 715, 716, 717, 719, 720, 722, 726, 727, 728, 729, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 743, 744, 745, 747, 748, 751, 752, 753, 754, 756, 757, 759, 760, 764, 765, 766, 767, 768, 770, 771, 773, 774, 777, 778, 779, 781, 782, 783, 784, 786, 787, 789, 790, 791, 792, 793, 795, 797, 798, 799, 801, 803, 805, 806, 807, 809, 810, 811, 812, 813, 814, 816, 817, 819, 824, 825, 826, 827, 828, 829, 830, 832, 833, 834, 837, 838, 839, 840, 842, 843, 846, 849, 851, 853, 854, 855, 856, 857, 858, 859, 861, 862, 863, 864, 865, 867, 868, 870, 872, 875, 876, 877, 878, 879, 881, 882, 883, 885, 886, 887, 888, 890, 891, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 912, 913, 914, 916, 920, 922, 925, 926, 927, 929, 931, 933, 934, 935, 938, 939, 940, 942, 943, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 956, 957, 958, 959, 964, 966, 967, 970, 971, 972, 973, 975, 977, 979, 982, 984, 985, 989, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1020, 1021, 1022, 1023], NumPruned=1432]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 53, 56, 57, 59, 60, 62, 64, 65, 67, 69, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 94, 95, 96, 98, 99, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 132, 133, 134, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 178, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 203, 204, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 254, 255, 256, 257, 259, 260, 263, 264, 267, 268, 271, 272, 273, 274, 276, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 340, 342, 343, 344, 345, 346, 349, 350, 351, 353, 355, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 370, 372, 373, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 405, 408, 409, 411, 412, 413, 415, 417, 419, 420, 423, 424, 425, 426, 427, 428, 430, 431, 434, 435, 436, 440, 442, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 470, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 487, 488, 489, 492, 496, 497, 498, 499, 501, 503, 506, 507, 508, 511, 512, 513, 514, 515, 517, 519, 520, 521, 523, 524, 526, 528, 529, 531, 532, 533, 534, 535, 536, 537, 539, 540, 542, 545, 547, 550, 551, 553, 554, 555, 558, 559, 561, 563, 564, 565, 566, 567, 568, 570, 571, 573, 574, 575, 576, 577, 579, 580, 582, 583, 586, 587, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 609, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 639, 640, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 665, 666, 667, 668, 672, 673, 674, 675, 676, 677, 678, 679, 680, 684, 685, 689, 691, 692, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 707, 709, 711, 712, 713, 714, 715, 716, 717, 719, 720, 722, 726, 727, 728, 729, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 743, 744, 745, 747, 748, 751, 752, 753, 754, 756, 757, 759, 760, 764, 765, 766, 767, 768, 770, 771, 773, 774, 777, 778, 779, 781, 782, 783, 784, 786, 787, 789, 790, 791, 792, 793, 795, 797, 798, 799, 801, 803, 805, 806, 807, 809, 810, 811, 812, 813, 814, 816, 817, 819, 824, 825, 826, 827, 828, 829, 830, 832, 833, 834, 837, 838, 839, 840, 842, 843, 846, 849, 851, 853, 854, 855, 856, 857, 858, 859, 861, 862, 863, 864, 865, 867, 868, 870, 872, 875, 876, 877, 878, 879, 881, 882, 883, 885, 886, 887, 888, 890, 891, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 912, 913, 914, 916, 920, 922, 925, 926, 927, 929, 931, 933, 934, 935, 938, 939, 940, 942, 943, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 956, 957, 958, 959, 964, 966, 967, 970, 971, 972, 973, 975, 977, 979, 982, 984, 985, 989, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1020, 1021, 1022, 1023], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.51.cv1.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 53, 56, 57, 59, 60, 62, 64, 65, 67, 69, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 94, 95, 96, 98, 99, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 132, 133, 134, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 178, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 203, 204, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 254, 255, 256, 257, 259, 260, 263, 264, 267, 268, 271, 272, 273, 274, 276, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 340, 342, 343, 344, 345, 346, 349, 350, 351, 353, 355, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 370, 372, 373, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 405, 408, 409, 411, 412, 413, 415, 417, 419, 420, 423, 424, 425, 426, 427, 428, 430, 431, 434, 435, 436, 440, 442, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 470, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 487, 488, 489, 492, 496, 497, 498, 499, 501, 503, 506, 507, 508, 511, 512, 513, 514, 515, 517, 519, 520, 521, 523, 524, 526, 528, 529, 531, 532, 533, 534, 535, 536, 537, 539, 540, 542, 545, 547, 550, 551, 553, 554, 555, 558, 559, 561, 563, 564, 565, 566, 567, 568, 570, 571, 573, 574, 575, 576, 577, 579, 580, 582, 583, 586, 587, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 609, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 639, 640, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 665, 666, 667, 668, 672, 673, 674, 675, 676, 677, 678, 679, 680, 684, 685, 689, 691, 692, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 707, 709, 711, 712, 713, 714, 715, 716, 717, 719, 720, 722, 726, 727, 728, 729, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 743, 744, 745, 747, 748, 751, 752, 753, 754, 756, 757, 759, 760, 764, 765, 766, 767, 768, 770, 771, 773, 774, 777, 778, 779, 781, 782, 783, 784, 786, 787, 789, 790, 791, 792, 793, 795, 797, 798, 799, 801, 803, 805, 806, 807, 809, 810, 811, 812, 813, 814, 816, 817, 819, 824, 825, 826, 827, 828, 829, 830, 832, 833, 834, 837, 838, 839, 840, 842, 843, 846, 849, 851, 853, 854, 855, 856, 857, 858, 859, 861, 862, 863, 864, 865, 867, 868, 870, 872, 875, 876, 877, 878, 879, 881, 882, 883, 885, 886, 887, 888, 890, 891, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 912, 913, 914, 916, 920, 922, 925, 926, 927, 929, 931, 933, 934, 935, 938, 939, 940, 942, 943, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 956, 957, 958, 959, 964, 966, 967, 970, 971, 972, 973, 975, 977, 979, 982, 984, 985, 989, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1020, 1021, 1022, 1023], NumPruned=366592]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.51.cv2.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 53, 56, 57, 59, 60, 62, 64, 65, 67, 69, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 94, 95, 96, 98, 99, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 132, 133, 134, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 178, 180, 181, 182, 183, 184, 185, 187, 188, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 203, 204, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 254, 255, 256, 257, 259, 260, 263, 264, 267, 268, 271, 272, 273, 274, 276, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 338, 339, 340, 342, 343, 344, 345, 346, 349, 350, 351, 353, 355, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 370, 372, 373, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 405, 408, 409, 411, 412, 413, 415, 417, 419, 420, 423, 424, 425, 426, 427, 428, 430, 431, 434, 435, 436, 440, 442, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 470, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 487, 488, 489, 492, 496, 497, 498, 499, 501, 503, 506, 507, 508, 511, 512, 513, 514, 515, 517, 519, 520, 521, 523, 524, 526, 528, 529, 531, 532, 533, 534, 535, 536, 537, 539, 540, 542, 545, 547, 550, 551, 553, 554, 555, 558, 559, 561, 563, 564, 565, 566, 567, 568, 570, 571, 573, 574, 575, 576, 577, 579, 580, 582, 583, 586, 587, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 609, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 635, 636, 639, 640, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 665, 666, 667, 668, 672, 673, 674, 675, 676, 677, 678, 679, 680, 684, 685, 689, 691, 692, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 706, 707, 709, 711, 712, 713, 714, 715, 716, 717, 719, 720, 722, 726, 727, 728, 729, 731, 732, 734, 735, 736, 737, 738, 739, 740, 741, 743, 744, 745, 747, 748, 751, 752, 753, 754, 756, 757, 759, 760, 764, 765, 766, 767, 768, 770, 771, 773, 774, 777, 778, 779, 781, 782, 783, 784, 786, 787, 789, 790, 791, 792, 793, 795, 797, 798, 799, 801, 803, 805, 806, 807, 809, 810, 811, 812, 813, 814, 816, 817, 819, 824, 825, 826, 827, 828, 829, 830, 832, 833, 834, 837, 838, 839, 840, 842, 843, 846, 849, 851, 853, 854, 855, 856, 857, 858, 859, 861, 862, 863, 864, 865, 867, 868, 870, 872, 875, 876, 877, 878, 879, 881, 882, 883, 885, 886, 887, 888, 890, 891, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 912, 913, 914, 916, 920, 922, 925, 926, 927, 929, 931, 933, 934, 935, 938, 939, 940, 942, 943, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 956, 957, 958, 959, 964, 966, 967, 970, 971, 972, 973, 975, 977, 979, 982, 984, 985, 989, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1020, 1021, 1022, 1023], NumPruned=366592]
803352 parameters will be pruned
-------------

2023-04-04 16:49:45.728 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.50.bn (BatchNorm2d(308, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 95, 97, 98, 99, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 130, 131, 134, 135, 136, 137, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 171, 172, 175, 177, 178, 179, 180, 183, 184, 185, 187, 188, 189, 191, 193, 196, 197, 198, 200, 203, 210, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 225, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 255, 256, 258, 260, 261, 262, 263, 265, 266, 267, 268, 270, 271, 273, 274, 278, 279, 280, 281, 283, 284, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 299, 300, 301, 302, 303, 304, 307], NumPruned=430]
[ <DEP: prune_batchnorm => prune_conv on model.50.conv (Conv2d(96, 308, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 95, 97, 98, 99, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 130, 131, 134, 135, 136, 137, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 171, 172, 175, 177, 178, 179, 180, 183, 184, 185, 187, 188, 189, 191, 193, 196, 197, 198, 200, 203, 210, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 225, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 255, 256, 258, 260, 261, 262, 263, 265, 266, 267, 268, 270, 271, 273, 274, 278, 279, 280, 281, 283, 284, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 299, 300, 301, 302, 303, 304, 307], NumPruned=20640]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 95, 97, 98, 99, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 130, 131, 134, 135, 136, 137, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 171, 172, 175, 177, 178, 179, 180, 183, 184, 185, 187, 188, 189, 191, 193, 196, 197, 198, 200, 203, 210, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 225, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 255, 256, 258, 260, 261, 262, 263, 265, 266, 267, 268, 270, 271, 273, 274, 278, 279, 280, 281, 283, 284, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 299, 300, 301, 302, 303, 304, 307], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.51.cv1.conv (Conv2d(308, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 95, 97, 98, 99, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 130, 131, 134, 135, 136, 137, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 171, 172, 175, 177, 178, 179, 180, 183, 184, 185, 187, 188, 189, 191, 193, 196, 197, 198, 200, 203, 210, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 225, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 255, 256, 258, 260, 261, 262, 263, 265, 266, 267, 268, 270, 271, 273, 274, 278, 279, 280, 281, 283, 284, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 299, 300, 301, 302, 303, 304, 307], NumPruned=110080]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.51.cv2.conv (Conv2d(308, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 95, 97, 98, 99, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 130, 131, 134, 135, 136, 137, 139, 140, 141, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 171, 172, 175, 177, 178, 179, 180, 183, 184, 185, 187, 188, 189, 191, 193, 196, 197, 198, 200, 203, 210, 212, 213, 215, 216, 218, 219, 220, 221, 222, 223, 225, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 255, 256, 258, 260, 261, 262, 263, 265, 266, 267, 268, 270, 271, 273, 274, 278, 279, 280, 281, 283, 284, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 299, 300, 301, 302, 303, 304, 307], NumPruned=110080]
241230 parameters will be pruned
-------------

2023-04-04 16:49:45.743 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.52.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 29, 32, 33, 34, 36, 39, 41, 42, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 84, 88, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 108, 109, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 136, 138, 139, 140, 141, 143, 145, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 175, 176, 177, 178, 179, 180, 181, 182, 183, 187, 188, 189, 190, 192, 194, 195, 197, 198, 199, 201, 202, 203, 205, 206, 207, 208, 209, 211, 212, 213, 218, 219, 220, 221, 222, 223, 224, 225, 227, 229, 232, 233, 234, 236, 237, 240, 242, 243, 244, 245, 246, 247, 249, 251, 253, 254, 255], NumPruned=91648]
[ <DEP: prune_conv => prune_batchnorm on model.52.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 29, 32, 33, 34, 36, 39, 41, 42, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 84, 88, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 108, 109, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 136, 138, 139, 140, 141, 143, 145, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 175, 176, 177, 178, 179, 180, 181, 182, 183, 187, 188, 189, 190, 192, 194, 195, 197, 198, 199, 201, 202, 203, 205, 206, 207, 208, 209, 211, 212, 213, 218, 219, 220, 221, 222, 223, 224, 225, 227, 229, 232, 233, 234, 236, 237, 240, 242, 243, 244, 245, 246, 247, 249, 251, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 29, 32, 33, 34, 36, 39, 41, 42, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 84, 88, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 108, 109, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 136, 138, 139, 140, 141, 143, 145, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 175, 176, 177, 178, 179, 180, 181, 182, 183, 187, 188, 189, 190, 192, 194, 195, 197, 198, 199, 201, 202, 203, 205, 206, 207, 208, 209, 211, 212, 213, 218, 219, 220, 221, 222, 223, 224, 225, 227, 229, 232, 233, 234, 236, 237, 240, 242, 243, 244, 245, 246, 247, 249, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 29, 32, 33, 34, 36, 39, 41, 42, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 84, 88, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 108, 109, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 136, 138, 139, 140, 141, 143, 145, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 175, 176, 177, 178, 179, 180, 181, 182, 183, 187, 188, 189, 190, 192, 194, 195, 197, 198, 199, 201, 202, 203, 205, 206, 207, 208, 209, 211, 212, 213, 218, 219, 220, 221, 222, 223, 224, 225, 227, 229, 232, 233, 234, 236, 237, 240, 242, 243, 244, 245, 246, 247, 249, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512])>, Index=[256, 257, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 278, 279, 280, 281, 283, 285, 288, 289, 290, 292, 295, 297, 298, 300, 301, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 337, 340, 344, 347, 348, 349, 350, 351, 352, 353, 354, 359, 360, 361, 364, 365, 367, 368, 369, 371, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388, 389, 390, 392, 394, 395, 396, 397, 399, 401, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 417, 418, 419, 421, 422, 423, 424, 425, 426, 431, 432, 433, 434, 435, 436, 437, 438, 439, 443, 444, 445, 446, 448, 450, 451, 453, 454, 455, 457, 458, 459, 461, 462, 463, 464, 465, 467, 468, 469, 474, 475, 476, 477, 478, 479, 480, 481, 483, 485, 488, 489, 490, 492, 493, 496, 498, 499, 500, 501, 502, 503, 505, 507, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.57.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 278, 279, 280, 281, 283, 285, 288, 289, 290, 292, 295, 297, 298, 300, 301, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 337, 340, 344, 347, 348, 349, 350, 351, 352, 353, 354, 359, 360, 361, 364, 365, 367, 368, 369, 371, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388, 389, 390, 392, 394, 395, 396, 397, 399, 401, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 417, 418, 419, 421, 422, 423, 424, 425, 426, 431, 432, 433, 434, 435, 436, 437, 438, 439, 443, 444, 445, 446, 448, 450, 451, 453, 454, 455, 457, 458, 459, 461, 462, 463, 464, 465, 467, 468, 469, 474, 475, 476, 477, 478, 479, 480, 481, 483, 485, 488, 489, 490, 492, 493, 496, 498, 499, 500, 501, 502, 503, 505, 507, 509, 510, 511], NumPruned=45824]
[ <DEP: _prune_concat => prune_related_conv on model.56.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 278, 279, 280, 281, 283, 285, 288, 289, 290, 292, 295, 297, 298, 300, 301, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 337, 340, 344, 347, 348, 349, 350, 351, 352, 353, 354, 359, 360, 361, 364, 365, 367, 368, 369, 371, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388, 389, 390, 392, 394, 395, 396, 397, 399, 401, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 417, 418, 419, 421, 422, 423, 424, 425, 426, 431, 432, 433, 434, 435, 436, 437, 438, 439, 443, 444, 445, 446, 448, 450, 451, 453, 454, 455, 457, 458, 459, 461, 462, 463, 464, 465, 467, 468, 469, 474, 475, 476, 477, 478, 479, 480, 481, 483, 485, 488, 489, 490, 492, 493, 496, 498, 499, 500, 501, 502, 503, 505, 507, 509, 510, 511], NumPruned=45824]
183654 parameters will be pruned
-------------

2023-04-04 16:49:45.759 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.52.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 21, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.52.conv (Conv2d(512, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 21, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 76], NumPruned=27136]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 21, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 21, 23, 25, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 333])>, Index=[256, 257, 258, 259, 261, 264, 265, 266, 267, 268, 269, 271, 272, 274, 275, 277, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 295, 296, 297, 298, 299, 300, 302, 304, 305, 306, 307, 308, 309, 312, 313, 314, 316, 317, 318, 321, 322, 323, 324, 326, 327, 328, 332], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.57.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 261, 264, 265, 266, 267, 268, 269, 271, 272, 274, 275, 277, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 295, 296, 297, 298, 299, 300, 302, 304, 305, 306, 307, 308, 309, 312, 313, 314, 316, 317, 318, 321, 322, 323, 324, 326, 327, 328, 332], NumPruned=13568]
[ <DEP: _prune_concat => prune_related_conv on model.56.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 259, 261, 264, 265, 266, 267, 268, 269, 271, 272, 274, 275, 277, 279, 281, 283, 284, 285, 286, 287, 288, 291, 292, 295, 296, 297, 298, 299, 300, 302, 304, 305, 306, 307, 308, 309, 312, 313, 314, 316, 317, 318, 321, 322, 323, 324, 326, 327, 328, 332], NumPruned=13568]
54378 parameters will be pruned
-------------

2023-04-04 16:49:45.761 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.54.conv (Conv2d(93, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=16647]
[ <DEP: prune_conv => prune_batchnorm on model.54.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 280])>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.57.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=45824]
[ <DEP: _prune_concat => prune_related_conv on model.56.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 131, 132, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 169, 173, 174, 176, 177, 179, 180, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 243, 245, 246, 248, 250, 251, 252, 253, 255], NumPruned=45824]
108653 parameters will be pruned
-------------

2023-04-04 16:49:45.775 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.54.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.54.conv (Conv2d(93, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=4929]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 77, 101])>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.57.conv (Conv2d(101, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=13568]
[ <DEP: _prune_concat => prune_related_conv on model.56.conv (Conv2d(101, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 46, 48, 49, 51, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 68, 70, 72, 73, 74, 75, 76], NumPruned=13568]
32171 parameters will be pruned
-------------

2023-04-04 16:49:45.776 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.56.conv (Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 34, 37, 38, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 67, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 92, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 128, 130, 131, 132, 133, 136, 138, 140, 141, 143, 145, 147, 148, 149, 151, 152, 154, 155, 156, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 176, 177, 178, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 208, 209, 210, 211, 213, 214, 215, 216, 217, 219, 220, 221, 223, 225, 226, 228, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 252, 253, 254], NumPruned=8592]
[ <DEP: prune_conv => prune_batchnorm on model.56.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 34, 37, 38, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 67, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 92, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 128, 130, 131, 132, 133, 136, 138, 140, 141, 143, 145, 147, 148, 149, 151, 152, 154, 155, 156, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 176, 177, 178, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 208, 209, 210, 211, 213, 214, 215, 216, 217, 219, 220, 221, 223, 225, 226, 228, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 252, 253, 254], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 5, 6, 7, 8, 9, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 34, 37, 38, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 67, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 92, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 128, 130, 131, 132, 133, 136, 138, 140, 141, 143, 145, 147, 148, 149, 151, 152, 154, 155, 156, 159, 160, 161, 162, 163, 164, 166, 167, 168, 170, 171, 172, 173, 174, 176, 177, 178, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 208, 209, 210, 211, 213, 214, 215, 216, 217, 219, 220, 221, 223, 225, 226, 228, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 252, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 1024])>, Index=[768, 769, 771, 773, 774, 775, 776, 777, 781, 782, 783, 785, 786, 788, 789, 791, 792, 793, 794, 795, 796, 797, 799, 802, 805, 806, 808, 809, 810, 812, 813, 815, 816, 818, 820, 821, 822, 823, 824, 825, 826, 829, 830, 831, 832, 835, 837, 838, 839, 843, 844, 845, 846, 847, 848, 849, 850, 852, 855, 856, 857, 860, 863, 864, 865, 866, 868, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 881, 882, 883, 884, 885, 889, 890, 891, 892, 893, 894, 896, 898, 899, 900, 901, 904, 906, 908, 909, 911, 913, 915, 916, 917, 919, 920, 922, 923, 924, 927, 928, 929, 930, 931, 932, 934, 935, 936, 938, 939, 940, 941, 942, 944, 945, 946, 949, 950, 951, 952, 953, 955, 956, 957, 959, 960, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 976, 977, 978, 979, 981, 982, 983, 984, 985, 987, 988, 989, 991, 993, 994, 996, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1017, 1020, 1021, 1022], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 769, 771, 773, 774, 775, 776, 777, 781, 782, 783, 785, 786, 788, 789, 791, 792, 793, 794, 795, 796, 797, 799, 802, 805, 806, 808, 809, 810, 812, 813, 815, 816, 818, 820, 821, 822, 823, 824, 825, 826, 829, 830, 831, 832, 835, 837, 838, 839, 843, 844, 845, 846, 847, 848, 849, 850, 852, 855, 856, 857, 860, 863, 864, 865, 866, 868, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 881, 882, 883, 884, 885, 889, 890, 891, 892, 893, 894, 896, 898, 899, 900, 901, 904, 906, 908, 909, 911, 913, 915, 916, 917, 919, 920, 922, 923, 924, 927, 928, 929, 930, 931, 932, 934, 935, 936, 938, 939, 940, 941, 942, 944, 945, 946, 949, 950, 951, 952, 953, 955, 956, 957, 959, 960, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 976, 977, 978, 979, 981, 982, 983, 984, 985, 987, 988, 989, 991, 993, 994, 996, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1017, 1020, 1021, 1022], NumPruned=45824]
54774 parameters will be pruned
-------------

2023-04-04 16:49:45.792 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.56.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 5, 7, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 47, 48, 49, 51, 53, 54, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.56.conv (Conv2d(48, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 5, 7, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 47, 48, 49, 51, 53, 54, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=2544]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 5, 7, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 47, 48, 49, 51, 53, 54, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 845])>, Index=[769, 771, 773, 775, 777, 778, 779, 780, 782, 783, 786, 787, 788, 789, 791, 792, 793, 794, 797, 798, 799, 800, 801, 802, 803, 804, 807, 808, 809, 811, 812, 815, 816, 817, 819, 821, 822, 824, 826, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(845, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[769, 771, 773, 775, 777, 778, 779, 780, 782, 783, 786, 787, 788, 789, 791, 792, 793, 794, 797, 798, 799, 800, 801, 802, 803, 804, 807, 808, 809, 811, 812, 815, 816, 817, 819, 821, 822, 824, 826, 830, 831, 832, 833, 834, 835, 836, 837, 839, 840, 841, 842, 843, 844], NumPruned=13568]
16218 parameters will be pruned
-------------

2023-04-04 16:49:45.794 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.57.conv (Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 50, 51, 52, 54, 55, 58, 59, 62, 64, 66, 67, 68, 69, 71, 73, 77, 78, 80, 81, 82, 86, 87, 88, 89, 90, 92, 93, 94, 95, 98, 99, 102, 103, 105, 107, 108, 109, 111, 112, 113, 114, 117, 118, 119, 121, 122, 123, 124, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 143, 144, 145, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 171, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 216, 218, 219, 220, 221, 222, 226, 227, 228, 230, 231, 232, 234, 235, 236, 237, 239, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=8592]
[ <DEP: prune_conv => prune_batchnorm on model.57.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 50, 51, 52, 54, 55, 58, 59, 62, 64, 66, 67, 68, 69, 71, 73, 77, 78, 80, 81, 82, 86, 87, 88, 89, 90, 92, 93, 94, 95, 98, 99, 102, 103, 105, 107, 108, 109, 111, 112, 113, 114, 117, 118, 119, 121, 122, 123, 124, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 143, 144, 145, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 171, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 216, 218, 219, 220, 221, 222, 226, 227, 228, 230, 231, 232, 234, 235, 236, 237, 239, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 50, 51, 52, 54, 55, 58, 59, 62, 64, 66, 67, 68, 69, 71, 73, 77, 78, 80, 81, 82, 86, 87, 88, 89, 90, 92, 93, 94, 95, 98, 99, 102, 103, 105, 107, 108, 109, 111, 112, 113, 114, 117, 118, 119, 121, 122, 123, 124, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 143, 144, 145, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 171, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 216, 218, 219, 220, 221, 222, 226, 227, 228, 230, 231, 232, 234, 235, 236, 237, 239, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.58.conv (Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 50, 51, 52, 54, 55, 58, 59, 62, 64, 66, 67, 68, 69, 71, 73, 77, 78, 80, 81, 82, 86, 87, 88, 89, 90, 92, 93, 94, 95, 98, 99, 102, 103, 105, 107, 108, 109, 111, 112, 113, 114, 117, 118, 119, 121, 122, 123, 124, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 143, 144, 145, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 171, 173, 174, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 216, 218, 219, 220, 221, 222, 226, 227, 228, 230, 231, 232, 234, 235, 236, 237, 239, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255], NumPruned=206208]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 792])>, Index=[512, 513, 514, 515, 516, 517, 519, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 539, 540, 541, 543, 545, 546, 548, 549, 550, 551, 552, 554, 556, 557, 559, 560, 562, 563, 564, 566, 567, 570, 571, 574, 576, 578, 579, 580, 581, 583, 585, 589, 590, 592, 593, 594, 598, 599, 600, 601, 602, 604, 605, 606, 607, 610, 611, 614, 615, 617, 619, 620, 621, 623, 624, 625, 626, 629, 630, 631, 633, 634, 635, 636, 638, 641, 642, 643, 644, 645, 647, 648, 649, 650, 651, 653, 655, 656, 657, 660, 661, 662, 665, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 678, 679, 680, 681, 683, 685, 686, 688, 689, 690, 692, 693, 694, 695, 696, 698, 699, 700, 701, 702, 703, 704, 705, 707, 708, 709, 713, 714, 715, 717, 718, 719, 721, 722, 723, 724, 725, 728, 730, 731, 732, 733, 734, 738, 739, 740, 742, 743, 744, 746, 747, 748, 749, 751, 753, 754, 755, 757, 758, 759, 760, 761, 762, 764, 765, 766, 767], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(792, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 513, 514, 515, 516, 517, 519, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 539, 540, 541, 543, 545, 546, 548, 549, 550, 551, 552, 554, 556, 557, 559, 560, 562, 563, 564, 566, 567, 570, 571, 574, 576, 578, 579, 580, 581, 583, 585, 589, 590, 592, 593, 594, 598, 599, 600, 601, 602, 604, 605, 606, 607, 610, 611, 614, 615, 617, 619, 620, 621, 623, 624, 625, 626, 629, 630, 631, 633, 634, 635, 636, 638, 641, 642, 643, 644, 645, 647, 648, 649, 650, 651, 653, 655, 656, 657, 660, 661, 662, 665, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 678, 679, 680, 681, 683, 685, 686, 688, 689, 690, 692, 693, 694, 695, 696, 698, 699, 700, 701, 702, 703, 704, 705, 707, 708, 709, 713, 714, 715, 717, 718, 719, 721, 722, 723, 724, 725, 728, 730, 731, 732, 733, 734, 738, 739, 740, 742, 743, 744, 746, 747, 748, 749, 751, 753, 754, 755, 757, 758, 759, 760, 761, 762, 764, 765, 766, 767], NumPruned=45824]
260982 parameters will be pruned
-------------

2023-04-04 16:49:45.808 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.57.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 31, 33, 34, 35, 36, 38, 39, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 64, 65, 67, 68, 69, 71, 72, 74, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.57.conv (Conv2d(48, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 31, 33, 34, 35, 36, 38, 39, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 64, 65, 67, 68, 69, 71, 72, 74, 76], NumPruned=2544]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 31, 33, 34, 35, 36, 38, 39, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 64, 65, 67, 68, 69, 71, 72, 74, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.58.conv (Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 31, 33, 34, 35, 36, 38, 39, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 64, 65, 67, 68, 69, 71, 72, 74, 76], NumPruned=61056]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 589, 613])>, Index=[512, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 528, 529, 530, 531, 533, 534, 535, 536, 538, 539, 543, 545, 546, 547, 548, 550, 551, 552, 558, 559, 560, 561, 562, 563, 564, 565, 566, 568, 570, 571, 572, 576, 577, 579, 580, 581, 583, 584, 586, 588], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(613, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 528, 529, 530, 531, 533, 534, 535, 536, 538, 539, 543, 545, 546, 547, 548, 550, 551, 552, 558, 559, 560, 561, 562, 563, 564, 565, 566, 568, 570, 571, 572, 576, 577, 579, 580, 581, 583, 584, 586, 588], NumPruned=13568]
77274 parameters will be pruned
-------------

2023-04-04 16:49:45.809 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.58.conv (Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 7, 8, 10, 13, 14, 16, 18, 19, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 67, 69, 70, 71, 72, 73, 74, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 112, 114, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127], NumPruned=19224]
[ <DEP: prune_conv => prune_batchnorm on model.58.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 7, 8, 10, 13, 14, 16, 18, 19, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 67, 69, 70, 71, 72, 73, 74, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 112, 114, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 7, 8, 10, 13, 14, 16, 18, 19, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 67, 69, 70, 71, 72, 73, 74, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 112, 114, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.59.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 7, 8, 10, 13, 14, 16, 18, 19, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 67, 69, 70, 71, 72, 73, 74, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 112, 114, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 536, 560])>, Index=[384, 385, 387, 388, 391, 392, 394, 397, 398, 400, 402, 403, 405, 407, 408, 410, 411, 413, 414, 415, 416, 417, 418, 419, 425, 426, 427, 428, 429, 431, 432, 433, 434, 436, 437, 438, 439, 440, 441, 442, 443, 447, 448, 451, 453, 454, 455, 456, 457, 458, 461, 462, 464, 466, 467, 468, 469, 471, 472, 473, 474, 476, 477, 478, 480, 481, 482, 484, 485, 487, 488, 489, 490, 491, 492, 493, 496, 498, 499, 500, 501, 502, 503, 505, 506, 508, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(560, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 385, 387, 388, 391, 392, 394, 397, 398, 400, 402, 403, 405, 407, 408, 410, 411, 413, 414, 415, 416, 417, 418, 419, 425, 426, 427, 428, 429, 431, 432, 433, 434, 436, 437, 438, 439, 440, 441, 442, 443, 447, 448, 451, 453, 454, 455, 456, 457, 458, 461, 462, 464, 466, 467, 468, 469, 471, 472, 473, 474, 476, 477, 478, 480, 481, 482, 484, 485, 487, 488, 489, 490, 491, 492, 493, 496, 498, 499, 500, 501, 502, 503, 505, 506, 508, 509, 510, 511], NumPruned=22784]
144714 parameters will be pruned
-------------

2023-04-04 16:49:45.823 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.58.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 14, 16, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 35, 36, 37], NumPruned=56]
[ <DEP: prune_batchnorm => prune_conv on model.58.conv (Conv2d(24, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 14, 16, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 35, 36, 37], NumPruned=6048]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 14, 16, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 35, 36, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.59.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 14, 16, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 35, 36, 37], NumPruned=32256]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 423, 447, 471])>, Index=[384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 398, 400, 402, 403, 405, 406, 407, 408, 409, 411, 412, 414, 415, 416, 419, 420, 421], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(471, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 398, 400, 402, 403, 405, 406, 407, 408, 409, 411, 412, 414, 415, 416, 419, 420, 421], NumPruned=7168]
45528 parameters will be pruned
-------------

2023-04-04 16:49:45.825 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.59.conv (Conv2d(11, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 6, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 60, 64, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 107, 108, 109, 110, 113, 115, 117, 118, 119, 122, 124, 125, 126], NumPruned=8811]
[ <DEP: prune_conv => prune_batchnorm on model.59.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 6, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 60, 64, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 107, 108, 109, 110, 113, 115, 117, 118, 119, 122, 124, 125, 126], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 6, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 60, 64, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 107, 108, 109, 110, 113, 115, 117, 118, 119, 122, 124, 125, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.60.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 6, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 60, 64, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 107, 108, 109, 110, 113, 115, 117, 118, 119, 122, 124, 125, 126], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 395, 419, 443])>, Index=[257, 259, 260, 262, 265, 266, 267, 268, 269, 272, 274, 275, 276, 277, 278, 280, 281, 282, 283, 285, 286, 287, 288, 289, 291, 292, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 309, 310, 311, 312, 313, 314, 316, 320, 321, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 337, 338, 339, 341, 342, 343, 344, 345, 348, 349, 350, 351, 352, 354, 355, 356, 358, 360, 361, 363, 364, 365, 366, 369, 371, 373, 374, 375, 378, 380, 381, 382], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(443, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 259, 260, 262, 265, 266, 267, 268, 269, 272, 274, 275, 276, 277, 278, 280, 281, 282, 283, 285, 286, 287, 288, 289, 291, 292, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 309, 310, 311, 312, 313, 314, 316, 320, 321, 323, 324, 325, 326, 328, 329, 330, 333, 334, 335, 337, 338, 339, 341, 342, 343, 344, 345, 348, 349, 350, 351, 352, 354, 355, 356, 358, 360, 361, 363, 364, 365, 366, 369, 371, 373, 374, 375, 378, 380, 381, 382], NumPruned=22784]
134301 parameters will be pruned
-------------

2023-04-04 16:49:45.839 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.59.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 6, 7, 8, 10, 11, 13, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.59.conv (Conv2d(11, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 6, 7, 8, 10, 11, 13, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38], NumPruned=2673]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 6, 7, 8, 10, 11, 13, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.60.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 6, 7, 8, 10, 11, 13, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 295, 306, 330, 354])>, Index=[257, 258, 259, 262, 263, 264, 266, 267, 269, 272, 273, 274, 276, 277, 278, 280, 281, 282, 283, 284, 285, 289, 290, 291, 292, 293, 294], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(354, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 259, 262, 263, 264, 266, 267, 269, 272, 273, 274, 276, 277, 278, 280, 281, 282, 283, 284, 285, 289, 290, 291, 292, 293, 294], NumPruned=6912]
40743 parameters will be pruned
-------------

2023-04-04 16:49:45.840 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.60.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 44, 46, 47, 51, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 71, 72, 73, 74, 76, 78, 79, 81, 82, 84, 86, 87, 88, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 118, 119, 121, 124, 125, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.60.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 44, 46, 47, 51, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 71, 72, 73, 74, 76, 78, 79, 81, 82, 84, 86, 87, 88, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 118, 119, 121, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 44, 46, 47, 51, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 71, 72, 73, 74, 76, 78, 79, 81, 82, 84, 86, 87, 88, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 118, 119, 121, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.61.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 44, 46, 47, 51, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 71, 72, 73, 74, 76, 78, 79, 81, 82, 84, 86, 87, 88, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 118, 119, 121, 124, 125, 126, 127], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 268, 279, 303, 327])>, Index=[128, 129, 130, 131, 133, 134, 136, 137, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 167, 169, 170, 172, 174, 175, 179, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 196, 199, 200, 201, 202, 204, 206, 207, 209, 210, 212, 214, 215, 216, 219, 220, 221, 222, 225, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 240, 241, 243, 244, 246, 247, 249, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(327, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 133, 134, 136, 137, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 167, 169, 170, 172, 174, 175, 179, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 196, 199, 200, 201, 202, 204, 206, 207, 209, 210, 212, 214, 215, 216, 219, 220, 221, 222, 225, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 240, 241, 243, 244, 246, 247, 249, 252, 253, 254, 255], NumPruned=22784]
135102 parameters will be pruned
-------------

2023-04-04 16:49:45.855 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.60.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 22, 25, 27, 30, 31, 32, 33, 35, 37], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.60.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 22, 25, 27, 30, 31, 32, 33, 35, 37], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 22, 25, 27, 30, 31, 32, 33, 35, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.61.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 22, 25, 27, 30, 31, 32, 33, 35, 37], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 167, 179, 190, 214, 238])>, Index=[128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 147, 148, 150, 153, 155, 158, 159, 160, 161, 163, 165], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(238, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 147, 148, 150, 153, 155, 158, 159, 160, 161, 163, 165], NumPruned=6912]
40986 parameters will be pruned
-------------

2023-04-04 16:49:45.856 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.61.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[3, 4, 9, 10, 12, 14, 15, 18, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.61.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[3, 4, 9, 10, 12, 14, 15, 18, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[3, 4, 9, 10, 12, 14, 15, 18, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 140, 152, 163, 187, 211])>, Index=[3, 4, 9, 10, 12, 14, 15, 18, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(211, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[3, 4, 9, 10, 12, 14, 15, 18, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=22784]
32574 parameters will be pruned
-------------

2023-04-04 16:49:45.870 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.61.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 5, 6, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.61.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 5, 6, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 5, 6, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 39, 51, 63, 74, 98, 122])>, Index=[1, 2, 3, 5, 6, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.63.conv (Conv2d(122, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 5, 6, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38], NumPruned=6912]
9882 parameters will be pruned
-------------

2023-04-04 16:49:45.871 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.63.conv (Conv2d(95, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 21, 22, 23, 25, 27, 28, 30, 32, 33, 35, 37, 40, 43, 44, 45, 48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 89, 91, 92, 93, 95, 96, 98, 99, 100, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 123, 124, 125, 127, 130, 131, 133, 134, 135, 136, 138, 140, 142, 143, 145, 146, 147, 149, 150, 151, 152, 153, 156, 158, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 176, 178, 179, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 208, 209, 210, 211, 213, 215, 216, 218, 219, 220, 221, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 250, 251, 253, 254, 255], NumPruned=17005]
[ <DEP: prune_conv => prune_batchnorm on model.63.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 21, 22, 23, 25, 27, 28, 30, 32, 33, 35, 37, 40, 43, 44, 45, 48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 89, 91, 92, 93, 95, 96, 98, 99, 100, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 123, 124, 125, 127, 130, 131, 133, 134, 135, 136, 138, 140, 142, 143, 145, 146, 147, 149, 150, 151, 152, 153, 156, 158, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 176, 178, 179, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 208, 209, 210, 211, 213, 215, 216, 218, 219, 220, 221, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 250, 251, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 21, 22, 23, 25, 27, 28, 30, 32, 33, 35, 37, 40, 43, 44, 45, 48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 89, 91, 92, 93, 95, 96, 98, 99, 100, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 123, 124, 125, 127, 130, 131, 133, 134, 135, 136, 138, 140, 142, 143, 145, 146, 147, 149, 150, 151, 152, 153, 156, 158, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 176, 178, 179, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 208, 209, 210, 211, 213, 215, 216, 218, 219, 220, 221, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 250, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.64.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 21, 22, 23, 25, 27, 28, 30, 32, 33, 35, 37, 40, 43, 44, 45, 48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 89, 91, 92, 93, 95, 96, 98, 99, 100, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 123, 124, 125, 127, 130, 131, 133, 134, 135, 136, 138, 140, 142, 143, 145, 146, 147, 149, 150, 151, 152, 153, 156, 158, 162, 163, 164, 166, 167, 168, 169, 170, 171, 173, 174, 176, 178, 179, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 205, 208, 209, 210, 211, 213, 215, 216, 218, 219, 220, 221, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 247, 250, 251, 253, 254, 255], NumPruned=22912]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 512])>, Index=[257, 258, 259, 260, 262, 263, 264, 265, 266, 268, 269, 270, 271, 273, 274, 277, 278, 279, 281, 283, 284, 286, 288, 289, 291, 293, 296, 299, 300, 301, 304, 305, 306, 307, 308, 311, 313, 314, 315, 316, 317, 318, 319, 321, 324, 325, 326, 327, 329, 331, 332, 333, 335, 336, 338, 339, 340, 341, 342, 345, 347, 348, 349, 351, 352, 354, 355, 356, 358, 359, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 374, 375, 376, 377, 379, 380, 381, 383, 386, 387, 389, 390, 391, 392, 394, 396, 398, 399, 401, 402, 403, 405, 406, 407, 408, 409, 412, 414, 418, 419, 420, 422, 423, 424, 425, 426, 427, 429, 430, 432, 434, 435, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 460, 461, 464, 465, 466, 467, 469, 471, 472, 474, 475, 476, 477, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 492, 493, 494, 495, 496, 497, 499, 500, 501, 502, 503, 506, 507, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 259, 260, 262, 263, 264, 265, 266, 268, 269, 270, 271, 273, 274, 277, 278, 279, 281, 283, 284, 286, 288, 289, 291, 293, 296, 299, 300, 301, 304, 305, 306, 307, 308, 311, 313, 314, 315, 316, 317, 318, 319, 321, 324, 325, 326, 327, 329, 331, 332, 333, 335, 336, 338, 339, 340, 341, 342, 345, 347, 348, 349, 351, 352, 354, 355, 356, 358, 359, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 374, 375, 376, 377, 379, 380, 381, 383, 386, 387, 389, 390, 391, 392, 394, 396, 398, 399, 401, 402, 403, 405, 406, 407, 408, 409, 412, 414, 418, 419, 420, 422, 423, 424, 425, 426, 427, 429, 430, 432, 434, 435, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 460, 461, 464, 465, 466, 467, 469, 471, 472, 474, 475, 476, 477, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 492, 493, 494, 495, 496, 497, 499, 500, 501, 502, 503, 506, 507, 509, 510, 511], NumPruned=45824]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 259, 260, 262, 263, 264, 265, 266, 268, 269, 270, 271, 273, 274, 277, 278, 279, 281, 283, 284, 286, 288, 289, 291, 293, 296, 299, 300, 301, 304, 305, 306, 307, 308, 311, 313, 314, 315, 316, 317, 318, 319, 321, 324, 325, 326, 327, 329, 331, 332, 333, 335, 336, 338, 339, 340, 341, 342, 345, 347, 348, 349, 351, 352, 354, 355, 356, 358, 359, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 374, 375, 376, 377, 379, 380, 381, 383, 386, 387, 389, 390, 391, 392, 394, 396, 398, 399, 401, 402, 403, 405, 406, 407, 408, 409, 412, 414, 418, 419, 420, 422, 423, 424, 425, 426, 427, 429, 430, 432, 434, 435, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 460, 461, 464, 465, 466, 467, 469, 471, 472, 474, 475, 476, 477, 479, 480, 481, 482, 484, 485, 486, 488, 489, 490, 492, 493, 494, 495, 496, 497, 499, 500, 501, 502, 503, 506, 507, 509, 510, 511], NumPruned=45824]
131923 parameters will be pruned
-------------

2023-04-04 16:49:45.887 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.63.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 58, 59, 61, 62, 66, 68, 69, 70, 72, 74], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.63.conv (Conv2d(95, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 58, 59, 61, 62, 66, 68, 69, 70, 72, 74], NumPruned=5035]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 58, 59, 61, 62, 66, 68, 69, 70, 72, 74], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.64.conv (Conv2d(77, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 58, 59, 61, 62, 66, 68, 69, 70, 72, 74], NumPruned=6784]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 333])>, Index=[256, 257, 260, 261, 262, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 282, 284, 286, 287, 288, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 302, 303, 307, 308, 309, 310, 311, 314, 315, 317, 318, 322, 324, 325, 326, 328, 330], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 260, 261, 262, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 282, 284, 286, 287, 288, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 302, 303, 307, 308, 309, 310, 311, 314, 315, 317, 318, 322, 324, 325, 326, 328, 330], NumPruned=13568]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(333, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 260, 261, 262, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 282, 284, 286, 287, 288, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 302, 303, 307, 308, 309, 310, 311, 314, 315, 317, 318, 322, 324, 325, 326, 328, 330], NumPruned=13568]
39061 parameters will be pruned
-------------

2023-04-04 16:49:45.888 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.64.conv (Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 37, 39, 40, 41, 42, 44, 45, 47, 50, 52, 53, 54, 55, 56, 58, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 89, 91, 93, 94, 95, 100, 101, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 120, 122, 123, 126, 127], NumPruned=2136]
[ <DEP: prune_conv => prune_batchnorm on model.64.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 37, 39, 40, 41, 42, 44, 45, 47, 50, 52, 53, 54, 55, 56, 58, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 89, 91, 93, 94, 95, 100, 101, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 120, 122, 123, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 37, 39, 40, 41, 42, 44, 45, 47, 50, 52, 53, 54, 55, 56, 58, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 89, 91, 93, 94, 95, 100, 101, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 120, 122, 123, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 37, 39, 40, 41, 42, 44, 45, 47, 50, 52, 53, 54, 55, 56, 58, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 89, 91, 93, 94, 95, 100, 101, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 120, 122, 123, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256])>, Index=[128, 129, 130, 131, 132, 133, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 158, 160, 161, 162, 165, 167, 168, 169, 170, 172, 173, 175, 178, 180, 181, 182, 183, 184, 186, 191, 192, 193, 194, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 210, 212, 213, 214, 215, 217, 219, 221, 222, 223, 228, 229, 230, 231, 233, 234, 235, 236, 238, 239, 240, 241, 242, 243, 244, 245, 248, 250, 251, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.69.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 158, 160, 161, 162, 165, 167, 168, 169, 170, 172, 173, 175, 178, 180, 181, 182, 183, 184, 186, 191, 192, 193, 194, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 210, 212, 213, 214, 215, 217, 219, 221, 222, 223, 228, 229, 230, 231, 233, 234, 235, 236, 238, 239, 240, 241, 242, 243, 244, 245, 248, 250, 251, 254, 255], NumPruned=11392]
[ <DEP: _prune_concat => prune_related_conv on model.68.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 158, 160, 161, 162, 165, 167, 168, 169, 170, 172, 173, 175, 178, 180, 181, 182, 183, 184, 186, 191, 192, 193, 194, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 210, 212, 213, 214, 215, 217, 219, 221, 222, 223, 228, 229, 230, 231, 233, 234, 235, 236, 238, 239, 240, 241, 242, 243, 244, 245, 248, 250, 251, 254, 255], NumPruned=11392]
25098 parameters will be pruned
-------------

2023-04-04 16:49:45.902 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.64.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 34, 35, 36], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.64.conv (Conv2d(24, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 34, 35, 36], NumPruned=648]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 34, 35, 36], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 34, 35, 36], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 167])>, Index=[130, 131, 132, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 155, 158, 160, 161, 162, 163, 164], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.69.conv (Conv2d(167, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[130, 131, 132, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 155, 158, 160, 161, 162, 163, 164], NumPruned=3456]
[ <DEP: _prune_concat => prune_related_conv on model.68.conv (Conv2d(167, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[130, 131, 132, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 155, 158, 160, 161, 162, 163, 164], NumPruned=3456]
7614 parameters will be pruned
-------------

2023-04-04 16:49:45.903 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.66.conv (Conv2d(47, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=4183]
[ <DEP: prune_conv => prune_batchnorm on model.66.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 140])>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.69.conv (Conv2d(140, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=11392]
[ <DEP: _prune_concat => prune_related_conv on model.68.conv (Conv2d(140, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92, 93, 94, 96, 97, 98, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127], NumPruned=11392]
27145 parameters will be pruned
-------------

2023-04-04 16:49:45.918 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.66.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.66.conv (Conv2d(47, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=1269]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 39, 51])>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.69.conv (Conv2d(51, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=3456]
[ <DEP: _prune_concat => prune_related_conv on model.68.conv (Conv2d(51, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38], NumPruned=3456]
8235 parameters will be pruned
-------------

2023-04-04 16:49:45.919 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.68.conv (Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 35, 37, 38, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 59, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 97, 100, 101, 102, 108, 109, 110, 112, 113, 114, 117, 118, 119, 120, 121, 125, 126, 127], NumPruned=2136]
[ <DEP: prune_conv => prune_batchnorm on model.68.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 35, 37, 38, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 59, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 97, 100, 101, 102, 108, 109, 110, 112, 113, 114, 117, 118, 119, 120, 121, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 35, 37, 38, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 59, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 97, 100, 101, 102, 108, 109, 110, 112, 113, 114, 117, 118, 119, 120, 121, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256, 384, 512])>, Index=[384, 385, 390, 391, 392, 393, 394, 395, 397, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 415, 416, 417, 419, 421, 422, 425, 426, 429, 430, 431, 432, 433, 434, 435, 436, 437, 440, 442, 443, 445, 446, 447, 448, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 466, 467, 468, 469, 470, 471, 474, 476, 477, 478, 479, 480, 481, 484, 485, 486, 492, 493, 494, 496, 497, 498, 501, 502, 503, 504, 505, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 385, 390, 391, 392, 393, 394, 395, 397, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 415, 416, 417, 419, 421, 422, 425, 426, 429, 430, 431, 432, 433, 434, 435, 436, 437, 440, 442, 443, 445, 446, 447, 448, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 466, 467, 468, 469, 470, 471, 474, 476, 477, 478, 479, 480, 481, 484, 485, 486, 492, 493, 494, 496, 497, 498, 501, 502, 503, 504, 505, 509, 510, 511], NumPruned=11392]
13706 parameters will be pruned
-------------

2023-04-04 16:49:45.934 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.68.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 12, 15, 16, 17, 20, 21, 22, 23, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.68.conv (Conv2d(24, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 12, 15, 16, 17, 20, 21, 22, 23, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37], NumPruned=648]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 12, 15, 16, 17, 20, 21, 22, 23, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256, 384, 423])>, Index=[384, 385, 386, 387, 389, 390, 392, 393, 394, 396, 399, 400, 401, 404, 405, 406, 407, 409, 411, 413, 414, 416, 417, 418, 419, 420, 421], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(423, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 385, 386, 387, 389, 390, 392, 393, 394, 396, 399, 400, 401, 404, 405, 406, 407, 409, 411, 413, 414, 416, 417, 418, 419, 420, 421], NumPruned=3456]
4158 parameters will be pruned
-------------

2023-04-04 16:49:45.935 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.69.conv (Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 7, 11, 12, 13, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 59, 60, 61, 62, 64, 66, 67, 68, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 122, 123, 127], NumPruned=2136]
[ <DEP: prune_conv => prune_batchnorm on model.69.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 6, 7, 11, 12, 13, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 59, 60, 61, 62, 64, 66, 67, 68, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 122, 123, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 6, 7, 11, 12, 13, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 59, 60, 61, 62, 64, 66, 67, 68, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 122, 123, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.70.conv (Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 7, 11, 12, 13, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 59, 60, 61, 62, 64, 66, 67, 68, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 85, 87, 88, 89, 90, 92, 93, 94, 96, 97, 98, 100, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 122, 123, 127], NumPruned=51264]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256, 384, 396])>, Index=[256, 257, 259, 260, 262, 263, 267, 268, 269, 271, 272, 273, 275, 276, 277, 279, 282, 283, 284, 285, 287, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 303, 304, 305, 307, 309, 311, 312, 315, 316, 317, 318, 320, 322, 323, 324, 328, 329, 330, 331, 333, 334, 335, 337, 338, 339, 341, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 356, 358, 359, 360, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 383], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(396, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 259, 260, 262, 263, 267, 268, 269, 271, 272, 273, 275, 276, 277, 279, 282, 283, 284, 285, 287, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 303, 304, 305, 307, 309, 311, 312, 315, 316, 317, 318, 320, 322, 323, 324, 328, 329, 330, 331, 333, 334, 335, 337, 338, 339, 341, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 356, 358, 359, 360, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 377, 378, 379, 383], NumPruned=11392]
64970 parameters will be pruned
-------------

2023-04-04 16:49:45.950 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.69.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 5, 6, 7, 8, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 27, 29, 30, 31, 33, 34, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.69.conv (Conv2d(24, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 5, 6, 7, 8, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 27, 29, 30, 31, 33, 34, 36, 37, 38], NumPruned=648]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 5, 6, 7, 8, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 27, 29, 30, 31, 33, 34, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.70.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 5, 6, 7, 8, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 27, 29, 30, 31, 33, 34, 36, 37, 38], NumPruned=15552]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256, 295, 307])>, Index=[256, 257, 258, 261, 262, 263, 264, 267, 268, 269, 271, 272, 273, 274, 276, 277, 279, 280, 283, 285, 286, 287, 289, 290, 292, 293, 294], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(307, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 258, 261, 262, 263, 264, 267, 268, 269, 271, 272, 273, 274, 276, 277, 279, 280, 283, 285, 286, 287, 289, 290, 292, 293, 294], NumPruned=3456]
19710 parameters will be pruned
-------------

2023-04-04 16:49:45.951 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.70.conv (Conv2d(12, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 6, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 31, 32, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 56, 58, 59, 60, 62, 63], NumPruned=4752]
[ <DEP: prune_conv => prune_batchnorm on model.70.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 6, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 31, 32, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 56, 58, 59, 60, 62, 63], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 6, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 31, 32, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 56, 58, 59, 60, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.71.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 6, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 31, 32, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 56, 58, 59, 60, 62, 63], NumPruned=25344]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256, 268, 280])>, Index=[193, 195, 198, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 215, 217, 218, 219, 220, 221, 223, 224, 227, 228, 230, 231, 233, 234, 235, 236, 237, 238, 240, 241, 242, 244, 245, 248, 250, 251, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[193, 195, 198, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 215, 217, 218, 219, 220, 221, 223, 224, 227, 228, 230, 231, 233, 234, 235, 236, 237, 238, 240, 241, 242, 244, 245, 248, 250, 251, 252, 254, 255], NumPruned=5632]
35816 parameters will be pruned
-------------

2023-04-04 16:49:45.952 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.70.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 16, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.70.conv (Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 16, 18, 19], NumPruned=1512]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 16, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.71.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 16, 18, 19], NumPruned=8064]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 212, 224, 236])>, Index=[193, 194, 195, 196, 197, 198, 199, 203, 204, 205, 206, 208, 210, 211], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(236, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[193, 194, 195, 196, 197, 198, 199, 203, 204, 205, 206, 208, 210, 211], NumPruned=1792]
11396 parameters will be pruned
-------------

2023-04-04 16:49:45.966 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.71.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 45, 47, 48, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.71.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 45, 47, 48, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 45, 47, 48, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.72.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 45, 47, 48, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62], NumPruned=25344]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 198, 210, 222])>, Index=[129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 165, 173, 175, 176, 179, 181, 182, 183, 184, 185, 187, 188, 189, 190], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(222, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 165, 173, 175, 176, 179, 181, 182, 183, 184, 185, 187, 188, 189, 190], NumPruned=5632]
33440 parameters will be pruned
-------------

2023-04-04 16:49:45.967 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.71.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 6, 7, 9, 12, 13, 14, 15, 17, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.71.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 9, 12, 13, 14, 15, 17, 18, 19], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 6, 7, 9, 12, 13, 14, 15, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.72.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 6, 7, 9, 12, 13, 14, 15, 17, 18, 19], NumPruned=8064]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 148, 154, 166, 178])>, Index=[128, 130, 132, 133, 134, 135, 137, 140, 141, 142, 143, 145, 146, 147], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(178, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 130, 132, 133, 134, 135, 137, 140, 141, 142, 143, 145, 146, 147], NumPruned=1792]
10640 parameters will be pruned
-------------

2023-04-04 16:49:45.968 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.72.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 56, 57, 59, 60], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.72.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 56, 57, 59, 60], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 56, 57, 59, 60], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.73.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 56, 57, 59, 60], NumPruned=25344]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 134, 140, 152, 164])>, Index=[64, 67, 70, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 98, 99, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 116, 118, 120, 121, 123, 124], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(164, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 67, 70, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 98, 99, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 116, 118, 120, 121, 123, 124], NumPruned=5632]
33440 parameters will be pruned
-------------

2023-04-04 16:49:45.981 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.72.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 14, 15, 16, 18], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.72.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 14, 15, 16, 18], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 14, 15, 16, 18], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.73.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 14, 15, 16, 18], NumPruned=8064]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 84, 90, 96, 108, 120])>, Index=[64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 78, 79, 80, 82], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 78, 79, 80, 82], NumPruned=1792]
10640 parameters will be pruned
-------------

2023-04-04 16:49:45.982 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.73.conv (Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 42, 44, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 61, 62], NumPruned=2376]
[ <DEP: prune_conv => prune_batchnorm on model.73.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 42, 44, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 61, 62], NumPruned=88]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 42, 44, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 61, 62], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 70, 76, 82, 94, 106])>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 42, 44, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 61, 62], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(106, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 42, 44, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 61, 62], NumPruned=5632]
8096 parameters will be pruned
-------------

2023-04-04 16:49:45.983 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.73.bn (BatchNorm2d(20, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], NumPruned=28]
[ <DEP: prune_batchnorm => prune_conv on model.73.conv (Conv2d(6, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], NumPruned=756]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 20, 26, 32, 38, 50, 62])>, Index=[0, 2, 3, 4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.75.conv (Conv2d(62, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], NumPruned=1792]
2576 parameters will be pruned
-------------

2023-04-04 16:49:45.998 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.75.conv (Conv2d(48, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=4272]
[ <DEP: prune_conv => prune_batchnorm on model.75.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.102.rbr_dense.0 (Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=205056]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.102.rbr_1x1.0 (Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=22784]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.78.conv (Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=11392]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.77.conv (Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 78, 79, 81, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126], NumPruned=11392]
255074 parameters will be pruned
-------------

2023-04-04 16:49:46.014 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.75.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.75.conv (Conv2d(48, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=1296]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.102.rbr_dense.0 (Conv2d(39, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=62208]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.102.rbr_1x1.0 (Conv2d(39, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=6912]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.78.conv (Conv2d(39, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=3456]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.77.conv (Conv2d(39, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38], NumPruned=3456]
77382 parameters will be pruned
-------------

2023-04-04 16:49:46.015 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.77.conv (Conv2d(12, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 64, 67, 68, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 84, 86, 87, 88, 91, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 126, 127], NumPruned=1068]
[ <DEP: prune_conv => prune_batchnorm on model.77.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 64, 67, 68, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 84, 86, 87, 88, 91, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 64, 67, 68, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 84, 86, 87, 88, 91, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 280])>, Index=[128, 129, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 150, 151, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 186, 192, 195, 196, 198, 199, 200, 201, 203, 204, 205, 207, 208, 209, 212, 214, 215, 216, 219, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 239, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 150, 151, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 186, 192, 195, 196, 198, 199, 200, 201, 203, 204, 205, 207, 208, 209, 212, 214, 215, 216, 219, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 239, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 252, 254, 255], NumPruned=22784]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 150, 151, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 186, 192, 195, 196, 198, 199, 200, 201, 203, 204, 205, 207, 208, 209, 212, 214, 215, 216, 219, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 239, 240, 241, 242, 243, 245, 246, 247, 248, 250, 251, 252, 254, 255], NumPruned=22784]
46814 parameters will be pruned
-------------

2023-04-04 16:49:46.030 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.77.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 18, 20, 21, 24, 26, 27, 28, 29, 30, 31, 33, 35, 36], NumPruned=56]
[ <DEP: prune_batchnorm => prune_conv on model.77.conv (Conv2d(12, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 18, 20, 21, 24, 26, 27, 28, 29, 30, 31, 33, 35, 36], NumPruned=336]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 18, 20, 21, 24, 26, 27, 28, 29, 30, 31, 33, 35, 36], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 167, 191])>, Index=[128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 146, 148, 149, 152, 154, 155, 156, 157, 158, 159, 161, 163, 164], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(191, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 146, 148, 149, 152, 154, 155, 156, 157, 158, 159, 161, 163, 164], NumPruned=7168]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(191, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 146, 148, 149, 152, 154, 155, 156, 157, 158, 159, 161, 163, 164], NumPruned=7168]
14728 parameters will be pruned
-------------

2023-04-04 16:49:46.031 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.78.conv (Conv2d(12, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 20, 21, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 38, 41, 42, 43, 44, 46, 48, 49, 50, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 82, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 104, 105, 106, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=1068]
[ <DEP: prune_conv => prune_batchnorm on model.78.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 20, 21, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 38, 41, 42, 43, 44, 46, 48, 49, 50, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 82, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 104, 105, 106, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 20, 21, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 38, 41, 42, 43, 44, 46, 48, 49, 50, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 82, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 104, 105, 106, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.79.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 20, 21, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 38, 41, 42, 43, 44, 46, 48, 49, 50, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 82, 85, 86, 87, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 104, 105, 106, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 127], NumPruned=102528]
103774 parameters will be pruned
-------------

2023-04-04 16:49:46.032 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.78.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 4, 5, 8, 9, 10, 11, 12, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.78.conv (Conv2d(12, 39, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 8, 9, 10, 11, 12, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 35, 36, 37, 38], NumPruned=324]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 4, 5, 8, 9, 10, 11, 12, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.79.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 8, 9, 10, 11, 12, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 35, 36, 37, 38], NumPruned=31104]
31482 parameters will be pruned
-------------

2023-04-04 16:49:46.045 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.79.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.79.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 139, 163])>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(163, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=22784]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(163, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 7, 9, 10, 11, 12, 14, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 88, 89, 91, 93, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 120, 121, 122, 123, 127], NumPruned=22784]
55358 parameters will be pruned
-------------

2023-04-04 16:49:46.046 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.79.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.79.conv (Conv2d(12, 39, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=2916]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 39, 50, 74])>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.82.conv (Conv2d(74, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=6912]
[ <DEP: _prune_concat => prune_related_conv on model.81.conv (Conv2d(74, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 4, 5, 7, 8, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38], NumPruned=6912]
16794 parameters will be pruned
-------------

2023-04-04 16:49:46.062 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.81.conv (Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 72, 74, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 98, 100, 101, 103, 105, 106, 107, 108, 110, 111, 113, 114, 118, 119, 120, 122, 123, 125, 126, 127, 130, 132, 133, 135, 138, 140, 141, 143, 144, 145, 146, 148, 150, 152, 153, 155, 157, 158, 159, 160, 161, 162, 167, 168, 169, 172, 173, 174, 175, 178, 179, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 217, 218, 219, 220, 222, 223, 225, 226, 229, 230, 231, 232, 233, 234, 235, 238, 239, 244, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=8413]
[ <DEP: prune_conv => prune_batchnorm on model.81.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 72, 74, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 98, 100, 101, 103, 105, 106, 107, 108, 110, 111, 113, 114, 118, 119, 120, 122, 123, 125, 126, 127, 130, 132, 133, 135, 138, 140, 141, 143, 144, 145, 146, 148, 150, 152, 153, 155, 157, 158, 159, 160, 161, 162, 167, 168, 169, 172, 173, 174, 175, 178, 179, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 217, 218, 219, 220, 222, 223, 225, 226, 229, 230, 231, 232, 233, 234, 235, 238, 239, 244, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 72, 74, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 92, 93, 94, 95, 96, 98, 100, 101, 103, 105, 106, 107, 108, 110, 111, 113, 114, 118, 119, 120, 122, 123, 125, 126, 127, 130, 132, 133, 135, 138, 140, 141, 143, 144, 145, 146, 148, 150, 152, 153, 155, 157, 158, 159, 160, 161, 162, 167, 168, 169, 172, 173, 174, 175, 178, 179, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 217, 218, 219, 220, 222, 223, 225, 226, 229, 230, 231, 232, 233, 234, 235, 238, 239, 244, 247, 248, 249, 250, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 1024])>, Index=[769, 771, 772, 773, 776, 777, 778, 779, 780, 781, 782, 783, 786, 787, 788, 789, 791, 792, 793, 794, 795, 796, 797, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 819, 820, 821, 823, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 837, 838, 840, 842, 844, 847, 848, 849, 850, 851, 852, 853, 854, 855, 858, 860, 861, 862, 863, 864, 866, 868, 869, 871, 873, 874, 875, 876, 878, 879, 881, 882, 886, 887, 888, 890, 891, 893, 894, 895, 898, 900, 901, 903, 906, 908, 909, 911, 912, 913, 914, 916, 918, 920, 921, 923, 925, 926, 927, 928, 929, 930, 935, 936, 937, 940, 941, 942, 943, 946, 947, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 965, 966, 968, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 985, 986, 987, 988, 990, 991, 993, 994, 997, 998, 999, 1000, 1001, 1002, 1003, 1006, 1007, 1012, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1023], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[769, 771, 772, 773, 776, 777, 778, 779, 780, 781, 782, 783, 786, 787, 788, 789, 791, 792, 793, 794, 795, 796, 797, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 819, 820, 821, 823, 824, 825, 826, 827, 828, 830, 831, 832, 833, 834, 835, 837, 838, 840, 842, 844, 847, 848, 849, 850, 851, 852, 853, 854, 855, 858, 860, 861, 862, 863, 864, 866, 868, 869, 871, 873, 874, 875, 876, 878, 879, 881, 882, 886, 887, 888, 890, 891, 893, 894, 895, 898, 900, 901, 903, 906, 908, 909, 911, 912, 913, 914, 916, 918, 920, 921, 923, 925, 926, 927, 928, 929, 930, 935, 936, 937, 940, 941, 942, 943, 946, 947, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 965, 966, 968, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 985, 986, 987, 988, 990, 991, 993, 994, 997, 998, 999, 1000, 1001, 1002, 1003, 1006, 1007, 1012, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1023], NumPruned=45824]
54595 parameters will be pruned
-------------

2023-04-04 16:49:46.078 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.81.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 5, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58, 60, 61, 63, 64, 65, 69, 70, 71, 74, 75, 76], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.81.conv (Conv2d(47, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58, 60, 61, 63, 64, 65, 69, 70, 71, 74, 75, 76], NumPruned=2491]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58, 60, 61, 63, 64, 65, 69, 70, 71, 74, 75, 76], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 845])>, Index=[768, 771, 772, 773, 775, 777, 778, 780, 781, 783, 785, 786, 787, 788, 789, 790, 791, 792, 793, 796, 798, 799, 800, 804, 805, 806, 807, 808, 809, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 822, 824, 826, 828, 829, 831, 832, 833, 837, 838, 839, 842, 843, 844], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(845, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 771, 772, 773, 775, 777, 778, 780, 781, 783, 785, 786, 787, 788, 789, 790, 791, 792, 793, 796, 798, 799, 800, 804, 805, 806, 807, 808, 809, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 822, 824, 826, 828, 829, 831, 832, 833, 837, 838, 839, 842, 843, 844], NumPruned=13568]
16165 parameters will be pruned
-------------

2023-04-04 16:49:46.079 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.82.conv (Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 24, 25, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 58, 59, 63, 65, 67, 68, 69, 71, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 93, 95, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 119, 121, 122, 123, 124, 126, 127, 130, 131, 133, 135, 136, 139, 140, 141, 142, 143, 144, 145, 148, 150, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 192, 193, 195, 196, 197, 200, 202, 204, 206, 209, 210, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=8413]
[ <DEP: prune_conv => prune_batchnorm on model.82.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 24, 25, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 58, 59, 63, 65, 67, 68, 69, 71, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 93, 95, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 119, 121, 122, 123, 124, 126, 127, 130, 131, 133, 135, 136, 139, 140, 141, 142, 143, 144, 145, 148, 150, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 192, 193, 195, 196, 197, 200, 202, 204, 206, 209, 210, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=358]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 24, 25, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 58, 59, 63, 65, 67, 68, 69, 71, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 93, 95, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 119, 121, 122, 123, 124, 126, 127, 130, 131, 133, 135, 136, 139, 140, 141, 142, 143, 144, 145, 148, 150, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 192, 193, 195, 196, 197, 200, 202, 204, 206, 209, 210, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.83.conv (Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 24, 25, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 58, 59, 63, 65, 67, 68, 69, 71, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 93, 95, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 119, 121, 122, 123, 124, 126, 127, 130, 131, 133, 135, 136, 139, 140, 141, 142, 143, 144, 145, 148, 150, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 192, 193, 195, 196, 197, 200, 202, 204, 206, 209, 210, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 253, 254, 255], NumPruned=206208]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 768, 792])>, Index=[513, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 528, 530, 531, 532, 534, 536, 537, 540, 541, 543, 544, 545, 546, 547, 549, 551, 552, 554, 555, 556, 557, 558, 559, 560, 562, 564, 565, 566, 567, 570, 571, 575, 577, 579, 580, 581, 583, 586, 587, 588, 589, 590, 592, 593, 595, 596, 597, 599, 600, 605, 607, 610, 611, 614, 615, 616, 617, 619, 620, 621, 622, 623, 625, 626, 628, 629, 631, 633, 634, 635, 636, 638, 639, 642, 643, 645, 647, 648, 651, 652, 653, 654, 655, 656, 657, 660, 662, 663, 665, 666, 669, 670, 671, 672, 673, 674, 675, 676, 677, 679, 682, 683, 684, 685, 687, 688, 689, 690, 691, 692, 693, 695, 696, 697, 698, 700, 701, 702, 704, 705, 707, 708, 709, 712, 714, 716, 718, 721, 722, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 739, 741, 742, 743, 744, 745, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 758, 760, 761, 762, 763, 765, 766, 767], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(792, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[513, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 528, 530, 531, 532, 534, 536, 537, 540, 541, 543, 544, 545, 546, 547, 549, 551, 552, 554, 555, 556, 557, 558, 559, 560, 562, 564, 565, 566, 567, 570, 571, 575, 577, 579, 580, 581, 583, 586, 587, 588, 589, 590, 592, 593, 595, 596, 597, 599, 600, 605, 607, 610, 611, 614, 615, 616, 617, 619, 620, 621, 622, 623, 625, 626, 628, 629, 631, 633, 634, 635, 636, 638, 639, 642, 643, 645, 647, 648, 651, 652, 653, 654, 655, 656, 657, 660, 662, 663, 665, 666, 669, 670, 671, 672, 673, 674, 675, 676, 677, 679, 682, 683, 684, 685, 687, 688, 689, 690, 691, 692, 693, 695, 696, 697, 698, 700, 701, 702, 704, 705, 707, 708, 709, 712, 714, 716, 718, 721, 722, 724, 725, 727, 728, 729, 730, 731, 732, 734, 735, 736, 737, 738, 739, 741, 742, 743, 744, 745, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 758, 760, 761, 762, 763, 765, 766, 767], NumPruned=45824]
260803 parameters will be pruned
-------------

2023-04-04 16:49:46.094 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.82.bn (BatchNorm2d(77, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 54, 56, 58, 59, 60, 62, 63, 66, 68, 71, 73, 74], NumPruned=106]
[ <DEP: prune_batchnorm => prune_conv on model.82.conv (Conv2d(47, 77, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 54, 56, 58, 59, 60, 62, 63, 66, 68, 71, 73, 74], NumPruned=2491]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 54, 56, 58, 59, 60, 62, 63, 66, 68, 71, 73, 74], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.83.conv (Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 54, 56, 58, 59, 60, 62, 63, 66, 68, 71, 73, 74], NumPruned=61056]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 589, 613])>, Index=[512, 513, 516, 517, 518, 519, 520, 521, 522, 526, 527, 528, 531, 532, 533, 534, 535, 536, 537, 538, 540, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 553, 554, 555, 556, 557, 558, 559, 561, 562, 563, 566, 568, 570, 571, 572, 574, 575, 578, 580, 583, 585, 586], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(613, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 513, 516, 517, 518, 519, 520, 521, 522, 526, 527, 528, 531, 532, 533, 534, 535, 536, 537, 538, 540, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 553, 554, 555, 556, 557, 558, 559, 561, 562, 563, 566, 568, 570, 571, 572, 574, 575, 578, 580, 583, 585, 586], NumPruned=13568]
77221 parameters will be pruned
-------------

2023-04-04 16:49:46.095 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.83.conv (Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 81, 82, 83, 85, 86, 87, 90, 94, 95, 97, 99, 101, 102, 104, 105, 106, 109, 110, 111, 112, 113, 115, 117, 118, 122, 123, 124, 126, 127], NumPruned=19224]
[ <DEP: prune_conv => prune_batchnorm on model.83.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 81, 82, 83, 85, 86, 87, 90, 94, 95, 97, 99, 101, 102, 104, 105, 106, 109, 110, 111, 112, 113, 115, 117, 118, 122, 123, 124, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 81, 82, 83, 85, 86, 87, 90, 94, 95, 97, 99, 101, 102, 104, 105, 106, 109, 110, 111, 112, 113, 115, 117, 118, 122, 123, 124, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.84.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 81, 82, 83, 85, 86, 87, 90, 94, 95, 97, 99, 101, 102, 104, 105, 106, 109, 110, 111, 112, 113, 115, 117, 118, 122, 123, 124, 126, 127], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512, 536, 560])>, Index=[384, 385, 387, 388, 389, 390, 392, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 426, 427, 429, 430, 431, 432, 433, 435, 436, 437, 439, 440, 442, 444, 445, 447, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 463, 465, 466, 467, 469, 470, 471, 474, 478, 479, 481, 483, 485, 486, 488, 489, 490, 493, 494, 495, 496, 497, 499, 501, 502, 506, 507, 508, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(560, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 385, 387, 388, 389, 390, 392, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 426, 427, 429, 430, 431, 432, 433, 435, 436, 437, 439, 440, 442, 444, 445, 447, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 463, 465, 466, 467, 469, 470, 471, 474, 478, 479, 481, 483, 485, 486, 488, 489, 490, 493, 494, 495, 496, 497, 499, 501, 502, 506, 507, 508, 510, 511], NumPruned=22784]
144714 parameters will be pruned
-------------

2023-04-04 16:49:46.110 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.83.bn (BatchNorm2d(39, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 5, 6, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38], NumPruned=54]
[ <DEP: prune_batchnorm => prune_conv on model.83.conv (Conv2d(24, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 5, 6, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38], NumPruned=5832]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 5, 6, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.84.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 5, 6, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38], NumPruned=31104]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 423, 447, 471])>, Index=[384, 387, 389, 390, 394, 396, 397, 398, 399, 401, 404, 405, 406, 407, 408, 409, 410, 412, 414, 415, 416, 417, 418, 419, 420, 421, 422], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(471, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 387, 389, 390, 394, 396, 397, 398, 399, 401, 404, 405, 406, 407, 408, 409, 410, 412, 414, 415, 416, 417, 418, 419, 420, 421, 422], NumPruned=6912]
43902 parameters will be pruned
-------------

2023-04-04 16:49:46.111 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.84.conv (Conv2d(12, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 6, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 70, 72, 75, 80, 81, 82, 83, 86, 87, 89, 91, 94, 95, 97, 98, 99, 100, 101, 102, 106, 107, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 121, 123, 126, 127], NumPruned=9612]
[ <DEP: prune_conv => prune_batchnorm on model.84.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 5, 6, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 70, 72, 75, 80, 81, 82, 83, 86, 87, 89, 91, 94, 95, 97, 98, 99, 100, 101, 102, 106, 107, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 121, 123, 126, 127], NumPruned=178]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 5, 6, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 70, 72, 75, 80, 81, 82, 83, 86, 87, 89, 91, 94, 95, 97, 98, 99, 100, 101, 102, 106, 107, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 121, 123, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.85.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 6, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 70, 72, 75, 80, 81, 82, 83, 86, 87, 89, 91, 94, 95, 97, 98, 99, 100, 101, 102, 106, 107, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 121, 123, 126, 127], NumPruned=102528]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 396, 420, 444])>, Index=[257, 260, 261, 262, 264, 265, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 298, 299, 300, 301, 302, 303, 305, 306, 307, 308, 309, 310, 311, 313, 315, 316, 317, 318, 319, 321, 322, 323, 326, 328, 331, 336, 337, 338, 339, 342, 343, 345, 347, 350, 351, 353, 354, 355, 356, 357, 358, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 377, 379, 382, 383], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.88.conv (Conv2d(444, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 260, 261, 262, 264, 265, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 298, 299, 300, 301, 302, 303, 305, 306, 307, 308, 309, 310, 311, 313, 315, 316, 317, 318, 319, 321, 322, 323, 326, 328, 331, 336, 337, 338, 339, 342, 343, 345, 347, 350, 351, 353, 354, 355, 356, 357, 358, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 377, 379, 382, 383], NumPruned=22784]
135102 parameters will be pruned
-------------

